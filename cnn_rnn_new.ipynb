{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of cnn-rnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOACgTMdvEP/ncNa3uMG+if",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4f9dc27239a740a59fe385f5ffc8432e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69ba2f05783741e5bcdf9a95cee55af8",
              "IPY_MODEL_12b5345d53ab4365a5623420d34ffd12",
              "IPY_MODEL_1b8618dc77c948f7a11dea67a8039ad5"
            ],
            "layout": "IPY_MODEL_4b9620eab8df4486a9d719ba6cca646e"
          }
        },
        "69ba2f05783741e5bcdf9a95cee55af8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_480acb7521e5447aaed7436dd060937d",
            "placeholder": "​",
            "style": "IPY_MODEL_ea498f6dbea44cc5aac3b67fb4d320c9",
            "value": " 40%"
          }
        },
        "12b5345d53ab4365a5623420d34ffd12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6efa111e3eb6491ea638fcdb0194e3bb",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_098118273bbb44df887d48c4de7bf173",
            "value": 405
          }
        },
        "1b8618dc77c948f7a11dea67a8039ad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7f362013dcd4e07b9a59bbd405663e5",
            "placeholder": "​",
            "style": "IPY_MODEL_8f371e13ec2b4d7a845758ad1998e761",
            "value": " 405/1000 [19:41&lt;24:52,  2.51s/it]"
          }
        },
        "4b9620eab8df4486a9d719ba6cca646e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "480acb7521e5447aaed7436dd060937d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea498f6dbea44cc5aac3b67fb4d320c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6efa111e3eb6491ea638fcdb0194e3bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "098118273bbb44df887d48c4de7bf173": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d7f362013dcd4e07b9a59bbd405663e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f371e13ec2b4d7a845758ad1998e761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "843fdbadeb2445afa181f7cd9beb66eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4de5c953034147d7ac70660fae3879f5",
              "IPY_MODEL_c80504120a844190a8c4a92800eb635f"
            ],
            "layout": "IPY_MODEL_3a36ece4aca542f9b59ba1a8ce98b8d4"
          }
        },
        "4de5c953034147d7ac70660fae3879f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb00df99724e4ec1b697626c81abdf86",
            "placeholder": "​",
            "style": "IPY_MODEL_486d4425be6f40bc9c300633ec60cab6",
            "value": "0.140 MB of 0.140 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "c80504120a844190a8c4a92800eb635f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94cb6d2928ab4a64a5455c496a3f8e3d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e417e7b192c4bb3952190532c25f219",
            "value": 1
          }
        },
        "3a36ece4aca542f9b59ba1a8ce98b8d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb00df99724e4ec1b697626c81abdf86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "486d4425be6f40bc9c300633ec60cab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94cb6d2928ab4a64a5455c496a3f8e3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e417e7b192c4bb3952190532c25f219": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qn19325/individualProject/blob/main/cnn_rnn_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3pcrcqjLMJNr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17df64eb-4fb3-4e63-9b3f-c454bea778e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "coYAG5g8MklR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcMpGikkwYpD",
        "outputId": "a353096a-ed6c-412a-c428-a89504026b41"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.14)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.10)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.8)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.2.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb \n",
        "\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgIBw2yJw-ng",
        "outputId": "0aaa5556-92b0-4e8f-d10d-cf0aac44d514"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mindividual_project\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3mhKozdMgxe",
        "outputId": "ce6c403a-20c8-4fd3-8f67-f86f813898fc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = dict(\n",
        "    epochs=1000,\n",
        "    train_batch_size=8,\n",
        "    test_batch_size=1,\n",
        "    learning_rate=0.001,\n",
        "    input_size = 128,\n",
        "    hidden_size = 128,\n",
        "    output_size = 1,\n",
        "    sequence_length = 2,\n",
        "    num_layers = 1,\n",
        "    dataset=\"basic64x64\",\n",
        "    architecture=\"CNN/RNN\")"
      ],
      "metadata": {
        "id": "NpAwC6Azx2b2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_pipeline(hyperparameters):\n",
        "\n",
        "    # tell wandb to get started\n",
        "    with wandb.init(project=\"individual_project\", config=hyperparameters):\n",
        "      # access all HPs through wandb.config, so logging matches execution!\n",
        "      config = wandb.config\n",
        "\n",
        "      # make the model, data, and optimization problem\n",
        "      encoder, model, train_loader, test_loader, criterion, optimizer = make(config)\n",
        "      print(model)\n",
        "\n",
        "      # and use them to train the model\n",
        "      main(encoder, model, train_loader, test_loader, criterion, optimizer, config)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "z3_fP4da2iLr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make(config):\n",
        "    # Make the data\n",
        "    dataset = get_data()\n",
        "    train_loader = make_loader(dataset, batch_size=config.train_batch_size)\n",
        "    test_loader = make_loader(dataset, batch_size=config.test_batch_size)\n",
        "\n",
        "    # Make the CNN encoder\n",
        "    encoder = Encoder().to(device)\n",
        "    # Make the RNN model\n",
        "    model = RNN(config).to(device)\n",
        "\n",
        "    # Make the loss and optimizer\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), \n",
        "                                 lr=config.learning_rate)\n",
        "    \n",
        "    return encoder, model, train_loader, test_loader, criterion, optimizer"
      ],
      "metadata": {
        "id": "lLmPLpmj2xVV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data():\n",
        "    full_dataset = ImageDataLoader()\n",
        "    \n",
        "    return full_dataset\n",
        "\n",
        "def make_loader(dataset, batch_size):\n",
        "    loader = DataLoader(dataset=dataset, \n",
        "                        batch_size=batch_size, \n",
        "                        shuffle=True)\n",
        "    return loader"
      ],
      "metadata": {
        "id": "R79lV1au25yk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataLoader(Dataset):\n",
        "    def __init__(self, dir_=None):\n",
        "        self.data_df = pd.read_csv('gdrive/MyDrive/64x64.csv')\n",
        "        self.dataset_len = len(self.data_df) # read the number of len of your csv files\n",
        "    def __getitem__(self, idx):\n",
        "        # load the next image\n",
        "        f_name_t = self.data_df['Filename'][idx]\n",
        "        f_name_tp1 = self.data_df['Filename'][idx+1]\n",
        "        label = self.data_df['Label'][idx]\n",
        "        label = label.astype(np.float32) \n",
        "        label = np.true_divide(label, 20)\n",
        "        img_t = torchvision.io.read_image('gdrive/MyDrive/64x64/{}'.format(f_name_t))\n",
        "        img_tp1 = torchvision.io.read_image('gdrive/MyDrive/64x64/{}'.format(f_name_tp1))\n",
        "        img_t = img_t.float().div_(255.0)\n",
        "        img_tp1 = img_tp1.float().div_(255.0)\n",
        "        return img_t, img_tp1, label\n",
        "    def __len__(self):\n",
        "        return self.dataset_len - 1"
      ],
      "metadata": {
        "id": "Wn1hd26kMovt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(1, 8, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(8, 16, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "        self.fc1 = nn.Linear(65536, 128)\n",
        "    def forward(self, x):\n",
        "        state = self.cnn(x)\n",
        "        state = self.fc1(state)\n",
        "        return state"
      ],
      "metadata": {
        "id": "43ZUIXSnNOIq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(RNN, self).__init__()\n",
        "        self.input_size = config.get(\"input_size\")\n",
        "        self.num_layers = config.get(\"num_layers\")\n",
        "        self.hidden_size = config.get(\"hidden_size\")\n",
        "        self.output_size = config.get(\"output_size\")\n",
        "        self.rnn = nn.RNN(self.input_size, self.hidden_size, self.num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
        "    def init_hidden(self):\n",
        "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_size).to(device))\n",
        "    def forward(self, x):\n",
        "        self.batch_size = x.size(0)\n",
        "        self.hidden = self.init_hidden()\n",
        "        out, self.hidden = self.rnn(x, self.hidden)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "cZ42l4tSSPTL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(encoder, model, train_loader, test_loader, criterion, optimizer, config):\n",
        "    # Tell wandb to watch what the model gets up to: gradients, weights, and more!\n",
        "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
        "\n",
        "    # Run training and track with wandb\n",
        "    example_ct = 0\n",
        "    batch_ct = 0\n",
        "    for epoch in tqdm(range(config.epochs)):\n",
        "      for _, (images1, images2, labels) in enumerate(train_loader):\n",
        "        loss = train(images1, images2, labels, encoder, model, optimizer, criterion, epoch)\n",
        "      \n",
        "        example_ct += len(images1)\n",
        "        batch_ct += 1\n",
        "\n",
        "        # Report metrics every 25th batch\n",
        "        if ((batch_ct + 1) % 25) == 0:\n",
        "          train_log(loss, batch_ct, example_ct, epoch)\n",
        "\n",
        "      if epoch % 5 == 0:\n",
        "          test(test_loader, encoder, model, epoch)\n",
        "\n",
        "      if epoch % 25 == 0:\n",
        "        EPOCH = epoch\n",
        "        PATH = \"gdrive/MyDrive/models/cnn_rnn_\" + str(epoch) + \".pt\"\n",
        "        LOSS = loss\n",
        "        torch.save({\n",
        "                    'epoch': EPOCH,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'encoder_state_dict': encoder.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'loss': LOSS,\n",
        "                    }, PATH)"
      ],
      "metadata": {
        "id": "Vs7BHks4CE8D"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(images1, images2, labels, encoder, model, optimizer, criterion, epoch):\n",
        "  model.train()\n",
        "\n",
        "  images1, images2, labels = images1.to(device), images2.to(device), (labels.float()).to(device)\n",
        "  \n",
        "  # Forward pass ➡\n",
        "  # pass to encoder\n",
        "  output1 = encoder(images1)\n",
        "  output2 = encoder(images2)\n",
        "  # pass to RNN\n",
        "  batch_size1 = len(output1)\n",
        "  batch_size2 = len(output2)\n",
        "\n",
        "  output1 = output1.reshape(batch_size1,1,-1)\n",
        "  output2 = output2.reshape(batch_size2,1,-1)\n",
        "  \n",
        "  seq = torch.cat((output1, output2.detach()), dim=1)\n",
        "\n",
        "  outputs = model(seq.to(device))\n",
        "  loss = criterion(outputs[:,-1].squeeze(), labels.float())\n",
        "\n",
        "  # Backward pass ⬅\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "\n",
        "  # Step with optimizer\n",
        "  optimizer.step()\n",
        "\n",
        "  return loss"
      ],
      "metadata": {
        "id": "4qQgn0P97eX5"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_log(loss, batch_ct, example_ct, epoch):\n",
        "    # Where the magic happens\n",
        "    wandb.log({\"epoch\": epoch, \"loss\": loss}, step=example_ct)\n",
        "    print(f\"Epoch: \" + str(epoch) + f\", Batch: \" + str(batch_ct).zfill(4) + f\", Example: \" + str(example_ct).zfill(5) + f\", Loss: {loss:.3f}\")"
      ],
      "metadata": {
        "id": "B21QwRG07rT6"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(test_loader, encoder, model, epoch):\n",
        "    model.eval()\n",
        "\n",
        "    # Run the model on some test examples\n",
        "    with torch.no_grad():\n",
        "        correct, total = 0, 0\n",
        "        for images1, images2, labels in test_loader:\n",
        "            images1, images2, labels = images1.to(device), images2.to(device), (labels.float()).to(device)\n",
        "            output1 = encoder(images1)\n",
        "            output2 = encoder(images2)\n",
        "            # pass to RNN\n",
        "            batch_size1 = len(output1)\n",
        "            batch_size2 = len(output2)\n",
        "\n",
        "            output1 = output1.reshape(batch_size1,1,-1)\n",
        "            output2 = output2.reshape(batch_size2,1,-1)\n",
        "            \n",
        "            seq = torch.cat((output1, output2.detach()), dim=1)\n",
        "\n",
        "            outputs = model(seq.to(device))\n",
        "            # if epoch % 100 == 0:\n",
        "            #   print(f\"prediction:\" + str(round(outputs[:,-1].item(), 5)) + f\", labels:\"+ str(round(labels.item(), 5)))\n",
        "              \n",
        "            predicted = round(outputs[:,-1].item(), 1)\n",
        "            speed = round(labels.item(), 1)\n",
        "            \n",
        "            total += labels.size(0)\n",
        "            if predicted == speed:\n",
        "              correct += 1\n",
        "\n",
        "        print(f\"Accuracy of the model at epoch {epoch}: \" + f\"{100 * correct / total}%\")\n",
        "        \n",
        "        wandb.log({\"test_accuracy\": correct / total})"
      ],
      "metadata": {
        "id": "Vu7dCMkgC9b1"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_pipeline(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4f9dc27239a740a59fe385f5ffc8432e",
            "69ba2f05783741e5bcdf9a95cee55af8",
            "12b5345d53ab4365a5623420d34ffd12",
            "1b8618dc77c948f7a11dea67a8039ad5",
            "4b9620eab8df4486a9d719ba6cca646e",
            "480acb7521e5447aaed7436dd060937d",
            "ea498f6dbea44cc5aac3b67fb4d320c9",
            "6efa111e3eb6491ea638fcdb0194e3bb",
            "098118273bbb44df887d48c4de7bf173",
            "d7f362013dcd4e07b9a59bbd405663e5",
            "8f371e13ec2b4d7a845758ad1998e761",
            "843fdbadeb2445afa181f7cd9beb66eb",
            "4de5c953034147d7ac70660fae3879f5",
            "c80504120a844190a8c4a92800eb635f",
            "3a36ece4aca542f9b59ba1a8ce98b8d4",
            "eb00df99724e4ec1b697626c81abdf86",
            "486d4425be6f40bc9c300633ec60cab6",
            "94cb6d2928ab4a64a5455c496a3f8e3d",
            "9e417e7b192c4bb3952190532c25f219"
          ]
        },
        "id": "nVf46RjK-QI3",
        "outputId": "7aa21570-afc9-4538-f9b5-a19ec6d9d520"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.14"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220415_160140-f9crp3u2</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/individual_project/individual_project/runs/f9crp3u2\" target=\"_blank\">lucky-glitter-74</a></strong> to <a href=\"https://wandb.ai/individual_project/individual_project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN(\n",
            "  (rnn): RNN(128, 128, batch_first=True)\n",
            "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f9dc27239a740a59fe385f5ffc8432e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Batch: 0024, Example: 00192, Loss: 0.167\n",
            "Epoch: 0, Batch: 0049, Example: 00392, Loss: 0.120\n",
            "Epoch: 0, Batch: 0074, Example: 00592, Loss: 0.173\n",
            "Epoch: 0, Batch: 0099, Example: 00792, Loss: 0.121\n",
            "Epoch: 0, Batch: 0124, Example: 00992, Loss: 0.128\n",
            "Accuracy of the model at epoch 0: 9.3812375249501%\n",
            "Epoch: 1, Batch: 0149, Example: 01186, Loss: 0.109\n",
            "Epoch: 1, Batch: 0174, Example: 01386, Loss: 0.159\n",
            "Epoch: 1, Batch: 0199, Example: 01586, Loss: 0.093\n",
            "Epoch: 1, Batch: 0224, Example: 01786, Loss: 0.044\n",
            "Epoch: 1, Batch: 0249, Example: 01986, Loss: 0.049\n",
            "Epoch: 2, Batch: 0274, Example: 02180, Loss: 0.137\n",
            "Epoch: 2, Batch: 0299, Example: 02380, Loss: 0.116\n",
            "Epoch: 2, Batch: 0324, Example: 02580, Loss: 0.099\n",
            "Epoch: 2, Batch: 0349, Example: 02780, Loss: 0.080\n",
            "Epoch: 2, Batch: 0374, Example: 02980, Loss: 0.106\n",
            "Epoch: 3, Batch: 0399, Example: 03174, Loss: 0.122\n",
            "Epoch: 3, Batch: 0424, Example: 03374, Loss: 0.073\n",
            "Epoch: 3, Batch: 0449, Example: 03574, Loss: 0.055\n",
            "Epoch: 3, Batch: 0474, Example: 03774, Loss: 0.038\n",
            "Epoch: 3, Batch: 0499, Example: 03974, Loss: 0.062\n",
            "Epoch: 4, Batch: 0524, Example: 04168, Loss: 0.058\n",
            "Epoch: 4, Batch: 0549, Example: 04368, Loss: 0.083\n",
            "Epoch: 4, Batch: 0574, Example: 04568, Loss: 0.155\n",
            "Epoch: 4, Batch: 0599, Example: 04768, Loss: 0.071\n",
            "Epoch: 4, Batch: 0624, Example: 04968, Loss: 0.056\n",
            "Epoch: 5, Batch: 0649, Example: 05162, Loss: 0.148\n",
            "Epoch: 5, Batch: 0674, Example: 05362, Loss: 0.041\n",
            "Epoch: 5, Batch: 0699, Example: 05562, Loss: 0.131\n",
            "Epoch: 5, Batch: 0724, Example: 05762, Loss: 0.094\n",
            "Epoch: 5, Batch: 0749, Example: 05962, Loss: 0.123\n",
            "Accuracy of the model at epoch 5: 10.079840319361278%\n",
            "Epoch: 6, Batch: 0774, Example: 06156, Loss: 0.065\n",
            "Epoch: 6, Batch: 0799, Example: 06356, Loss: 0.077\n",
            "Epoch: 6, Batch: 0824, Example: 06556, Loss: 0.074\n",
            "Epoch: 6, Batch: 0849, Example: 06756, Loss: 0.036\n",
            "Epoch: 6, Batch: 0874, Example: 06956, Loss: 0.076\n",
            "Epoch: 7, Batch: 0899, Example: 07150, Loss: 0.164\n",
            "Epoch: 7, Batch: 0924, Example: 07350, Loss: 0.058\n",
            "Epoch: 7, Batch: 0949, Example: 07550, Loss: 0.101\n",
            "Epoch: 7, Batch: 0974, Example: 07750, Loss: 0.083\n",
            "Epoch: 7, Batch: 0999, Example: 07950, Loss: 0.110\n",
            "Epoch: 8, Batch: 1024, Example: 08144, Loss: 0.072\n",
            "Epoch: 8, Batch: 1049, Example: 08344, Loss: 0.070\n",
            "Epoch: 8, Batch: 1074, Example: 08544, Loss: 0.127\n",
            "Epoch: 8, Batch: 1099, Example: 08744, Loss: 0.128\n",
            "Epoch: 8, Batch: 1124, Example: 08944, Loss: 0.127\n",
            "Epoch: 9, Batch: 1149, Example: 09138, Loss: 0.035\n",
            "Epoch: 9, Batch: 1174, Example: 09338, Loss: 0.074\n",
            "Epoch: 9, Batch: 1199, Example: 09538, Loss: 0.084\n",
            "Epoch: 9, Batch: 1224, Example: 09738, Loss: 0.044\n",
            "Epoch: 9, Batch: 1249, Example: 09938, Loss: 0.090\n",
            "Epoch: 10, Batch: 1274, Example: 10132, Loss: 0.069\n",
            "Epoch: 10, Batch: 1299, Example: 10332, Loss: 0.083\n",
            "Epoch: 10, Batch: 1324, Example: 10532, Loss: 0.034\n",
            "Epoch: 10, Batch: 1349, Example: 10732, Loss: 0.113\n",
            "Epoch: 10, Batch: 1374, Example: 10932, Loss: 0.055\n",
            "Accuracy of the model at epoch 10: 10.079840319361278%\n",
            "Epoch: 11, Batch: 1399, Example: 11126, Loss: 0.084\n",
            "Epoch: 11, Batch: 1424, Example: 11326, Loss: 0.064\n",
            "Epoch: 11, Batch: 1449, Example: 11526, Loss: 0.037\n",
            "Epoch: 11, Batch: 1474, Example: 11726, Loss: 0.078\n",
            "Epoch: 11, Batch: 1499, Example: 11926, Loss: 0.068\n",
            "Epoch: 12, Batch: 1524, Example: 12120, Loss: 0.112\n",
            "Epoch: 12, Batch: 1549, Example: 12320, Loss: 0.076\n",
            "Epoch: 12, Batch: 1574, Example: 12520, Loss: 0.080\n",
            "Epoch: 12, Batch: 1599, Example: 12720, Loss: 0.132\n",
            "Epoch: 12, Batch: 1624, Example: 12920, Loss: 0.073\n",
            "Epoch: 13, Batch: 1649, Example: 13114, Loss: 0.055\n",
            "Epoch: 13, Batch: 1674, Example: 13314, Loss: 0.071\n",
            "Epoch: 13, Batch: 1699, Example: 13514, Loss: 0.038\n",
            "Epoch: 13, Batch: 1724, Example: 13714, Loss: 0.079\n",
            "Epoch: 13, Batch: 1749, Example: 13914, Loss: 0.075\n",
            "Epoch: 14, Batch: 1774, Example: 14108, Loss: 0.079\n",
            "Epoch: 14, Batch: 1799, Example: 14308, Loss: 0.062\n",
            "Epoch: 14, Batch: 1824, Example: 14508, Loss: 0.092\n",
            "Epoch: 14, Batch: 1849, Example: 14708, Loss: 0.044\n",
            "Epoch: 14, Batch: 1874, Example: 14908, Loss: 0.068\n",
            "Epoch: 15, Batch: 1899, Example: 15102, Loss: 0.055\n",
            "Epoch: 15, Batch: 1924, Example: 15302, Loss: 0.113\n",
            "Epoch: 15, Batch: 1949, Example: 15502, Loss: 0.079\n",
            "Epoch: 15, Batch: 1974, Example: 15702, Loss: 0.079\n",
            "Epoch: 15, Batch: 1999, Example: 15902, Loss: 0.086\n",
            "Accuracy of the model at epoch 15: 9.3812375249501%\n",
            "Epoch: 16, Batch: 2024, Example: 16096, Loss: 0.124\n",
            "Epoch: 16, Batch: 2049, Example: 16296, Loss: 0.097\n",
            "Epoch: 16, Batch: 2074, Example: 16496, Loss: 0.063\n",
            "Epoch: 16, Batch: 2099, Example: 16696, Loss: 0.114\n",
            "Epoch: 16, Batch: 2124, Example: 16896, Loss: 0.058\n",
            "Epoch: 17, Batch: 2149, Example: 17090, Loss: 0.056\n",
            "Epoch: 17, Batch: 2174, Example: 17290, Loss: 0.058\n",
            "Epoch: 17, Batch: 2199, Example: 17490, Loss: 0.072\n",
            "Epoch: 17, Batch: 2224, Example: 17690, Loss: 0.064\n",
            "Epoch: 17, Batch: 2249, Example: 17890, Loss: 0.059\n",
            "Epoch: 18, Batch: 2274, Example: 18084, Loss: 0.043\n",
            "Epoch: 18, Batch: 2299, Example: 18284, Loss: 0.090\n",
            "Epoch: 18, Batch: 2324, Example: 18484, Loss: 0.054\n",
            "Epoch: 18, Batch: 2349, Example: 18684, Loss: 0.084\n",
            "Epoch: 18, Batch: 2374, Example: 18884, Loss: 0.121\n",
            "Epoch: 19, Batch: 2399, Example: 19078, Loss: 0.041\n",
            "Epoch: 19, Batch: 2424, Example: 19278, Loss: 0.053\n",
            "Epoch: 19, Batch: 2449, Example: 19478, Loss: 0.101\n",
            "Epoch: 19, Batch: 2474, Example: 19678, Loss: 0.049\n",
            "Epoch: 19, Batch: 2499, Example: 19878, Loss: 0.124\n",
            "Epoch: 20, Batch: 2524, Example: 20072, Loss: 0.099\n",
            "Epoch: 20, Batch: 2549, Example: 20272, Loss: 0.050\n",
            "Epoch: 20, Batch: 2574, Example: 20472, Loss: 0.093\n",
            "Epoch: 20, Batch: 2599, Example: 20672, Loss: 0.053\n",
            "Epoch: 20, Batch: 2624, Example: 20872, Loss: 0.140\n",
            "Accuracy of the model at epoch 20: 18.862275449101798%\n",
            "Epoch: 21, Batch: 2649, Example: 21066, Loss: 0.043\n",
            "Epoch: 21, Batch: 2674, Example: 21266, Loss: 0.050\n",
            "Epoch: 21, Batch: 2699, Example: 21466, Loss: 0.081\n",
            "Epoch: 21, Batch: 2724, Example: 21666, Loss: 0.081\n",
            "Epoch: 21, Batch: 2749, Example: 21866, Loss: 0.063\n",
            "Epoch: 22, Batch: 2774, Example: 22060, Loss: 0.045\n",
            "Epoch: 22, Batch: 2799, Example: 22260, Loss: 0.054\n",
            "Epoch: 22, Batch: 2824, Example: 22460, Loss: 0.087\n",
            "Epoch: 22, Batch: 2849, Example: 22660, Loss: 0.072\n",
            "Epoch: 22, Batch: 2874, Example: 22860, Loss: 0.132\n",
            "Epoch: 23, Batch: 2899, Example: 23054, Loss: 0.081\n",
            "Epoch: 23, Batch: 2924, Example: 23254, Loss: 0.057\n",
            "Epoch: 23, Batch: 2949, Example: 23454, Loss: 0.106\n",
            "Epoch: 23, Batch: 2974, Example: 23654, Loss: 0.027\n",
            "Epoch: 23, Batch: 2999, Example: 23854, Loss: 0.111\n",
            "Epoch: 23, Batch: 3024, Example: 24048, Loss: 0.117\n",
            "Epoch: 24, Batch: 3049, Example: 24248, Loss: 0.082\n",
            "Epoch: 24, Batch: 3074, Example: 24448, Loss: 0.147\n",
            "Epoch: 24, Batch: 3099, Example: 24648, Loss: 0.078\n",
            "Epoch: 24, Batch: 3124, Example: 24848, Loss: 0.097\n",
            "Epoch: 24, Batch: 3149, Example: 25048, Loss: 0.059\n",
            "Epoch: 25, Batch: 3174, Example: 25242, Loss: 0.079\n",
            "Epoch: 25, Batch: 3199, Example: 25442, Loss: 0.063\n",
            "Epoch: 25, Batch: 3224, Example: 25642, Loss: 0.093\n",
            "Epoch: 25, Batch: 3249, Example: 25842, Loss: 0.093\n",
            "Epoch: 25, Batch: 3274, Example: 26042, Loss: 0.081\n",
            "Accuracy of the model at epoch 25: 19.560878243512974%\n",
            "Epoch: 26, Batch: 3299, Example: 26236, Loss: 0.065\n",
            "Epoch: 26, Batch: 3324, Example: 26436, Loss: 0.026\n",
            "Epoch: 26, Batch: 3349, Example: 26636, Loss: 0.079\n",
            "Epoch: 26, Batch: 3374, Example: 26836, Loss: 0.079\n",
            "Epoch: 26, Batch: 3399, Example: 27036, Loss: 0.066\n",
            "Epoch: 27, Batch: 3424, Example: 27230, Loss: 0.097\n",
            "Epoch: 27, Batch: 3449, Example: 27430, Loss: 0.029\n",
            "Epoch: 27, Batch: 3474, Example: 27630, Loss: 0.089\n",
            "Epoch: 27, Batch: 3499, Example: 27830, Loss: 0.059\n",
            "Epoch: 27, Batch: 3524, Example: 28030, Loss: 0.092\n",
            "Epoch: 28, Batch: 3549, Example: 28224, Loss: 0.032\n",
            "Epoch: 28, Batch: 3574, Example: 28424, Loss: 0.073\n",
            "Epoch: 28, Batch: 3599, Example: 28624, Loss: 0.090\n",
            "Epoch: 28, Batch: 3624, Example: 28824, Loss: 0.078\n",
            "Epoch: 28, Batch: 3649, Example: 29024, Loss: 0.082\n",
            "Epoch: 29, Batch: 3674, Example: 29218, Loss: 0.032\n",
            "Epoch: 29, Batch: 3699, Example: 29418, Loss: 0.059\n",
            "Epoch: 29, Batch: 3724, Example: 29618, Loss: 0.077\n",
            "Epoch: 29, Batch: 3749, Example: 29818, Loss: 0.071\n",
            "Epoch: 29, Batch: 3774, Example: 30018, Loss: 0.065\n",
            "Epoch: 30, Batch: 3799, Example: 30212, Loss: 0.076\n",
            "Epoch: 30, Batch: 3824, Example: 30412, Loss: 0.045\n",
            "Epoch: 30, Batch: 3849, Example: 30612, Loss: 0.055\n",
            "Epoch: 30, Batch: 3874, Example: 30812, Loss: 0.090\n",
            "Epoch: 30, Batch: 3899, Example: 31012, Loss: 0.066\n",
            "Accuracy of the model at epoch 30: 21.856287425149702%\n",
            "Epoch: 31, Batch: 3924, Example: 31206, Loss: 0.049\n",
            "Epoch: 31, Batch: 3949, Example: 31406, Loss: 0.035\n",
            "Epoch: 31, Batch: 3974, Example: 31606, Loss: 0.078\n",
            "Epoch: 31, Batch: 3999, Example: 31806, Loss: 0.071\n",
            "Epoch: 31, Batch: 4024, Example: 32006, Loss: 0.043\n",
            "Epoch: 32, Batch: 4049, Example: 32200, Loss: 0.074\n",
            "Epoch: 32, Batch: 4074, Example: 32400, Loss: 0.055\n",
            "Epoch: 32, Batch: 4099, Example: 32600, Loss: 0.091\n",
            "Epoch: 32, Batch: 4124, Example: 32800, Loss: 0.048\n",
            "Epoch: 32, Batch: 4149, Example: 33000, Loss: 0.098\n",
            "Epoch: 33, Batch: 4174, Example: 33194, Loss: 0.029\n",
            "Epoch: 33, Batch: 4199, Example: 33394, Loss: 0.040\n",
            "Epoch: 33, Batch: 4224, Example: 33594, Loss: 0.015\n",
            "Epoch: 33, Batch: 4249, Example: 33794, Loss: 0.065\n",
            "Epoch: 33, Batch: 4274, Example: 33994, Loss: 0.085\n",
            "Epoch: 34, Batch: 4299, Example: 34188, Loss: 0.047\n",
            "Epoch: 34, Batch: 4324, Example: 34388, Loss: 0.061\n",
            "Epoch: 34, Batch: 4349, Example: 34588, Loss: 0.037\n",
            "Epoch: 34, Batch: 4374, Example: 34788, Loss: 0.031\n",
            "Epoch: 34, Batch: 4399, Example: 34988, Loss: 0.041\n",
            "Epoch: 35, Batch: 4424, Example: 35182, Loss: 0.067\n",
            "Epoch: 35, Batch: 4449, Example: 35382, Loss: 0.045\n",
            "Epoch: 35, Batch: 4474, Example: 35582, Loss: 0.040\n",
            "Epoch: 35, Batch: 4499, Example: 35782, Loss: 0.064\n",
            "Epoch: 35, Batch: 4524, Example: 35982, Loss: 0.043\n",
            "Accuracy of the model at epoch 35: 13.972055888223553%\n",
            "Epoch: 36, Batch: 4549, Example: 36176, Loss: 0.038\n",
            "Epoch: 36, Batch: 4574, Example: 36376, Loss: 0.045\n",
            "Epoch: 36, Batch: 4599, Example: 36576, Loss: 0.030\n",
            "Epoch: 36, Batch: 4624, Example: 36776, Loss: 0.036\n",
            "Epoch: 36, Batch: 4649, Example: 36976, Loss: 0.055\n",
            "Epoch: 37, Batch: 4674, Example: 37170, Loss: 0.066\n",
            "Epoch: 37, Batch: 4699, Example: 37370, Loss: 0.071\n",
            "Epoch: 37, Batch: 4724, Example: 37570, Loss: 0.024\n",
            "Epoch: 37, Batch: 4749, Example: 37770, Loss: 0.040\n",
            "Epoch: 37, Batch: 4774, Example: 37970, Loss: 0.056\n",
            "Epoch: 38, Batch: 4799, Example: 38164, Loss: 0.056\n",
            "Epoch: 38, Batch: 4824, Example: 38364, Loss: 0.059\n",
            "Epoch: 38, Batch: 4849, Example: 38564, Loss: 0.048\n",
            "Epoch: 38, Batch: 4874, Example: 38764, Loss: 0.089\n",
            "Epoch: 38, Batch: 4899, Example: 38964, Loss: 0.054\n",
            "Epoch: 39, Batch: 4924, Example: 39158, Loss: 0.083\n",
            "Epoch: 39, Batch: 4949, Example: 39358, Loss: 0.032\n",
            "Epoch: 39, Batch: 4974, Example: 39558, Loss: 0.062\n",
            "Epoch: 39, Batch: 4999, Example: 39758, Loss: 0.079\n",
            "Epoch: 39, Batch: 5024, Example: 39958, Loss: 0.011\n",
            "Epoch: 40, Batch: 5049, Example: 40152, Loss: 0.070\n",
            "Epoch: 40, Batch: 5074, Example: 40352, Loss: 0.039\n",
            "Epoch: 40, Batch: 5099, Example: 40552, Loss: 0.010\n",
            "Epoch: 40, Batch: 5124, Example: 40752, Loss: 0.022\n",
            "Epoch: 40, Batch: 5149, Example: 40952, Loss: 0.044\n",
            "Accuracy of the model at epoch 40: 31.3373253493014%\n",
            "Epoch: 41, Batch: 5174, Example: 41146, Loss: 0.034\n",
            "Epoch: 41, Batch: 5199, Example: 41346, Loss: 0.023\n",
            "Epoch: 41, Batch: 5224, Example: 41546, Loss: 0.052\n",
            "Epoch: 41, Batch: 5249, Example: 41746, Loss: 0.039\n",
            "Epoch: 41, Batch: 5274, Example: 41946, Loss: 0.004\n",
            "Epoch: 42, Batch: 5299, Example: 42140, Loss: 0.054\n",
            "Epoch: 42, Batch: 5324, Example: 42340, Loss: 0.018\n",
            "Epoch: 42, Batch: 5349, Example: 42540, Loss: 0.073\n",
            "Epoch: 42, Batch: 5374, Example: 42740, Loss: 0.023\n",
            "Epoch: 42, Batch: 5399, Example: 42940, Loss: 0.047\n",
            "Epoch: 43, Batch: 5424, Example: 43134, Loss: 0.028\n",
            "Epoch: 43, Batch: 5449, Example: 43334, Loss: 0.033\n",
            "Epoch: 43, Batch: 5474, Example: 43534, Loss: 0.032\n",
            "Epoch: 43, Batch: 5499, Example: 43734, Loss: 0.012\n",
            "Epoch: 43, Batch: 5524, Example: 43934, Loss: 0.018\n",
            "Epoch: 44, Batch: 5549, Example: 44128, Loss: 0.018\n",
            "Epoch: 44, Batch: 5574, Example: 44328, Loss: 0.073\n",
            "Epoch: 44, Batch: 5599, Example: 44528, Loss: 0.039\n",
            "Epoch: 44, Batch: 5624, Example: 44728, Loss: 0.024\n",
            "Epoch: 44, Batch: 5649, Example: 44928, Loss: 0.043\n",
            "Epoch: 45, Batch: 5674, Example: 45122, Loss: 0.050\n",
            "Epoch: 45, Batch: 5699, Example: 45322, Loss: 0.008\n",
            "Epoch: 45, Batch: 5724, Example: 45522, Loss: 0.019\n",
            "Epoch: 45, Batch: 5749, Example: 45722, Loss: 0.008\n",
            "Epoch: 45, Batch: 5774, Example: 45922, Loss: 0.012\n",
            "Accuracy of the model at epoch 45: 19.960079840319363%\n",
            "Epoch: 46, Batch: 5799, Example: 46116, Loss: 0.023\n",
            "Epoch: 46, Batch: 5824, Example: 46316, Loss: 0.010\n",
            "Epoch: 46, Batch: 5849, Example: 46516, Loss: 0.021\n",
            "Epoch: 46, Batch: 5874, Example: 46716, Loss: 0.013\n",
            "Epoch: 46, Batch: 5899, Example: 46916, Loss: 0.009\n",
            "Epoch: 47, Batch: 5924, Example: 47110, Loss: 0.027\n",
            "Epoch: 47, Batch: 5949, Example: 47310, Loss: 0.023\n",
            "Epoch: 47, Batch: 5974, Example: 47510, Loss: 0.006\n",
            "Epoch: 47, Batch: 5999, Example: 47710, Loss: 0.004\n",
            "Epoch: 47, Batch: 6024, Example: 47910, Loss: 0.007\n",
            "Epoch: 48, Batch: 6049, Example: 48104, Loss: 0.006\n",
            "Epoch: 48, Batch: 6074, Example: 48304, Loss: 0.015\n",
            "Epoch: 48, Batch: 6099, Example: 48504, Loss: 0.007\n",
            "Epoch: 48, Batch: 6124, Example: 48704, Loss: 0.026\n",
            "Epoch: 48, Batch: 6149, Example: 48904, Loss: 0.021\n",
            "Epoch: 48, Batch: 6174, Example: 49098, Loss: 0.007\n",
            "Epoch: 49, Batch: 6199, Example: 49298, Loss: 0.015\n",
            "Epoch: 49, Batch: 6224, Example: 49498, Loss: 0.026\n",
            "Epoch: 49, Batch: 6249, Example: 49698, Loss: 0.032\n",
            "Epoch: 49, Batch: 6274, Example: 49898, Loss: 0.004\n",
            "Epoch: 49, Batch: 6299, Example: 50098, Loss: 0.017\n",
            "Epoch: 50, Batch: 6324, Example: 50292, Loss: 0.005\n",
            "Epoch: 50, Batch: 6349, Example: 50492, Loss: 0.012\n",
            "Epoch: 50, Batch: 6374, Example: 50692, Loss: 0.013\n",
            "Epoch: 50, Batch: 6399, Example: 50892, Loss: 0.011\n",
            "Epoch: 50, Batch: 6424, Example: 51092, Loss: 0.020\n",
            "Accuracy of the model at epoch 50: 35.62874251497006%\n",
            "Epoch: 51, Batch: 6449, Example: 51286, Loss: 0.005\n",
            "Epoch: 51, Batch: 6474, Example: 51486, Loss: 0.007\n",
            "Epoch: 51, Batch: 6499, Example: 51686, Loss: 0.023\n",
            "Epoch: 51, Batch: 6524, Example: 51886, Loss: 0.006\n",
            "Epoch: 51, Batch: 6549, Example: 52086, Loss: 0.029\n",
            "Epoch: 52, Batch: 6574, Example: 52280, Loss: 0.011\n",
            "Epoch: 52, Batch: 6599, Example: 52480, Loss: 0.006\n",
            "Epoch: 52, Batch: 6624, Example: 52680, Loss: 0.004\n",
            "Epoch: 52, Batch: 6649, Example: 52880, Loss: 0.010\n",
            "Epoch: 52, Batch: 6674, Example: 53080, Loss: 0.008\n",
            "Epoch: 53, Batch: 6699, Example: 53274, Loss: 0.005\n",
            "Epoch: 53, Batch: 6724, Example: 53474, Loss: 0.009\n",
            "Epoch: 53, Batch: 6749, Example: 53674, Loss: 0.011\n",
            "Epoch: 53, Batch: 6774, Example: 53874, Loss: 0.006\n",
            "Epoch: 53, Batch: 6799, Example: 54074, Loss: 0.006\n",
            "Epoch: 54, Batch: 6824, Example: 54268, Loss: 0.006\n",
            "Epoch: 54, Batch: 6849, Example: 54468, Loss: 0.007\n",
            "Epoch: 54, Batch: 6874, Example: 54668, Loss: 0.003\n",
            "Epoch: 54, Batch: 6899, Example: 54868, Loss: 0.026\n",
            "Epoch: 54, Batch: 6924, Example: 55068, Loss: 0.029\n",
            "Epoch: 55, Batch: 6949, Example: 55262, Loss: 0.006\n",
            "Epoch: 55, Batch: 6974, Example: 55462, Loss: 0.039\n",
            "Epoch: 55, Batch: 6999, Example: 55662, Loss: 0.002\n",
            "Epoch: 55, Batch: 7024, Example: 55862, Loss: 0.004\n",
            "Epoch: 55, Batch: 7049, Example: 56062, Loss: 0.010\n",
            "Accuracy of the model at epoch 55: 44.41117764471058%\n",
            "Epoch: 56, Batch: 7074, Example: 56256, Loss: 0.004\n",
            "Epoch: 56, Batch: 7099, Example: 56456, Loss: 0.043\n",
            "Epoch: 56, Batch: 7124, Example: 56656, Loss: 0.016\n",
            "Epoch: 56, Batch: 7149, Example: 56856, Loss: 0.014\n",
            "Epoch: 56, Batch: 7174, Example: 57056, Loss: 0.021\n",
            "Epoch: 57, Batch: 7199, Example: 57250, Loss: 0.006\n",
            "Epoch: 57, Batch: 7224, Example: 57450, Loss: 0.012\n",
            "Epoch: 57, Batch: 7249, Example: 57650, Loss: 0.016\n",
            "Epoch: 57, Batch: 7274, Example: 57850, Loss: 0.007\n",
            "Epoch: 57, Batch: 7299, Example: 58050, Loss: 0.008\n",
            "Epoch: 58, Batch: 7324, Example: 58244, Loss: 0.026\n",
            "Epoch: 58, Batch: 7349, Example: 58444, Loss: 0.018\n",
            "Epoch: 58, Batch: 7374, Example: 58644, Loss: 0.007\n",
            "Epoch: 58, Batch: 7399, Example: 58844, Loss: 0.008\n",
            "Epoch: 58, Batch: 7424, Example: 59044, Loss: 0.011\n",
            "Epoch: 59, Batch: 7449, Example: 59238, Loss: 0.015\n",
            "Epoch: 59, Batch: 7474, Example: 59438, Loss: 0.004\n",
            "Epoch: 59, Batch: 7499, Example: 59638, Loss: 0.009\n",
            "Epoch: 59, Batch: 7524, Example: 59838, Loss: 0.007\n",
            "Epoch: 59, Batch: 7549, Example: 60038, Loss: 0.002\n",
            "Epoch: 60, Batch: 7574, Example: 60232, Loss: 0.005\n",
            "Epoch: 60, Batch: 7599, Example: 60432, Loss: 0.001\n",
            "Epoch: 60, Batch: 7624, Example: 60632, Loss: 0.013\n",
            "Epoch: 60, Batch: 7649, Example: 60832, Loss: 0.024\n",
            "Epoch: 60, Batch: 7674, Example: 61032, Loss: 0.008\n",
            "Accuracy of the model at epoch 60: 45.50898203592814%\n",
            "Epoch: 61, Batch: 7699, Example: 61226, Loss: 0.010\n",
            "Epoch: 61, Batch: 7724, Example: 61426, Loss: 0.040\n",
            "Epoch: 61, Batch: 7749, Example: 61626, Loss: 0.003\n",
            "Epoch: 61, Batch: 7774, Example: 61826, Loss: 0.009\n",
            "Epoch: 61, Batch: 7799, Example: 62026, Loss: 0.018\n",
            "Epoch: 62, Batch: 7824, Example: 62220, Loss: 0.005\n",
            "Epoch: 62, Batch: 7849, Example: 62420, Loss: 0.023\n",
            "Epoch: 62, Batch: 7874, Example: 62620, Loss: 0.006\n",
            "Epoch: 62, Batch: 7899, Example: 62820, Loss: 0.007\n",
            "Epoch: 62, Batch: 7924, Example: 63020, Loss: 0.003\n",
            "Epoch: 63, Batch: 7949, Example: 63214, Loss: 0.010\n",
            "Epoch: 63, Batch: 7974, Example: 63414, Loss: 0.011\n",
            "Epoch: 63, Batch: 7999, Example: 63614, Loss: 0.011\n",
            "Epoch: 63, Batch: 8024, Example: 63814, Loss: 0.017\n",
            "Epoch: 63, Batch: 8049, Example: 64014, Loss: 0.001\n",
            "Epoch: 64, Batch: 8074, Example: 64208, Loss: 0.005\n",
            "Epoch: 64, Batch: 8099, Example: 64408, Loss: 0.017\n",
            "Epoch: 64, Batch: 8124, Example: 64608, Loss: 0.003\n",
            "Epoch: 64, Batch: 8149, Example: 64808, Loss: 0.012\n",
            "Epoch: 64, Batch: 8174, Example: 65008, Loss: 0.037\n",
            "Epoch: 65, Batch: 8199, Example: 65202, Loss: 0.025\n",
            "Epoch: 65, Batch: 8224, Example: 65402, Loss: 0.010\n",
            "Epoch: 65, Batch: 8249, Example: 65602, Loss: 0.002\n",
            "Epoch: 65, Batch: 8274, Example: 65802, Loss: 0.018\n",
            "Epoch: 65, Batch: 8299, Example: 66002, Loss: 0.026\n",
            "Accuracy of the model at epoch 65: 49.10179640718563%\n",
            "Epoch: 66, Batch: 8324, Example: 66196, Loss: 0.003\n",
            "Epoch: 66, Batch: 8349, Example: 66396, Loss: 0.012\n",
            "Epoch: 66, Batch: 8374, Example: 66596, Loss: 0.002\n",
            "Epoch: 66, Batch: 8399, Example: 66796, Loss: 0.007\n",
            "Epoch: 66, Batch: 8424, Example: 66996, Loss: 0.012\n",
            "Epoch: 67, Batch: 8449, Example: 67190, Loss: 0.017\n",
            "Epoch: 67, Batch: 8474, Example: 67390, Loss: 0.019\n",
            "Epoch: 67, Batch: 8499, Example: 67590, Loss: 0.001\n",
            "Epoch: 67, Batch: 8524, Example: 67790, Loss: 0.007\n",
            "Epoch: 67, Batch: 8549, Example: 67990, Loss: 0.007\n",
            "Epoch: 68, Batch: 8574, Example: 68184, Loss: 0.005\n",
            "Epoch: 68, Batch: 8599, Example: 68384, Loss: 0.007\n",
            "Epoch: 68, Batch: 8624, Example: 68584, Loss: 0.003\n",
            "Epoch: 68, Batch: 8649, Example: 68784, Loss: 0.006\n",
            "Epoch: 68, Batch: 8674, Example: 68984, Loss: 0.006\n",
            "Epoch: 69, Batch: 8699, Example: 69178, Loss: 0.006\n",
            "Epoch: 69, Batch: 8724, Example: 69378, Loss: 0.002\n",
            "Epoch: 69, Batch: 8749, Example: 69578, Loss: 0.007\n",
            "Epoch: 69, Batch: 8774, Example: 69778, Loss: 0.014\n",
            "Epoch: 69, Batch: 8799, Example: 69978, Loss: 0.004\n",
            "Epoch: 70, Batch: 8824, Example: 70172, Loss: 0.009\n",
            "Epoch: 70, Batch: 8849, Example: 70372, Loss: 0.003\n",
            "Epoch: 70, Batch: 8874, Example: 70572, Loss: 0.003\n",
            "Epoch: 70, Batch: 8899, Example: 70772, Loss: 0.011\n",
            "Epoch: 70, Batch: 8924, Example: 70972, Loss: 0.002\n",
            "Accuracy of the model at epoch 70: 48.40319361277445%\n",
            "Epoch: 71, Batch: 8949, Example: 71166, Loss: 0.007\n",
            "Epoch: 71, Batch: 8974, Example: 71366, Loss: 0.009\n",
            "Epoch: 71, Batch: 8999, Example: 71566, Loss: 0.001\n",
            "Epoch: 71, Batch: 9024, Example: 71766, Loss: 0.007\n",
            "Epoch: 71, Batch: 9049, Example: 71966, Loss: 0.002\n",
            "Epoch: 72, Batch: 9074, Example: 72160, Loss: 0.002\n",
            "Epoch: 72, Batch: 9099, Example: 72360, Loss: 0.011\n",
            "Epoch: 72, Batch: 9124, Example: 72560, Loss: 0.010\n",
            "Epoch: 72, Batch: 9149, Example: 72760, Loss: 0.001\n",
            "Epoch: 72, Batch: 9174, Example: 72960, Loss: 0.003\n",
            "Epoch: 73, Batch: 9199, Example: 73154, Loss: 0.002\n",
            "Epoch: 73, Batch: 9224, Example: 73354, Loss: 0.002\n",
            "Epoch: 73, Batch: 9249, Example: 73554, Loss: 0.005\n",
            "Epoch: 73, Batch: 9274, Example: 73754, Loss: 0.007\n",
            "Epoch: 73, Batch: 9299, Example: 73954, Loss: 0.005\n",
            "Epoch: 73, Batch: 9324, Example: 74148, Loss: 0.003\n",
            "Epoch: 74, Batch: 9349, Example: 74348, Loss: 0.004\n",
            "Epoch: 74, Batch: 9374, Example: 74548, Loss: 0.017\n",
            "Epoch: 74, Batch: 9399, Example: 74748, Loss: 0.005\n",
            "Epoch: 74, Batch: 9424, Example: 74948, Loss: 0.006\n",
            "Epoch: 74, Batch: 9449, Example: 75148, Loss: 0.003\n",
            "Epoch: 75, Batch: 9474, Example: 75342, Loss: 0.008\n",
            "Epoch: 75, Batch: 9499, Example: 75542, Loss: 0.016\n",
            "Epoch: 75, Batch: 9524, Example: 75742, Loss: 0.003\n",
            "Epoch: 75, Batch: 9549, Example: 75942, Loss: 0.004\n",
            "Epoch: 75, Batch: 9574, Example: 76142, Loss: 0.011\n",
            "Accuracy of the model at epoch 75: 39.52095808383233%\n",
            "Epoch: 76, Batch: 9599, Example: 76336, Loss: 0.003\n",
            "Epoch: 76, Batch: 9624, Example: 76536, Loss: 0.006\n",
            "Epoch: 76, Batch: 9649, Example: 76736, Loss: 0.002\n",
            "Epoch: 76, Batch: 9674, Example: 76936, Loss: 0.014\n",
            "Epoch: 76, Batch: 9699, Example: 77136, Loss: 0.004\n",
            "Epoch: 77, Batch: 9724, Example: 77330, Loss: 0.002\n",
            "Epoch: 77, Batch: 9749, Example: 77530, Loss: 0.004\n",
            "Epoch: 77, Batch: 9774, Example: 77730, Loss: 0.004\n",
            "Epoch: 77, Batch: 9799, Example: 77930, Loss: 0.004\n",
            "Epoch: 77, Batch: 9824, Example: 78130, Loss: 0.001\n",
            "Epoch: 78, Batch: 9849, Example: 78324, Loss: 0.001\n",
            "Epoch: 78, Batch: 9874, Example: 78524, Loss: 0.001\n",
            "Epoch: 78, Batch: 9899, Example: 78724, Loss: 0.004\n",
            "Epoch: 78, Batch: 9924, Example: 78924, Loss: 0.016\n",
            "Epoch: 78, Batch: 9949, Example: 79124, Loss: 0.002\n",
            "Epoch: 79, Batch: 9974, Example: 79318, Loss: 0.008\n",
            "Epoch: 79, Batch: 9999, Example: 79518, Loss: 0.006\n",
            "Epoch: 79, Batch: 10024, Example: 79718, Loss: 0.005\n",
            "Epoch: 79, Batch: 10049, Example: 79918, Loss: 0.001\n",
            "Epoch: 79, Batch: 10074, Example: 80118, Loss: 0.003\n",
            "Epoch: 80, Batch: 10099, Example: 80312, Loss: 0.007\n",
            "Epoch: 80, Batch: 10124, Example: 80512, Loss: 0.006\n",
            "Epoch: 80, Batch: 10149, Example: 80712, Loss: 0.017\n",
            "Epoch: 80, Batch: 10174, Example: 80912, Loss: 0.007\n",
            "Epoch: 80, Batch: 10199, Example: 81112, Loss: 0.003\n",
            "Accuracy of the model at epoch 80: 61.377245508982035%\n",
            "Epoch: 81, Batch: 10224, Example: 81306, Loss: 0.007\n",
            "Epoch: 81, Batch: 10249, Example: 81506, Loss: 0.008\n",
            "Epoch: 81, Batch: 10274, Example: 81706, Loss: 0.011\n",
            "Epoch: 81, Batch: 10299, Example: 81906, Loss: 0.003\n",
            "Epoch: 81, Batch: 10324, Example: 82106, Loss: 0.003\n",
            "Epoch: 82, Batch: 10349, Example: 82300, Loss: 0.001\n",
            "Epoch: 82, Batch: 10374, Example: 82500, Loss: 0.002\n",
            "Epoch: 82, Batch: 10399, Example: 82700, Loss: 0.003\n",
            "Epoch: 82, Batch: 10424, Example: 82900, Loss: 0.003\n",
            "Epoch: 82, Batch: 10449, Example: 83100, Loss: 0.005\n",
            "Epoch: 83, Batch: 10474, Example: 83294, Loss: 0.006\n",
            "Epoch: 83, Batch: 10499, Example: 83494, Loss: 0.004\n",
            "Epoch: 83, Batch: 10524, Example: 83694, Loss: 0.005\n",
            "Epoch: 83, Batch: 10549, Example: 83894, Loss: 0.010\n",
            "Epoch: 83, Batch: 10574, Example: 84094, Loss: 0.006\n",
            "Epoch: 84, Batch: 10599, Example: 84288, Loss: 0.001\n",
            "Epoch: 84, Batch: 10624, Example: 84488, Loss: 0.002\n",
            "Epoch: 84, Batch: 10649, Example: 84688, Loss: 0.001\n",
            "Epoch: 84, Batch: 10674, Example: 84888, Loss: 0.003\n",
            "Epoch: 84, Batch: 10699, Example: 85088, Loss: 0.003\n",
            "Epoch: 85, Batch: 10724, Example: 85282, Loss: 0.004\n",
            "Epoch: 85, Batch: 10749, Example: 85482, Loss: 0.018\n",
            "Epoch: 85, Batch: 10774, Example: 85682, Loss: 0.003\n",
            "Epoch: 85, Batch: 10799, Example: 85882, Loss: 0.003\n",
            "Epoch: 85, Batch: 10824, Example: 86082, Loss: 0.006\n",
            "Accuracy of the model at epoch 85: 54.69061876247505%\n",
            "Epoch: 86, Batch: 10849, Example: 86276, Loss: 0.012\n",
            "Epoch: 86, Batch: 10874, Example: 86476, Loss: 0.002\n",
            "Epoch: 86, Batch: 10899, Example: 86676, Loss: 0.001\n",
            "Epoch: 86, Batch: 10924, Example: 86876, Loss: 0.009\n",
            "Epoch: 86, Batch: 10949, Example: 87076, Loss: 0.002\n",
            "Epoch: 87, Batch: 10974, Example: 87270, Loss: 0.002\n",
            "Epoch: 87, Batch: 10999, Example: 87470, Loss: 0.004\n",
            "Epoch: 87, Batch: 11024, Example: 87670, Loss: 0.005\n",
            "Epoch: 87, Batch: 11049, Example: 87870, Loss: 0.009\n",
            "Epoch: 87, Batch: 11074, Example: 88070, Loss: 0.006\n",
            "Epoch: 88, Batch: 11099, Example: 88264, Loss: 0.008\n",
            "Epoch: 88, Batch: 11124, Example: 88464, Loss: 0.002\n",
            "Epoch: 88, Batch: 11149, Example: 88664, Loss: 0.006\n",
            "Epoch: 88, Batch: 11174, Example: 88864, Loss: 0.004\n",
            "Epoch: 88, Batch: 11199, Example: 89064, Loss: 0.003\n",
            "Epoch: 89, Batch: 11224, Example: 89258, Loss: 0.003\n",
            "Epoch: 89, Batch: 11249, Example: 89458, Loss: 0.002\n",
            "Epoch: 89, Batch: 11274, Example: 89658, Loss: 0.004\n",
            "Epoch: 89, Batch: 11299, Example: 89858, Loss: 0.002\n",
            "Epoch: 89, Batch: 11324, Example: 90058, Loss: 0.001\n",
            "Epoch: 90, Batch: 11349, Example: 90252, Loss: 0.001\n",
            "Epoch: 90, Batch: 11374, Example: 90452, Loss: 0.001\n",
            "Epoch: 90, Batch: 11399, Example: 90652, Loss: 0.001\n",
            "Epoch: 90, Batch: 11424, Example: 90852, Loss: 0.002\n",
            "Epoch: 90, Batch: 11449, Example: 91052, Loss: 0.004\n",
            "Accuracy of the model at epoch 90: 69.06187624750498%\n",
            "Epoch: 91, Batch: 11474, Example: 91246, Loss: 0.006\n",
            "Epoch: 91, Batch: 11499, Example: 91446, Loss: 0.002\n",
            "Epoch: 91, Batch: 11524, Example: 91646, Loss: 0.001\n",
            "Epoch: 91, Batch: 11549, Example: 91846, Loss: 0.003\n",
            "Epoch: 91, Batch: 11574, Example: 92046, Loss: 0.002\n",
            "Epoch: 92, Batch: 11599, Example: 92240, Loss: 0.001\n",
            "Epoch: 92, Batch: 11624, Example: 92440, Loss: 0.001\n",
            "Epoch: 92, Batch: 11649, Example: 92640, Loss: 0.002\n",
            "Epoch: 92, Batch: 11674, Example: 92840, Loss: 0.002\n",
            "Epoch: 92, Batch: 11699, Example: 93040, Loss: 0.005\n",
            "Epoch: 93, Batch: 11724, Example: 93234, Loss: 0.001\n",
            "Epoch: 93, Batch: 11749, Example: 93434, Loss: 0.005\n",
            "Epoch: 93, Batch: 11774, Example: 93634, Loss: 0.002\n",
            "Epoch: 93, Batch: 11799, Example: 93834, Loss: 0.002\n",
            "Epoch: 93, Batch: 11824, Example: 94034, Loss: 0.001\n",
            "Epoch: 94, Batch: 11849, Example: 94228, Loss: 0.004\n",
            "Epoch: 94, Batch: 11874, Example: 94428, Loss: 0.002\n",
            "Epoch: 94, Batch: 11899, Example: 94628, Loss: 0.009\n",
            "Epoch: 94, Batch: 11924, Example: 94828, Loss: 0.004\n",
            "Epoch: 94, Batch: 11949, Example: 95028, Loss: 0.005\n",
            "Epoch: 95, Batch: 11974, Example: 95222, Loss: 0.001\n",
            "Epoch: 95, Batch: 11999, Example: 95422, Loss: 0.004\n",
            "Epoch: 95, Batch: 12024, Example: 95622, Loss: 0.003\n",
            "Epoch: 95, Batch: 12049, Example: 95822, Loss: 0.003\n",
            "Epoch: 95, Batch: 12074, Example: 96022, Loss: 0.003\n",
            "Accuracy of the model at epoch 95: 58.28343313373254%\n",
            "Epoch: 96, Batch: 12099, Example: 96216, Loss: 0.001\n",
            "Epoch: 96, Batch: 12124, Example: 96416, Loss: 0.001\n",
            "Epoch: 96, Batch: 12149, Example: 96616, Loss: 0.002\n",
            "Epoch: 96, Batch: 12174, Example: 96816, Loss: 0.003\n",
            "Epoch: 96, Batch: 12199, Example: 97016, Loss: 0.002\n",
            "Epoch: 97, Batch: 12224, Example: 97210, Loss: 0.002\n",
            "Epoch: 97, Batch: 12249, Example: 97410, Loss: 0.003\n",
            "Epoch: 97, Batch: 12274, Example: 97610, Loss: 0.007\n",
            "Epoch: 97, Batch: 12299, Example: 97810, Loss: 0.002\n",
            "Epoch: 97, Batch: 12324, Example: 98010, Loss: 0.005\n",
            "Epoch: 98, Batch: 12349, Example: 98204, Loss: 0.004\n",
            "Epoch: 98, Batch: 12374, Example: 98404, Loss: 0.004\n",
            "Epoch: 98, Batch: 12399, Example: 98604, Loss: 0.002\n",
            "Epoch: 98, Batch: 12424, Example: 98804, Loss: 0.003\n",
            "Epoch: 98, Batch: 12449, Example: 99004, Loss: 0.002\n",
            "Epoch: 98, Batch: 12474, Example: 99198, Loss: 0.001\n",
            "Epoch: 99, Batch: 12499, Example: 99398, Loss: 0.002\n",
            "Epoch: 99, Batch: 12524, Example: 99598, Loss: 0.006\n",
            "Epoch: 99, Batch: 12549, Example: 99798, Loss: 0.003\n",
            "Epoch: 99, Batch: 12574, Example: 99998, Loss: 0.001\n",
            "Epoch: 99, Batch: 12599, Example: 100198, Loss: 0.005\n",
            "Epoch: 100, Batch: 12624, Example: 100392, Loss: 0.002\n",
            "Epoch: 100, Batch: 12649, Example: 100592, Loss: 0.002\n",
            "Epoch: 100, Batch: 12674, Example: 100792, Loss: 0.001\n",
            "Epoch: 100, Batch: 12699, Example: 100992, Loss: 0.003\n",
            "Epoch: 100, Batch: 12724, Example: 101192, Loss: 0.002\n",
            "Accuracy of the model at epoch 100: 72.55489021956087%\n",
            "Epoch: 101, Batch: 12749, Example: 101386, Loss: 0.001\n",
            "Epoch: 101, Batch: 12774, Example: 101586, Loss: 0.002\n",
            "Epoch: 101, Batch: 12799, Example: 101786, Loss: 0.001\n",
            "Epoch: 101, Batch: 12824, Example: 101986, Loss: 0.001\n",
            "Epoch: 101, Batch: 12849, Example: 102186, Loss: 0.001\n",
            "Epoch: 102, Batch: 12874, Example: 102380, Loss: 0.003\n",
            "Epoch: 102, Batch: 12899, Example: 102580, Loss: 0.002\n",
            "Epoch: 102, Batch: 12924, Example: 102780, Loss: 0.004\n",
            "Epoch: 102, Batch: 12949, Example: 102980, Loss: 0.002\n",
            "Epoch: 102, Batch: 12974, Example: 103180, Loss: 0.000\n",
            "Epoch: 103, Batch: 12999, Example: 103374, Loss: 0.002\n",
            "Epoch: 103, Batch: 13024, Example: 103574, Loss: 0.003\n",
            "Epoch: 103, Batch: 13049, Example: 103774, Loss: 0.003\n",
            "Epoch: 103, Batch: 13074, Example: 103974, Loss: 0.002\n",
            "Epoch: 103, Batch: 13099, Example: 104174, Loss: 0.003\n",
            "Epoch: 104, Batch: 13124, Example: 104368, Loss: 0.004\n",
            "Epoch: 104, Batch: 13149, Example: 104568, Loss: 0.005\n",
            "Epoch: 104, Batch: 13174, Example: 104768, Loss: 0.004\n",
            "Epoch: 104, Batch: 13199, Example: 104968, Loss: 0.002\n",
            "Epoch: 104, Batch: 13224, Example: 105168, Loss: 0.001\n",
            "Epoch: 105, Batch: 13249, Example: 105362, Loss: 0.001\n",
            "Epoch: 105, Batch: 13274, Example: 105562, Loss: 0.003\n",
            "Epoch: 105, Batch: 13299, Example: 105762, Loss: 0.000\n",
            "Epoch: 105, Batch: 13324, Example: 105962, Loss: 0.001\n",
            "Epoch: 105, Batch: 13349, Example: 106162, Loss: 0.004\n",
            "Accuracy of the model at epoch 105: 67.76447105788424%\n",
            "Epoch: 106, Batch: 13374, Example: 106356, Loss: 0.001\n",
            "Epoch: 106, Batch: 13399, Example: 106556, Loss: 0.002\n",
            "Epoch: 106, Batch: 13424, Example: 106756, Loss: 0.003\n",
            "Epoch: 106, Batch: 13449, Example: 106956, Loss: 0.002\n",
            "Epoch: 106, Batch: 13474, Example: 107156, Loss: 0.003\n",
            "Epoch: 107, Batch: 13499, Example: 107350, Loss: 0.003\n",
            "Epoch: 107, Batch: 13524, Example: 107550, Loss: 0.005\n",
            "Epoch: 107, Batch: 13549, Example: 107750, Loss: 0.003\n",
            "Epoch: 107, Batch: 13574, Example: 107950, Loss: 0.002\n",
            "Epoch: 107, Batch: 13599, Example: 108150, Loss: 0.002\n",
            "Epoch: 108, Batch: 13624, Example: 108344, Loss: 0.003\n",
            "Epoch: 108, Batch: 13649, Example: 108544, Loss: 0.001\n",
            "Epoch: 108, Batch: 13674, Example: 108744, Loss: 0.002\n",
            "Epoch: 108, Batch: 13699, Example: 108944, Loss: 0.002\n",
            "Epoch: 108, Batch: 13724, Example: 109144, Loss: 0.002\n",
            "Epoch: 109, Batch: 13749, Example: 109338, Loss: 0.001\n",
            "Epoch: 109, Batch: 13774, Example: 109538, Loss: 0.002\n",
            "Epoch: 109, Batch: 13799, Example: 109738, Loss: 0.001\n",
            "Epoch: 109, Batch: 13824, Example: 109938, Loss: 0.003\n",
            "Epoch: 109, Batch: 13849, Example: 110138, Loss: 0.003\n",
            "Epoch: 110, Batch: 13874, Example: 110332, Loss: 0.002\n",
            "Epoch: 110, Batch: 13899, Example: 110532, Loss: 0.002\n",
            "Epoch: 110, Batch: 13924, Example: 110732, Loss: 0.002\n",
            "Epoch: 110, Batch: 13949, Example: 110932, Loss: 0.001\n",
            "Epoch: 110, Batch: 13974, Example: 111132, Loss: 0.003\n",
            "Accuracy of the model at epoch 110: 43.51297405189621%\n",
            "Epoch: 111, Batch: 13999, Example: 111326, Loss: 0.002\n",
            "Epoch: 111, Batch: 14024, Example: 111526, Loss: 0.002\n",
            "Epoch: 111, Batch: 14049, Example: 111726, Loss: 0.001\n",
            "Epoch: 111, Batch: 14074, Example: 111926, Loss: 0.002\n",
            "Epoch: 111, Batch: 14099, Example: 112126, Loss: 0.002\n",
            "Epoch: 112, Batch: 14124, Example: 112320, Loss: 0.005\n",
            "Epoch: 112, Batch: 14149, Example: 112520, Loss: 0.009\n",
            "Epoch: 112, Batch: 14174, Example: 112720, Loss: 0.002\n",
            "Epoch: 112, Batch: 14199, Example: 112920, Loss: 0.003\n",
            "Epoch: 112, Batch: 14224, Example: 113120, Loss: 0.004\n",
            "Epoch: 113, Batch: 14249, Example: 113314, Loss: 0.001\n",
            "Epoch: 113, Batch: 14274, Example: 113514, Loss: 0.003\n",
            "Epoch: 113, Batch: 14299, Example: 113714, Loss: 0.001\n",
            "Epoch: 113, Batch: 14324, Example: 113914, Loss: 0.002\n",
            "Epoch: 113, Batch: 14349, Example: 114114, Loss: 0.002\n",
            "Epoch: 114, Batch: 14374, Example: 114308, Loss: 0.006\n",
            "Epoch: 114, Batch: 14399, Example: 114508, Loss: 0.001\n",
            "Epoch: 114, Batch: 14424, Example: 114708, Loss: 0.001\n",
            "Epoch: 114, Batch: 14449, Example: 114908, Loss: 0.002\n",
            "Epoch: 114, Batch: 14474, Example: 115108, Loss: 0.003\n",
            "Epoch: 115, Batch: 14499, Example: 115302, Loss: 0.002\n",
            "Epoch: 115, Batch: 14524, Example: 115502, Loss: 0.001\n",
            "Epoch: 115, Batch: 14549, Example: 115702, Loss: 0.002\n",
            "Epoch: 115, Batch: 14574, Example: 115902, Loss: 0.000\n",
            "Epoch: 115, Batch: 14599, Example: 116102, Loss: 0.003\n",
            "Accuracy of the model at epoch 115: 72.75449101796407%\n",
            "Epoch: 116, Batch: 14624, Example: 116296, Loss: 0.002\n",
            "Epoch: 116, Batch: 14649, Example: 116496, Loss: 0.001\n",
            "Epoch: 116, Batch: 14674, Example: 116696, Loss: 0.001\n",
            "Epoch: 116, Batch: 14699, Example: 116896, Loss: 0.001\n",
            "Epoch: 116, Batch: 14724, Example: 117096, Loss: 0.001\n",
            "Epoch: 117, Batch: 14749, Example: 117290, Loss: 0.004\n",
            "Epoch: 117, Batch: 14774, Example: 117490, Loss: 0.001\n",
            "Epoch: 117, Batch: 14799, Example: 117690, Loss: 0.001\n",
            "Epoch: 117, Batch: 14824, Example: 117890, Loss: 0.002\n",
            "Epoch: 117, Batch: 14849, Example: 118090, Loss: 0.002\n",
            "Epoch: 118, Batch: 14874, Example: 118284, Loss: 0.002\n",
            "Epoch: 118, Batch: 14899, Example: 118484, Loss: 0.003\n",
            "Epoch: 118, Batch: 14924, Example: 118684, Loss: 0.005\n",
            "Epoch: 118, Batch: 14949, Example: 118884, Loss: 0.004\n",
            "Epoch: 118, Batch: 14974, Example: 119084, Loss: 0.002\n",
            "Epoch: 119, Batch: 14999, Example: 119278, Loss: 0.001\n",
            "Epoch: 119, Batch: 15024, Example: 119478, Loss: 0.005\n",
            "Epoch: 119, Batch: 15049, Example: 119678, Loss: 0.002\n",
            "Epoch: 119, Batch: 15074, Example: 119878, Loss: 0.004\n",
            "Epoch: 119, Batch: 15099, Example: 120078, Loss: 0.001\n",
            "Epoch: 120, Batch: 15124, Example: 120272, Loss: 0.007\n",
            "Epoch: 120, Batch: 15149, Example: 120472, Loss: 0.001\n",
            "Epoch: 120, Batch: 15174, Example: 120672, Loss: 0.003\n",
            "Epoch: 120, Batch: 15199, Example: 120872, Loss: 0.002\n",
            "Epoch: 120, Batch: 15224, Example: 121072, Loss: 0.003\n",
            "Accuracy of the model at epoch 120: 63.87225548902195%\n",
            "Epoch: 121, Batch: 15249, Example: 121266, Loss: 0.003\n",
            "Epoch: 121, Batch: 15274, Example: 121466, Loss: 0.002\n",
            "Epoch: 121, Batch: 15299, Example: 121666, Loss: 0.002\n",
            "Epoch: 121, Batch: 15324, Example: 121866, Loss: 0.004\n",
            "Epoch: 121, Batch: 15349, Example: 122066, Loss: 0.001\n",
            "Epoch: 122, Batch: 15374, Example: 122260, Loss: 0.002\n",
            "Epoch: 122, Batch: 15399, Example: 122460, Loss: 0.003\n",
            "Epoch: 122, Batch: 15424, Example: 122660, Loss: 0.003\n",
            "Epoch: 122, Batch: 15449, Example: 122860, Loss: 0.001\n",
            "Epoch: 122, Batch: 15474, Example: 123060, Loss: 0.000\n",
            "Epoch: 123, Batch: 15499, Example: 123254, Loss: 0.001\n",
            "Epoch: 123, Batch: 15524, Example: 123454, Loss: 0.002\n",
            "Epoch: 123, Batch: 15549, Example: 123654, Loss: 0.001\n",
            "Epoch: 123, Batch: 15574, Example: 123854, Loss: 0.003\n",
            "Epoch: 123, Batch: 15599, Example: 124054, Loss: 0.001\n",
            "Epoch: 123, Batch: 15624, Example: 124248, Loss: 0.004\n",
            "Epoch: 124, Batch: 15649, Example: 124448, Loss: 0.003\n",
            "Epoch: 124, Batch: 15674, Example: 124648, Loss: 0.002\n",
            "Epoch: 124, Batch: 15699, Example: 124848, Loss: 0.001\n",
            "Epoch: 124, Batch: 15724, Example: 125048, Loss: 0.004\n",
            "Epoch: 124, Batch: 15749, Example: 125248, Loss: 0.001\n",
            "Epoch: 125, Batch: 15774, Example: 125442, Loss: 0.001\n",
            "Epoch: 125, Batch: 15799, Example: 125642, Loss: 0.003\n",
            "Epoch: 125, Batch: 15824, Example: 125842, Loss: 0.002\n",
            "Epoch: 125, Batch: 15849, Example: 126042, Loss: 0.002\n",
            "Epoch: 125, Batch: 15874, Example: 126242, Loss: 0.001\n",
            "Accuracy of the model at epoch 125: 85.12974051896208%\n",
            "Epoch: 126, Batch: 15899, Example: 126436, Loss: 0.001\n",
            "Epoch: 126, Batch: 15924, Example: 126636, Loss: 0.004\n",
            "Epoch: 126, Batch: 15949, Example: 126836, Loss: 0.002\n",
            "Epoch: 126, Batch: 15974, Example: 127036, Loss: 0.004\n",
            "Epoch: 126, Batch: 15999, Example: 127236, Loss: 0.003\n",
            "Epoch: 127, Batch: 16024, Example: 127430, Loss: 0.003\n",
            "Epoch: 127, Batch: 16049, Example: 127630, Loss: 0.002\n",
            "Epoch: 127, Batch: 16074, Example: 127830, Loss: 0.002\n",
            "Epoch: 127, Batch: 16099, Example: 128030, Loss: 0.002\n",
            "Epoch: 127, Batch: 16124, Example: 128230, Loss: 0.003\n",
            "Epoch: 128, Batch: 16149, Example: 128424, Loss: 0.002\n",
            "Epoch: 128, Batch: 16174, Example: 128624, Loss: 0.001\n",
            "Epoch: 128, Batch: 16199, Example: 128824, Loss: 0.003\n",
            "Epoch: 128, Batch: 16224, Example: 129024, Loss: 0.001\n",
            "Epoch: 128, Batch: 16249, Example: 129224, Loss: 0.002\n",
            "Epoch: 129, Batch: 16274, Example: 129418, Loss: 0.001\n",
            "Epoch: 129, Batch: 16299, Example: 129618, Loss: 0.002\n",
            "Epoch: 129, Batch: 16324, Example: 129818, Loss: 0.002\n",
            "Epoch: 129, Batch: 16349, Example: 130018, Loss: 0.001\n",
            "Epoch: 129, Batch: 16374, Example: 130218, Loss: 0.001\n",
            "Epoch: 130, Batch: 16399, Example: 130412, Loss: 0.003\n",
            "Epoch: 130, Batch: 16424, Example: 130612, Loss: 0.002\n",
            "Epoch: 130, Batch: 16449, Example: 130812, Loss: 0.001\n",
            "Epoch: 130, Batch: 16474, Example: 131012, Loss: 0.002\n",
            "Epoch: 130, Batch: 16499, Example: 131212, Loss: 0.001\n",
            "Accuracy of the model at epoch 130: 80.73852295409182%\n",
            "Epoch: 131, Batch: 16524, Example: 131406, Loss: 0.001\n",
            "Epoch: 131, Batch: 16549, Example: 131606, Loss: 0.002\n",
            "Epoch: 131, Batch: 16574, Example: 131806, Loss: 0.001\n",
            "Epoch: 131, Batch: 16599, Example: 132006, Loss: 0.002\n",
            "Epoch: 131, Batch: 16624, Example: 132206, Loss: 0.002\n",
            "Epoch: 132, Batch: 16649, Example: 132400, Loss: 0.002\n",
            "Epoch: 132, Batch: 16674, Example: 132600, Loss: 0.002\n",
            "Epoch: 132, Batch: 16699, Example: 132800, Loss: 0.002\n",
            "Epoch: 132, Batch: 16724, Example: 133000, Loss: 0.002\n",
            "Epoch: 132, Batch: 16749, Example: 133200, Loss: 0.001\n",
            "Epoch: 133, Batch: 16774, Example: 133394, Loss: 0.002\n",
            "Epoch: 133, Batch: 16799, Example: 133594, Loss: 0.002\n",
            "Epoch: 133, Batch: 16824, Example: 133794, Loss: 0.001\n",
            "Epoch: 133, Batch: 16849, Example: 133994, Loss: 0.001\n",
            "Epoch: 133, Batch: 16874, Example: 134194, Loss: 0.001\n",
            "Epoch: 134, Batch: 16899, Example: 134388, Loss: 0.001\n",
            "Epoch: 134, Batch: 16924, Example: 134588, Loss: 0.002\n",
            "Epoch: 134, Batch: 16949, Example: 134788, Loss: 0.001\n",
            "Epoch: 134, Batch: 16974, Example: 134988, Loss: 0.001\n",
            "Epoch: 134, Batch: 16999, Example: 135188, Loss: 0.002\n",
            "Epoch: 135, Batch: 17024, Example: 135382, Loss: 0.001\n",
            "Epoch: 135, Batch: 17049, Example: 135582, Loss: 0.003\n",
            "Epoch: 135, Batch: 17074, Example: 135782, Loss: 0.001\n",
            "Epoch: 135, Batch: 17099, Example: 135982, Loss: 0.001\n",
            "Epoch: 135, Batch: 17124, Example: 136182, Loss: 0.002\n",
            "Accuracy of the model at epoch 135: 75.1497005988024%\n",
            "Epoch: 136, Batch: 17149, Example: 136376, Loss: 0.001\n",
            "Epoch: 136, Batch: 17174, Example: 136576, Loss: 0.002\n",
            "Epoch: 136, Batch: 17199, Example: 136776, Loss: 0.002\n",
            "Epoch: 136, Batch: 17224, Example: 136976, Loss: 0.003\n",
            "Epoch: 136, Batch: 17249, Example: 137176, Loss: 0.002\n",
            "Epoch: 137, Batch: 17274, Example: 137370, Loss: 0.003\n",
            "Epoch: 137, Batch: 17299, Example: 137570, Loss: 0.002\n",
            "Epoch: 137, Batch: 17324, Example: 137770, Loss: 0.001\n",
            "Epoch: 137, Batch: 17349, Example: 137970, Loss: 0.000\n",
            "Epoch: 137, Batch: 17374, Example: 138170, Loss: 0.002\n",
            "Epoch: 138, Batch: 17399, Example: 138364, Loss: 0.001\n",
            "Epoch: 138, Batch: 17424, Example: 138564, Loss: 0.001\n",
            "Epoch: 138, Batch: 17449, Example: 138764, Loss: 0.000\n",
            "Epoch: 138, Batch: 17474, Example: 138964, Loss: 0.001\n",
            "Epoch: 138, Batch: 17499, Example: 139164, Loss: 0.001\n",
            "Epoch: 139, Batch: 17524, Example: 139358, Loss: 0.000\n",
            "Epoch: 139, Batch: 17549, Example: 139558, Loss: 0.001\n",
            "Epoch: 139, Batch: 17574, Example: 139758, Loss: 0.004\n",
            "Epoch: 139, Batch: 17599, Example: 139958, Loss: 0.002\n",
            "Epoch: 139, Batch: 17624, Example: 140158, Loss: 0.005\n",
            "Epoch: 140, Batch: 17649, Example: 140352, Loss: 0.004\n",
            "Epoch: 140, Batch: 17674, Example: 140552, Loss: 0.002\n",
            "Epoch: 140, Batch: 17699, Example: 140752, Loss: 0.001\n",
            "Epoch: 140, Batch: 17724, Example: 140952, Loss: 0.003\n",
            "Epoch: 140, Batch: 17749, Example: 141152, Loss: 0.003\n",
            "Accuracy of the model at epoch 140: 80.83832335329342%\n",
            "Epoch: 141, Batch: 17774, Example: 141346, Loss: 0.004\n",
            "Epoch: 141, Batch: 17799, Example: 141546, Loss: 0.001\n",
            "Epoch: 141, Batch: 17824, Example: 141746, Loss: 0.000\n",
            "Epoch: 141, Batch: 17849, Example: 141946, Loss: 0.001\n",
            "Epoch: 141, Batch: 17874, Example: 142146, Loss: 0.000\n",
            "Epoch: 142, Batch: 17899, Example: 142340, Loss: 0.002\n",
            "Epoch: 142, Batch: 17924, Example: 142540, Loss: 0.001\n",
            "Epoch: 142, Batch: 17949, Example: 142740, Loss: 0.001\n",
            "Epoch: 142, Batch: 17974, Example: 142940, Loss: 0.002\n",
            "Epoch: 142, Batch: 17999, Example: 143140, Loss: 0.003\n",
            "Epoch: 143, Batch: 18024, Example: 143334, Loss: 0.002\n",
            "Epoch: 143, Batch: 18049, Example: 143534, Loss: 0.001\n",
            "Epoch: 143, Batch: 18074, Example: 143734, Loss: 0.001\n",
            "Epoch: 143, Batch: 18099, Example: 143934, Loss: 0.002\n",
            "Epoch: 143, Batch: 18124, Example: 144134, Loss: 0.001\n",
            "Epoch: 144, Batch: 18149, Example: 144328, Loss: 0.002\n",
            "Epoch: 144, Batch: 18174, Example: 144528, Loss: 0.001\n",
            "Epoch: 144, Batch: 18199, Example: 144728, Loss: 0.001\n",
            "Epoch: 144, Batch: 18224, Example: 144928, Loss: 0.001\n",
            "Epoch: 144, Batch: 18249, Example: 145128, Loss: 0.001\n",
            "Epoch: 145, Batch: 18274, Example: 145322, Loss: 0.000\n",
            "Epoch: 145, Batch: 18299, Example: 145522, Loss: 0.002\n",
            "Epoch: 145, Batch: 18324, Example: 145722, Loss: 0.004\n",
            "Epoch: 145, Batch: 18349, Example: 145922, Loss: 0.002\n",
            "Epoch: 145, Batch: 18374, Example: 146122, Loss: 0.002\n",
            "Accuracy of the model at epoch 145: 79.14171656686626%\n",
            "Epoch: 146, Batch: 18399, Example: 146316, Loss: 0.001\n",
            "Epoch: 146, Batch: 18424, Example: 146516, Loss: 0.002\n",
            "Epoch: 146, Batch: 18449, Example: 146716, Loss: 0.002\n",
            "Epoch: 146, Batch: 18474, Example: 146916, Loss: 0.002\n",
            "Epoch: 146, Batch: 18499, Example: 147116, Loss: 0.001\n",
            "Epoch: 147, Batch: 18524, Example: 147310, Loss: 0.001\n",
            "Epoch: 147, Batch: 18549, Example: 147510, Loss: 0.001\n",
            "Epoch: 147, Batch: 18574, Example: 147710, Loss: 0.002\n",
            "Epoch: 147, Batch: 18599, Example: 147910, Loss: 0.000\n",
            "Epoch: 147, Batch: 18624, Example: 148110, Loss: 0.002\n",
            "Epoch: 148, Batch: 18649, Example: 148304, Loss: 0.001\n",
            "Epoch: 148, Batch: 18674, Example: 148504, Loss: 0.001\n",
            "Epoch: 148, Batch: 18699, Example: 148704, Loss: 0.002\n",
            "Epoch: 148, Batch: 18724, Example: 148904, Loss: 0.001\n",
            "Epoch: 148, Batch: 18749, Example: 149104, Loss: 0.002\n",
            "Epoch: 148, Batch: 18774, Example: 149298, Loss: 0.000\n",
            "Epoch: 149, Batch: 18799, Example: 149498, Loss: 0.001\n",
            "Epoch: 149, Batch: 18824, Example: 149698, Loss: 0.002\n",
            "Epoch: 149, Batch: 18849, Example: 149898, Loss: 0.001\n",
            "Epoch: 149, Batch: 18874, Example: 150098, Loss: 0.001\n",
            "Epoch: 149, Batch: 18899, Example: 150298, Loss: 0.001\n",
            "Epoch: 150, Batch: 18924, Example: 150492, Loss: 0.001\n",
            "Epoch: 150, Batch: 18949, Example: 150692, Loss: 0.000\n",
            "Epoch: 150, Batch: 18974, Example: 150892, Loss: 0.002\n",
            "Epoch: 150, Batch: 18999, Example: 151092, Loss: 0.002\n",
            "Epoch: 150, Batch: 19024, Example: 151292, Loss: 0.002\n",
            "Accuracy of the model at epoch 150: 70.75848303393214%\n",
            "Epoch: 151, Batch: 19049, Example: 151486, Loss: 0.001\n",
            "Epoch: 151, Batch: 19074, Example: 151686, Loss: 0.001\n",
            "Epoch: 151, Batch: 19099, Example: 151886, Loss: 0.001\n",
            "Epoch: 151, Batch: 19124, Example: 152086, Loss: 0.001\n",
            "Epoch: 151, Batch: 19149, Example: 152286, Loss: 0.001\n",
            "Epoch: 152, Batch: 19174, Example: 152480, Loss: 0.001\n",
            "Epoch: 152, Batch: 19199, Example: 152680, Loss: 0.001\n",
            "Epoch: 152, Batch: 19224, Example: 152880, Loss: 0.002\n",
            "Epoch: 152, Batch: 19249, Example: 153080, Loss: 0.000\n",
            "Epoch: 152, Batch: 19274, Example: 153280, Loss: 0.001\n",
            "Epoch: 153, Batch: 19299, Example: 153474, Loss: 0.002\n",
            "Epoch: 153, Batch: 19324, Example: 153674, Loss: 0.002\n",
            "Epoch: 153, Batch: 19349, Example: 153874, Loss: 0.001\n",
            "Epoch: 153, Batch: 19374, Example: 154074, Loss: 0.001\n",
            "Epoch: 153, Batch: 19399, Example: 154274, Loss: 0.002\n",
            "Epoch: 154, Batch: 19424, Example: 154468, Loss: 0.002\n",
            "Epoch: 154, Batch: 19449, Example: 154668, Loss: 0.001\n",
            "Epoch: 154, Batch: 19474, Example: 154868, Loss: 0.001\n",
            "Epoch: 154, Batch: 19499, Example: 155068, Loss: 0.001\n",
            "Epoch: 154, Batch: 19524, Example: 155268, Loss: 0.000\n",
            "Epoch: 155, Batch: 19549, Example: 155462, Loss: 0.001\n",
            "Epoch: 155, Batch: 19574, Example: 155662, Loss: 0.002\n",
            "Epoch: 155, Batch: 19599, Example: 155862, Loss: 0.001\n",
            "Epoch: 155, Batch: 19624, Example: 156062, Loss: 0.002\n",
            "Epoch: 155, Batch: 19649, Example: 156262, Loss: 0.001\n",
            "Accuracy of the model at epoch 155: 91.91616766467065%\n",
            "Epoch: 156, Batch: 19674, Example: 156456, Loss: 0.002\n",
            "Epoch: 156, Batch: 19699, Example: 156656, Loss: 0.002\n",
            "Epoch: 156, Batch: 19724, Example: 156856, Loss: 0.002\n",
            "Epoch: 156, Batch: 19749, Example: 157056, Loss: 0.001\n",
            "Epoch: 156, Batch: 19774, Example: 157256, Loss: 0.001\n",
            "Epoch: 157, Batch: 19799, Example: 157450, Loss: 0.001\n",
            "Epoch: 157, Batch: 19824, Example: 157650, Loss: 0.001\n",
            "Epoch: 157, Batch: 19849, Example: 157850, Loss: 0.001\n",
            "Epoch: 157, Batch: 19874, Example: 158050, Loss: 0.001\n",
            "Epoch: 157, Batch: 19899, Example: 158250, Loss: 0.001\n",
            "Epoch: 158, Batch: 19924, Example: 158444, Loss: 0.001\n",
            "Epoch: 158, Batch: 19949, Example: 158644, Loss: 0.001\n",
            "Epoch: 158, Batch: 19974, Example: 158844, Loss: 0.001\n",
            "Epoch: 158, Batch: 19999, Example: 159044, Loss: 0.001\n",
            "Epoch: 158, Batch: 20024, Example: 159244, Loss: 0.002\n",
            "Epoch: 159, Batch: 20049, Example: 159438, Loss: 0.001\n",
            "Epoch: 159, Batch: 20074, Example: 159638, Loss: 0.003\n",
            "Epoch: 159, Batch: 20099, Example: 159838, Loss: 0.001\n",
            "Epoch: 159, Batch: 20124, Example: 160038, Loss: 0.005\n",
            "Epoch: 159, Batch: 20149, Example: 160238, Loss: 0.001\n",
            "Epoch: 160, Batch: 20174, Example: 160432, Loss: 0.001\n",
            "Epoch: 160, Batch: 20199, Example: 160632, Loss: 0.002\n",
            "Epoch: 160, Batch: 20224, Example: 160832, Loss: 0.001\n",
            "Epoch: 160, Batch: 20249, Example: 161032, Loss: 0.001\n",
            "Epoch: 160, Batch: 20274, Example: 161232, Loss: 0.001\n",
            "Accuracy of the model at epoch 160: 83.53293413173652%\n",
            "Epoch: 161, Batch: 20299, Example: 161426, Loss: 0.002\n",
            "Epoch: 161, Batch: 20324, Example: 161626, Loss: 0.001\n",
            "Epoch: 161, Batch: 20349, Example: 161826, Loss: 0.001\n",
            "Epoch: 161, Batch: 20374, Example: 162026, Loss: 0.001\n",
            "Epoch: 161, Batch: 20399, Example: 162226, Loss: 0.002\n",
            "Epoch: 162, Batch: 20424, Example: 162420, Loss: 0.000\n",
            "Epoch: 162, Batch: 20449, Example: 162620, Loss: 0.001\n",
            "Epoch: 162, Batch: 20474, Example: 162820, Loss: 0.001\n",
            "Epoch: 162, Batch: 20499, Example: 163020, Loss: 0.002\n",
            "Epoch: 162, Batch: 20524, Example: 163220, Loss: 0.001\n",
            "Epoch: 163, Batch: 20549, Example: 163414, Loss: 0.001\n",
            "Epoch: 163, Batch: 20574, Example: 163614, Loss: 0.001\n",
            "Epoch: 163, Batch: 20599, Example: 163814, Loss: 0.001\n",
            "Epoch: 163, Batch: 20624, Example: 164014, Loss: 0.001\n",
            "Epoch: 163, Batch: 20649, Example: 164214, Loss: 0.002\n",
            "Epoch: 164, Batch: 20674, Example: 164408, Loss: 0.001\n",
            "Epoch: 164, Batch: 20699, Example: 164608, Loss: 0.002\n",
            "Epoch: 164, Batch: 20724, Example: 164808, Loss: 0.002\n",
            "Epoch: 164, Batch: 20749, Example: 165008, Loss: 0.002\n",
            "Epoch: 164, Batch: 20774, Example: 165208, Loss: 0.001\n",
            "Epoch: 165, Batch: 20799, Example: 165402, Loss: 0.005\n",
            "Epoch: 165, Batch: 20824, Example: 165602, Loss: 0.002\n",
            "Epoch: 165, Batch: 20849, Example: 165802, Loss: 0.000\n",
            "Epoch: 165, Batch: 20874, Example: 166002, Loss: 0.000\n",
            "Epoch: 165, Batch: 20899, Example: 166202, Loss: 0.001\n",
            "Accuracy of the model at epoch 165: 88.32335329341318%\n",
            "Epoch: 166, Batch: 20924, Example: 166396, Loss: 0.000\n",
            "Epoch: 166, Batch: 20949, Example: 166596, Loss: 0.001\n",
            "Epoch: 166, Batch: 20974, Example: 166796, Loss: 0.001\n",
            "Epoch: 166, Batch: 20999, Example: 166996, Loss: 0.000\n",
            "Epoch: 166, Batch: 21024, Example: 167196, Loss: 0.001\n",
            "Epoch: 167, Batch: 21049, Example: 167390, Loss: 0.004\n",
            "Epoch: 167, Batch: 21074, Example: 167590, Loss: 0.002\n",
            "Epoch: 167, Batch: 21099, Example: 167790, Loss: 0.002\n",
            "Epoch: 167, Batch: 21124, Example: 167990, Loss: 0.001\n",
            "Epoch: 167, Batch: 21149, Example: 168190, Loss: 0.002\n",
            "Epoch: 168, Batch: 21174, Example: 168384, Loss: 0.001\n",
            "Epoch: 168, Batch: 21199, Example: 168584, Loss: 0.001\n",
            "Epoch: 168, Batch: 21224, Example: 168784, Loss: 0.000\n",
            "Epoch: 168, Batch: 21249, Example: 168984, Loss: 0.001\n",
            "Epoch: 168, Batch: 21274, Example: 169184, Loss: 0.001\n",
            "Epoch: 169, Batch: 21299, Example: 169378, Loss: 0.001\n",
            "Epoch: 169, Batch: 21324, Example: 169578, Loss: 0.001\n",
            "Epoch: 169, Batch: 21349, Example: 169778, Loss: 0.001\n",
            "Epoch: 169, Batch: 21374, Example: 169978, Loss: 0.001\n",
            "Epoch: 169, Batch: 21399, Example: 170178, Loss: 0.001\n",
            "Epoch: 170, Batch: 21424, Example: 170372, Loss: 0.001\n",
            "Epoch: 170, Batch: 21449, Example: 170572, Loss: 0.001\n",
            "Epoch: 170, Batch: 21474, Example: 170772, Loss: 0.001\n",
            "Epoch: 170, Batch: 21499, Example: 170972, Loss: 0.001\n",
            "Epoch: 170, Batch: 21524, Example: 171172, Loss: 0.002\n",
            "Accuracy of the model at epoch 170: 77.8443113772455%\n",
            "Epoch: 171, Batch: 21549, Example: 171366, Loss: 0.003\n",
            "Epoch: 171, Batch: 21574, Example: 171566, Loss: 0.000\n",
            "Epoch: 171, Batch: 21599, Example: 171766, Loss: 0.001\n",
            "Epoch: 171, Batch: 21624, Example: 171966, Loss: 0.000\n",
            "Epoch: 171, Batch: 21649, Example: 172166, Loss: 0.001\n",
            "Epoch: 172, Batch: 21674, Example: 172360, Loss: 0.002\n",
            "Epoch: 172, Batch: 21699, Example: 172560, Loss: 0.000\n",
            "Epoch: 172, Batch: 21724, Example: 172760, Loss: 0.001\n",
            "Epoch: 172, Batch: 21749, Example: 172960, Loss: 0.001\n",
            "Epoch: 172, Batch: 21774, Example: 173160, Loss: 0.001\n",
            "Epoch: 173, Batch: 21799, Example: 173354, Loss: 0.003\n",
            "Epoch: 173, Batch: 21824, Example: 173554, Loss: 0.001\n",
            "Epoch: 173, Batch: 21849, Example: 173754, Loss: 0.001\n",
            "Epoch: 173, Batch: 21874, Example: 173954, Loss: 0.002\n",
            "Epoch: 173, Batch: 21899, Example: 174154, Loss: 0.000\n",
            "Epoch: 173, Batch: 21924, Example: 174348, Loss: 0.002\n",
            "Epoch: 174, Batch: 21949, Example: 174548, Loss: 0.001\n",
            "Epoch: 174, Batch: 21974, Example: 174748, Loss: 0.001\n",
            "Epoch: 174, Batch: 21999, Example: 174948, Loss: 0.001\n",
            "Epoch: 174, Batch: 22024, Example: 175148, Loss: 0.000\n",
            "Epoch: 174, Batch: 22049, Example: 175348, Loss: 0.002\n",
            "Epoch: 175, Batch: 22074, Example: 175542, Loss: 0.004\n",
            "Epoch: 175, Batch: 22099, Example: 175742, Loss: 0.001\n",
            "Epoch: 175, Batch: 22124, Example: 175942, Loss: 0.001\n",
            "Epoch: 175, Batch: 22149, Example: 176142, Loss: 0.001\n",
            "Epoch: 175, Batch: 22174, Example: 176342, Loss: 0.001\n",
            "Accuracy of the model at epoch 175: 83.73253493013972%\n",
            "Epoch: 176, Batch: 22199, Example: 176536, Loss: 0.001\n",
            "Epoch: 176, Batch: 22224, Example: 176736, Loss: 0.001\n",
            "Epoch: 176, Batch: 22249, Example: 176936, Loss: 0.001\n",
            "Epoch: 176, Batch: 22274, Example: 177136, Loss: 0.001\n",
            "Epoch: 176, Batch: 22299, Example: 177336, Loss: 0.001\n",
            "Epoch: 177, Batch: 22324, Example: 177530, Loss: 0.002\n",
            "Epoch: 177, Batch: 22349, Example: 177730, Loss: 0.001\n",
            "Epoch: 177, Batch: 22374, Example: 177930, Loss: 0.003\n",
            "Epoch: 177, Batch: 22399, Example: 178130, Loss: 0.001\n",
            "Epoch: 177, Batch: 22424, Example: 178330, Loss: 0.001\n",
            "Epoch: 178, Batch: 22449, Example: 178524, Loss: 0.001\n",
            "Epoch: 178, Batch: 22474, Example: 178724, Loss: 0.003\n",
            "Epoch: 178, Batch: 22499, Example: 178924, Loss: 0.001\n",
            "Epoch: 178, Batch: 22524, Example: 179124, Loss: 0.001\n",
            "Epoch: 178, Batch: 22549, Example: 179324, Loss: 0.001\n",
            "Epoch: 179, Batch: 22574, Example: 179518, Loss: 0.001\n",
            "Epoch: 179, Batch: 22599, Example: 179718, Loss: 0.000\n",
            "Epoch: 179, Batch: 22624, Example: 179918, Loss: 0.001\n",
            "Epoch: 179, Batch: 22649, Example: 180118, Loss: 0.001\n",
            "Epoch: 179, Batch: 22674, Example: 180318, Loss: 0.001\n",
            "Epoch: 180, Batch: 22699, Example: 180512, Loss: 0.001\n",
            "Epoch: 180, Batch: 22724, Example: 180712, Loss: 0.001\n",
            "Epoch: 180, Batch: 22749, Example: 180912, Loss: 0.001\n",
            "Epoch: 180, Batch: 22774, Example: 181112, Loss: 0.001\n",
            "Epoch: 180, Batch: 22799, Example: 181312, Loss: 0.001\n",
            "Accuracy of the model at epoch 180: 89.12175648702595%\n",
            "Epoch: 181, Batch: 22824, Example: 181506, Loss: 0.001\n",
            "Epoch: 181, Batch: 22849, Example: 181706, Loss: 0.001\n",
            "Epoch: 181, Batch: 22874, Example: 181906, Loss: 0.001\n",
            "Epoch: 181, Batch: 22899, Example: 182106, Loss: 0.001\n",
            "Epoch: 181, Batch: 22924, Example: 182306, Loss: 0.001\n",
            "Epoch: 182, Batch: 22949, Example: 182500, Loss: 0.000\n",
            "Epoch: 182, Batch: 22974, Example: 182700, Loss: 0.002\n",
            "Epoch: 182, Batch: 22999, Example: 182900, Loss: 0.001\n",
            "Epoch: 182, Batch: 23024, Example: 183100, Loss: 0.002\n",
            "Epoch: 182, Batch: 23049, Example: 183300, Loss: 0.001\n",
            "Epoch: 183, Batch: 23074, Example: 183494, Loss: 0.000\n",
            "Epoch: 183, Batch: 23099, Example: 183694, Loss: 0.001\n",
            "Epoch: 183, Batch: 23124, Example: 183894, Loss: 0.003\n",
            "Epoch: 183, Batch: 23149, Example: 184094, Loss: 0.001\n",
            "Epoch: 183, Batch: 23174, Example: 184294, Loss: 0.001\n",
            "Epoch: 184, Batch: 23199, Example: 184488, Loss: 0.002\n",
            "Epoch: 184, Batch: 23224, Example: 184688, Loss: 0.001\n",
            "Epoch: 184, Batch: 23249, Example: 184888, Loss: 0.003\n",
            "Epoch: 184, Batch: 23274, Example: 185088, Loss: 0.001\n",
            "Epoch: 184, Batch: 23299, Example: 185288, Loss: 0.001\n",
            "Epoch: 185, Batch: 23324, Example: 185482, Loss: 0.001\n",
            "Epoch: 185, Batch: 23349, Example: 185682, Loss: 0.002\n",
            "Epoch: 185, Batch: 23374, Example: 185882, Loss: 0.001\n",
            "Epoch: 185, Batch: 23399, Example: 186082, Loss: 0.002\n",
            "Epoch: 185, Batch: 23424, Example: 186282, Loss: 0.002\n",
            "Accuracy of the model at epoch 185: 84.3313373253493%\n",
            "Epoch: 186, Batch: 23449, Example: 186476, Loss: 0.001\n",
            "Epoch: 186, Batch: 23474, Example: 186676, Loss: 0.003\n",
            "Epoch: 186, Batch: 23499, Example: 186876, Loss: 0.001\n",
            "Epoch: 186, Batch: 23524, Example: 187076, Loss: 0.001\n",
            "Epoch: 186, Batch: 23549, Example: 187276, Loss: 0.002\n",
            "Epoch: 187, Batch: 23574, Example: 187470, Loss: 0.002\n",
            "Epoch: 187, Batch: 23599, Example: 187670, Loss: 0.001\n",
            "Epoch: 187, Batch: 23624, Example: 187870, Loss: 0.000\n",
            "Epoch: 187, Batch: 23649, Example: 188070, Loss: 0.001\n",
            "Epoch: 187, Batch: 23674, Example: 188270, Loss: 0.001\n",
            "Epoch: 188, Batch: 23699, Example: 188464, Loss: 0.001\n",
            "Epoch: 188, Batch: 23724, Example: 188664, Loss: 0.001\n",
            "Epoch: 188, Batch: 23749, Example: 188864, Loss: 0.001\n",
            "Epoch: 188, Batch: 23774, Example: 189064, Loss: 0.001\n",
            "Epoch: 188, Batch: 23799, Example: 189264, Loss: 0.001\n",
            "Epoch: 189, Batch: 23824, Example: 189458, Loss: 0.000\n",
            "Epoch: 189, Batch: 23849, Example: 189658, Loss: 0.002\n",
            "Epoch: 189, Batch: 23874, Example: 189858, Loss: 0.001\n",
            "Epoch: 189, Batch: 23899, Example: 190058, Loss: 0.000\n",
            "Epoch: 189, Batch: 23924, Example: 190258, Loss: 0.001\n",
            "Epoch: 190, Batch: 23949, Example: 190452, Loss: 0.001\n",
            "Epoch: 190, Batch: 23974, Example: 190652, Loss: 0.001\n",
            "Epoch: 190, Batch: 23999, Example: 190852, Loss: 0.001\n",
            "Epoch: 190, Batch: 24024, Example: 191052, Loss: 0.001\n",
            "Epoch: 190, Batch: 24049, Example: 191252, Loss: 0.001\n",
            "Accuracy of the model at epoch 190: 76.74650698602794%\n",
            "Epoch: 191, Batch: 24074, Example: 191446, Loss: 0.002\n",
            "Epoch: 191, Batch: 24099, Example: 191646, Loss: 0.001\n",
            "Epoch: 191, Batch: 24124, Example: 191846, Loss: 0.002\n",
            "Epoch: 191, Batch: 24149, Example: 192046, Loss: 0.002\n",
            "Epoch: 191, Batch: 24174, Example: 192246, Loss: 0.002\n",
            "Epoch: 192, Batch: 24199, Example: 192440, Loss: 0.001\n",
            "Epoch: 192, Batch: 24224, Example: 192640, Loss: 0.001\n",
            "Epoch: 192, Batch: 24249, Example: 192840, Loss: 0.000\n",
            "Epoch: 192, Batch: 24274, Example: 193040, Loss: 0.000\n",
            "Epoch: 192, Batch: 24299, Example: 193240, Loss: 0.000\n",
            "Epoch: 193, Batch: 24324, Example: 193434, Loss: 0.002\n",
            "Epoch: 193, Batch: 24349, Example: 193634, Loss: 0.000\n",
            "Epoch: 193, Batch: 24374, Example: 193834, Loss: 0.002\n",
            "Epoch: 193, Batch: 24399, Example: 194034, Loss: 0.001\n",
            "Epoch: 193, Batch: 24424, Example: 194234, Loss: 0.001\n",
            "Epoch: 194, Batch: 24449, Example: 194428, Loss: 0.001\n",
            "Epoch: 194, Batch: 24474, Example: 194628, Loss: 0.001\n",
            "Epoch: 194, Batch: 24499, Example: 194828, Loss: 0.000\n",
            "Epoch: 194, Batch: 24524, Example: 195028, Loss: 0.000\n",
            "Epoch: 194, Batch: 24549, Example: 195228, Loss: 0.000\n",
            "Epoch: 195, Batch: 24574, Example: 195422, Loss: 0.001\n",
            "Epoch: 195, Batch: 24599, Example: 195622, Loss: 0.002\n",
            "Epoch: 195, Batch: 24624, Example: 195822, Loss: 0.000\n",
            "Epoch: 195, Batch: 24649, Example: 196022, Loss: 0.001\n",
            "Epoch: 195, Batch: 24674, Example: 196222, Loss: 0.001\n",
            "Accuracy of the model at epoch 195: 90.41916167664671%\n",
            "Epoch: 196, Batch: 24699, Example: 196416, Loss: 0.001\n",
            "Epoch: 196, Batch: 24724, Example: 196616, Loss: 0.000\n",
            "Epoch: 196, Batch: 24749, Example: 196816, Loss: 0.000\n",
            "Epoch: 196, Batch: 24774, Example: 197016, Loss: 0.001\n",
            "Epoch: 196, Batch: 24799, Example: 197216, Loss: 0.001\n",
            "Epoch: 197, Batch: 24824, Example: 197410, Loss: 0.001\n",
            "Epoch: 197, Batch: 24849, Example: 197610, Loss: 0.001\n",
            "Epoch: 197, Batch: 24874, Example: 197810, Loss: 0.001\n",
            "Epoch: 197, Batch: 24899, Example: 198010, Loss: 0.001\n",
            "Epoch: 197, Batch: 24924, Example: 198210, Loss: 0.000\n",
            "Epoch: 198, Batch: 24949, Example: 198404, Loss: 0.001\n",
            "Epoch: 198, Batch: 24974, Example: 198604, Loss: 0.001\n",
            "Epoch: 198, Batch: 24999, Example: 198804, Loss: 0.000\n",
            "Epoch: 198, Batch: 25024, Example: 199004, Loss: 0.001\n",
            "Epoch: 198, Batch: 25049, Example: 199204, Loss: 0.001\n",
            "Epoch: 198, Batch: 25074, Example: 199398, Loss: 0.002\n",
            "Epoch: 199, Batch: 25099, Example: 199598, Loss: 0.001\n",
            "Epoch: 199, Batch: 25124, Example: 199798, Loss: 0.001\n",
            "Epoch: 199, Batch: 25149, Example: 199998, Loss: 0.001\n",
            "Epoch: 199, Batch: 25174, Example: 200198, Loss: 0.000\n",
            "Epoch: 199, Batch: 25199, Example: 200398, Loss: 0.001\n",
            "Epoch: 200, Batch: 25224, Example: 200592, Loss: 0.001\n",
            "Epoch: 200, Batch: 25249, Example: 200792, Loss: 0.000\n",
            "Epoch: 200, Batch: 25274, Example: 200992, Loss: 0.002\n",
            "Epoch: 200, Batch: 25299, Example: 201192, Loss: 0.001\n",
            "Epoch: 200, Batch: 25324, Example: 201392, Loss: 0.000\n",
            "Accuracy of the model at epoch 200: 93.41317365269461%\n",
            "Epoch: 201, Batch: 25349, Example: 201586, Loss: 0.001\n",
            "Epoch: 201, Batch: 25374, Example: 201786, Loss: 0.001\n",
            "Epoch: 201, Batch: 25399, Example: 201986, Loss: 0.000\n",
            "Epoch: 201, Batch: 25424, Example: 202186, Loss: 0.002\n",
            "Epoch: 201, Batch: 25449, Example: 202386, Loss: 0.001\n",
            "Epoch: 202, Batch: 25474, Example: 202580, Loss: 0.001\n",
            "Epoch: 202, Batch: 25499, Example: 202780, Loss: 0.000\n",
            "Epoch: 202, Batch: 25524, Example: 202980, Loss: 0.001\n",
            "Epoch: 202, Batch: 25549, Example: 203180, Loss: 0.001\n",
            "Epoch: 202, Batch: 25574, Example: 203380, Loss: 0.002\n",
            "Epoch: 203, Batch: 25599, Example: 203574, Loss: 0.001\n",
            "Epoch: 203, Batch: 25624, Example: 203774, Loss: 0.001\n",
            "Epoch: 203, Batch: 25649, Example: 203974, Loss: 0.000\n",
            "Epoch: 203, Batch: 25674, Example: 204174, Loss: 0.001\n",
            "Epoch: 203, Batch: 25699, Example: 204374, Loss: 0.002\n",
            "Epoch: 204, Batch: 25724, Example: 204568, Loss: 0.001\n",
            "Epoch: 204, Batch: 25749, Example: 204768, Loss: 0.001\n",
            "Epoch: 204, Batch: 25774, Example: 204968, Loss: 0.001\n",
            "Epoch: 204, Batch: 25799, Example: 205168, Loss: 0.001\n",
            "Epoch: 204, Batch: 25824, Example: 205368, Loss: 0.000\n",
            "Epoch: 205, Batch: 25849, Example: 205562, Loss: 0.004\n",
            "Epoch: 205, Batch: 25874, Example: 205762, Loss: 0.002\n",
            "Epoch: 205, Batch: 25899, Example: 205962, Loss: 0.001\n",
            "Epoch: 205, Batch: 25924, Example: 206162, Loss: 0.001\n",
            "Epoch: 205, Batch: 25949, Example: 206362, Loss: 0.001\n",
            "Accuracy of the model at epoch 205: 90.41916167664671%\n",
            "Epoch: 206, Batch: 25974, Example: 206556, Loss: 0.002\n",
            "Epoch: 206, Batch: 25999, Example: 206756, Loss: 0.001\n",
            "Epoch: 206, Batch: 26024, Example: 206956, Loss: 0.001\n",
            "Epoch: 206, Batch: 26049, Example: 207156, Loss: 0.001\n",
            "Epoch: 206, Batch: 26074, Example: 207356, Loss: 0.001\n",
            "Epoch: 207, Batch: 26099, Example: 207550, Loss: 0.001\n",
            "Epoch: 207, Batch: 26124, Example: 207750, Loss: 0.000\n",
            "Epoch: 207, Batch: 26149, Example: 207950, Loss: 0.000\n",
            "Epoch: 207, Batch: 26174, Example: 208150, Loss: 0.001\n",
            "Epoch: 207, Batch: 26199, Example: 208350, Loss: 0.000\n",
            "Epoch: 208, Batch: 26224, Example: 208544, Loss: 0.001\n",
            "Epoch: 208, Batch: 26249, Example: 208744, Loss: 0.001\n",
            "Epoch: 208, Batch: 26274, Example: 208944, Loss: 0.001\n",
            "Epoch: 208, Batch: 26299, Example: 209144, Loss: 0.000\n",
            "Epoch: 208, Batch: 26324, Example: 209344, Loss: 0.000\n",
            "Epoch: 209, Batch: 26349, Example: 209538, Loss: 0.000\n",
            "Epoch: 209, Batch: 26374, Example: 209738, Loss: 0.001\n",
            "Epoch: 209, Batch: 26399, Example: 209938, Loss: 0.001\n",
            "Epoch: 209, Batch: 26424, Example: 210138, Loss: 0.000\n",
            "Epoch: 209, Batch: 26449, Example: 210338, Loss: 0.001\n",
            "Epoch: 210, Batch: 26474, Example: 210532, Loss: 0.001\n",
            "Epoch: 210, Batch: 26499, Example: 210732, Loss: 0.000\n",
            "Epoch: 210, Batch: 26524, Example: 210932, Loss: 0.001\n",
            "Epoch: 210, Batch: 26549, Example: 211132, Loss: 0.002\n",
            "Epoch: 210, Batch: 26574, Example: 211332, Loss: 0.001\n",
            "Accuracy of the model at epoch 210: 94.21157684630738%\n",
            "Epoch: 211, Batch: 26599, Example: 211526, Loss: 0.001\n",
            "Epoch: 211, Batch: 26624, Example: 211726, Loss: 0.001\n",
            "Epoch: 211, Batch: 26649, Example: 211926, Loss: 0.001\n",
            "Epoch: 211, Batch: 26674, Example: 212126, Loss: 0.001\n",
            "Epoch: 211, Batch: 26699, Example: 212326, Loss: 0.002\n",
            "Epoch: 212, Batch: 26724, Example: 212520, Loss: 0.001\n",
            "Epoch: 212, Batch: 26749, Example: 212720, Loss: 0.001\n",
            "Epoch: 212, Batch: 26774, Example: 212920, Loss: 0.001\n",
            "Epoch: 212, Batch: 26799, Example: 213120, Loss: 0.001\n",
            "Epoch: 212, Batch: 26824, Example: 213320, Loss: 0.000\n",
            "Epoch: 213, Batch: 26849, Example: 213514, Loss: 0.001\n",
            "Epoch: 213, Batch: 26874, Example: 213714, Loss: 0.002\n",
            "Epoch: 213, Batch: 26899, Example: 213914, Loss: 0.001\n",
            "Epoch: 213, Batch: 26924, Example: 214114, Loss: 0.002\n",
            "Epoch: 213, Batch: 26949, Example: 214314, Loss: 0.001\n",
            "Epoch: 214, Batch: 26974, Example: 214508, Loss: 0.001\n",
            "Epoch: 214, Batch: 26999, Example: 214708, Loss: 0.001\n",
            "Epoch: 214, Batch: 27024, Example: 214908, Loss: 0.001\n",
            "Epoch: 214, Batch: 27049, Example: 215108, Loss: 0.001\n",
            "Epoch: 214, Batch: 27074, Example: 215308, Loss: 0.002\n",
            "Epoch: 215, Batch: 27099, Example: 215502, Loss: 0.000\n",
            "Epoch: 215, Batch: 27124, Example: 215702, Loss: 0.000\n",
            "Epoch: 215, Batch: 27149, Example: 215902, Loss: 0.001\n",
            "Epoch: 215, Batch: 27174, Example: 216102, Loss: 0.001\n",
            "Epoch: 215, Batch: 27199, Example: 216302, Loss: 0.000\n",
            "Accuracy of the model at epoch 215: 91.51696606786427%\n",
            "Epoch: 216, Batch: 27224, Example: 216496, Loss: 0.001\n",
            "Epoch: 216, Batch: 27249, Example: 216696, Loss: 0.000\n",
            "Epoch: 216, Batch: 27274, Example: 216896, Loss: 0.000\n",
            "Epoch: 216, Batch: 27299, Example: 217096, Loss: 0.001\n",
            "Epoch: 216, Batch: 27324, Example: 217296, Loss: 0.000\n",
            "Epoch: 217, Batch: 27349, Example: 217490, Loss: 0.001\n",
            "Epoch: 217, Batch: 27374, Example: 217690, Loss: 0.001\n",
            "Epoch: 217, Batch: 27399, Example: 217890, Loss: 0.001\n",
            "Epoch: 217, Batch: 27424, Example: 218090, Loss: 0.002\n",
            "Epoch: 217, Batch: 27449, Example: 218290, Loss: 0.002\n",
            "Epoch: 218, Batch: 27474, Example: 218484, Loss: 0.003\n",
            "Epoch: 218, Batch: 27499, Example: 218684, Loss: 0.001\n",
            "Epoch: 218, Batch: 27524, Example: 218884, Loss: 0.002\n",
            "Epoch: 218, Batch: 27549, Example: 219084, Loss: 0.001\n",
            "Epoch: 218, Batch: 27574, Example: 219284, Loss: 0.001\n",
            "Epoch: 219, Batch: 27599, Example: 219478, Loss: 0.000\n",
            "Epoch: 219, Batch: 27624, Example: 219678, Loss: 0.001\n",
            "Epoch: 219, Batch: 27649, Example: 219878, Loss: 0.002\n",
            "Epoch: 219, Batch: 27674, Example: 220078, Loss: 0.001\n",
            "Epoch: 219, Batch: 27699, Example: 220278, Loss: 0.000\n",
            "Epoch: 220, Batch: 27724, Example: 220472, Loss: 0.000\n",
            "Epoch: 220, Batch: 27749, Example: 220672, Loss: 0.001\n",
            "Epoch: 220, Batch: 27774, Example: 220872, Loss: 0.001\n",
            "Epoch: 220, Batch: 27799, Example: 221072, Loss: 0.000\n",
            "Epoch: 220, Batch: 27824, Example: 221272, Loss: 0.001\n",
            "Accuracy of the model at epoch 220: 92.41516966067864%\n",
            "Epoch: 221, Batch: 27849, Example: 221466, Loss: 0.002\n",
            "Epoch: 221, Batch: 27874, Example: 221666, Loss: 0.002\n",
            "Epoch: 221, Batch: 27899, Example: 221866, Loss: 0.000\n",
            "Epoch: 221, Batch: 27924, Example: 222066, Loss: 0.001\n",
            "Epoch: 221, Batch: 27949, Example: 222266, Loss: 0.001\n",
            "Epoch: 222, Batch: 27974, Example: 222460, Loss: 0.001\n",
            "Epoch: 222, Batch: 27999, Example: 222660, Loss: 0.000\n",
            "Epoch: 222, Batch: 28024, Example: 222860, Loss: 0.001\n",
            "Epoch: 222, Batch: 28049, Example: 223060, Loss: 0.001\n",
            "Epoch: 222, Batch: 28074, Example: 223260, Loss: 0.002\n",
            "Epoch: 223, Batch: 28099, Example: 223454, Loss: 0.001\n",
            "Epoch: 223, Batch: 28124, Example: 223654, Loss: 0.001\n",
            "Epoch: 223, Batch: 28149, Example: 223854, Loss: 0.001\n",
            "Epoch: 223, Batch: 28174, Example: 224054, Loss: 0.002\n",
            "Epoch: 223, Batch: 28199, Example: 224254, Loss: 0.001\n",
            "Epoch: 223, Batch: 28224, Example: 224448, Loss: 0.002\n",
            "Epoch: 224, Batch: 28249, Example: 224648, Loss: 0.001\n",
            "Epoch: 224, Batch: 28274, Example: 224848, Loss: 0.000\n",
            "Epoch: 224, Batch: 28299, Example: 225048, Loss: 0.000\n",
            "Epoch: 224, Batch: 28324, Example: 225248, Loss: 0.001\n",
            "Epoch: 224, Batch: 28349, Example: 225448, Loss: 0.001\n",
            "Epoch: 225, Batch: 28374, Example: 225642, Loss: 0.001\n",
            "Epoch: 225, Batch: 28399, Example: 225842, Loss: 0.000\n",
            "Epoch: 225, Batch: 28424, Example: 226042, Loss: 0.001\n",
            "Epoch: 225, Batch: 28449, Example: 226242, Loss: 0.000\n",
            "Epoch: 225, Batch: 28474, Example: 226442, Loss: 0.002\n",
            "Accuracy of the model at epoch 225: 60.678642714570856%\n",
            "Epoch: 226, Batch: 28499, Example: 226636, Loss: 0.002\n",
            "Epoch: 226, Batch: 28524, Example: 226836, Loss: 0.000\n",
            "Epoch: 226, Batch: 28549, Example: 227036, Loss: 0.001\n",
            "Epoch: 226, Batch: 28574, Example: 227236, Loss: 0.000\n",
            "Epoch: 226, Batch: 28599, Example: 227436, Loss: 0.000\n",
            "Epoch: 227, Batch: 28624, Example: 227630, Loss: 0.001\n",
            "Epoch: 227, Batch: 28649, Example: 227830, Loss: 0.001\n",
            "Epoch: 227, Batch: 28674, Example: 228030, Loss: 0.003\n",
            "Epoch: 227, Batch: 28699, Example: 228230, Loss: 0.001\n",
            "Epoch: 227, Batch: 28724, Example: 228430, Loss: 0.001\n",
            "Epoch: 228, Batch: 28749, Example: 228624, Loss: 0.000\n",
            "Epoch: 228, Batch: 28774, Example: 228824, Loss: 0.001\n",
            "Epoch: 228, Batch: 28799, Example: 229024, Loss: 0.000\n",
            "Epoch: 228, Batch: 28824, Example: 229224, Loss: 0.000\n",
            "Epoch: 228, Batch: 28849, Example: 229424, Loss: 0.001\n",
            "Epoch: 229, Batch: 28874, Example: 229618, Loss: 0.001\n",
            "Epoch: 229, Batch: 28899, Example: 229818, Loss: 0.001\n",
            "Epoch: 229, Batch: 28924, Example: 230018, Loss: 0.001\n",
            "Epoch: 229, Batch: 28949, Example: 230218, Loss: 0.002\n",
            "Epoch: 229, Batch: 28974, Example: 230418, Loss: 0.002\n",
            "Epoch: 230, Batch: 28999, Example: 230612, Loss: 0.001\n",
            "Epoch: 230, Batch: 29024, Example: 230812, Loss: 0.001\n",
            "Epoch: 230, Batch: 29049, Example: 231012, Loss: 0.001\n",
            "Epoch: 230, Batch: 29074, Example: 231212, Loss: 0.001\n",
            "Epoch: 230, Batch: 29099, Example: 231412, Loss: 0.000\n",
            "Accuracy of the model at epoch 230: 88.62275449101796%\n",
            "Epoch: 231, Batch: 29124, Example: 231606, Loss: 0.001\n",
            "Epoch: 231, Batch: 29149, Example: 231806, Loss: 0.001\n",
            "Epoch: 231, Batch: 29174, Example: 232006, Loss: 0.001\n",
            "Epoch: 231, Batch: 29199, Example: 232206, Loss: 0.000\n",
            "Epoch: 231, Batch: 29224, Example: 232406, Loss: 0.000\n",
            "Epoch: 232, Batch: 29249, Example: 232600, Loss: 0.001\n",
            "Epoch: 232, Batch: 29274, Example: 232800, Loss: 0.000\n",
            "Epoch: 232, Batch: 29299, Example: 233000, Loss: 0.000\n",
            "Epoch: 232, Batch: 29324, Example: 233200, Loss: 0.000\n",
            "Epoch: 232, Batch: 29349, Example: 233400, Loss: 0.001\n",
            "Epoch: 233, Batch: 29374, Example: 233594, Loss: 0.001\n",
            "Epoch: 233, Batch: 29399, Example: 233794, Loss: 0.000\n",
            "Epoch: 233, Batch: 29424, Example: 233994, Loss: 0.000\n",
            "Epoch: 233, Batch: 29449, Example: 234194, Loss: 0.001\n",
            "Epoch: 233, Batch: 29474, Example: 234394, Loss: 0.001\n",
            "Epoch: 234, Batch: 29499, Example: 234588, Loss: 0.000\n",
            "Epoch: 234, Batch: 29524, Example: 234788, Loss: 0.001\n",
            "Epoch: 234, Batch: 29549, Example: 234988, Loss: 0.001\n",
            "Epoch: 234, Batch: 29574, Example: 235188, Loss: 0.001\n",
            "Epoch: 234, Batch: 29599, Example: 235388, Loss: 0.000\n",
            "Epoch: 235, Batch: 29624, Example: 235582, Loss: 0.000\n",
            "Epoch: 235, Batch: 29649, Example: 235782, Loss: 0.001\n",
            "Epoch: 235, Batch: 29674, Example: 235982, Loss: 0.001\n",
            "Epoch: 235, Batch: 29699, Example: 236182, Loss: 0.001\n",
            "Epoch: 235, Batch: 29724, Example: 236382, Loss: 0.000\n",
            "Accuracy of the model at epoch 235: 77.34530938123753%\n",
            "Epoch: 236, Batch: 29749, Example: 236576, Loss: 0.003\n",
            "Epoch: 236, Batch: 29774, Example: 236776, Loss: 0.002\n",
            "Epoch: 236, Batch: 29799, Example: 236976, Loss: 0.002\n",
            "Epoch: 236, Batch: 29824, Example: 237176, Loss: 0.001\n",
            "Epoch: 236, Batch: 29849, Example: 237376, Loss: 0.001\n",
            "Epoch: 237, Batch: 29874, Example: 237570, Loss: 0.001\n",
            "Epoch: 237, Batch: 29899, Example: 237770, Loss: 0.000\n",
            "Epoch: 237, Batch: 29924, Example: 237970, Loss: 0.000\n",
            "Epoch: 237, Batch: 29949, Example: 238170, Loss: 0.000\n",
            "Epoch: 237, Batch: 29974, Example: 238370, Loss: 0.001\n",
            "Epoch: 238, Batch: 29999, Example: 238564, Loss: 0.000\n",
            "Epoch: 238, Batch: 30024, Example: 238764, Loss: 0.001\n",
            "Epoch: 238, Batch: 30049, Example: 238964, Loss: 0.001\n",
            "Epoch: 238, Batch: 30074, Example: 239164, Loss: 0.001\n",
            "Epoch: 238, Batch: 30099, Example: 239364, Loss: 0.001\n",
            "Epoch: 239, Batch: 30124, Example: 239558, Loss: 0.002\n",
            "Epoch: 239, Batch: 30149, Example: 239758, Loss: 0.001\n",
            "Epoch: 239, Batch: 30174, Example: 239958, Loss: 0.001\n",
            "Epoch: 239, Batch: 30199, Example: 240158, Loss: 0.001\n",
            "Epoch: 239, Batch: 30224, Example: 240358, Loss: 0.001\n",
            "Epoch: 240, Batch: 30249, Example: 240552, Loss: 0.000\n",
            "Epoch: 240, Batch: 30274, Example: 240752, Loss: 0.001\n",
            "Epoch: 240, Batch: 30299, Example: 240952, Loss: 0.001\n",
            "Epoch: 240, Batch: 30324, Example: 241152, Loss: 0.000\n",
            "Epoch: 240, Batch: 30349, Example: 241352, Loss: 0.002\n",
            "Accuracy of the model at epoch 240: 83.73253493013972%\n",
            "Epoch: 241, Batch: 30374, Example: 241546, Loss: 0.002\n",
            "Epoch: 241, Batch: 30399, Example: 241746, Loss: 0.000\n",
            "Epoch: 241, Batch: 30424, Example: 241946, Loss: 0.001\n",
            "Epoch: 241, Batch: 30449, Example: 242146, Loss: 0.002\n",
            "Epoch: 241, Batch: 30474, Example: 242346, Loss: 0.001\n",
            "Epoch: 242, Batch: 30499, Example: 242540, Loss: 0.001\n",
            "Epoch: 242, Batch: 30524, Example: 242740, Loss: 0.002\n",
            "Epoch: 242, Batch: 30549, Example: 242940, Loss: 0.002\n",
            "Epoch: 242, Batch: 30574, Example: 243140, Loss: 0.000\n",
            "Epoch: 242, Batch: 30599, Example: 243340, Loss: 0.000\n",
            "Epoch: 243, Batch: 30624, Example: 243534, Loss: 0.001\n",
            "Epoch: 243, Batch: 30649, Example: 243734, Loss: 0.000\n",
            "Epoch: 243, Batch: 30674, Example: 243934, Loss: 0.000\n",
            "Epoch: 243, Batch: 30699, Example: 244134, Loss: 0.000\n",
            "Epoch: 243, Batch: 30724, Example: 244334, Loss: 0.001\n",
            "Epoch: 244, Batch: 30749, Example: 244528, Loss: 0.001\n",
            "Epoch: 244, Batch: 30774, Example: 244728, Loss: 0.000\n",
            "Epoch: 244, Batch: 30799, Example: 244928, Loss: 0.001\n",
            "Epoch: 244, Batch: 30824, Example: 245128, Loss: 0.002\n",
            "Epoch: 244, Batch: 30849, Example: 245328, Loss: 0.002\n",
            "Epoch: 245, Batch: 30874, Example: 245522, Loss: 0.001\n",
            "Epoch: 245, Batch: 30899, Example: 245722, Loss: 0.001\n",
            "Epoch: 245, Batch: 30924, Example: 245922, Loss: 0.001\n",
            "Epoch: 245, Batch: 30949, Example: 246122, Loss: 0.000\n",
            "Epoch: 245, Batch: 30974, Example: 246322, Loss: 0.001\n",
            "Accuracy of the model at epoch 245: 94.81037924151697%\n",
            "Epoch: 246, Batch: 30999, Example: 246516, Loss: 0.001\n",
            "Epoch: 246, Batch: 31024, Example: 246716, Loss: 0.003\n",
            "Epoch: 246, Batch: 31049, Example: 246916, Loss: 0.001\n",
            "Epoch: 246, Batch: 31074, Example: 247116, Loss: 0.001\n",
            "Epoch: 246, Batch: 31099, Example: 247316, Loss: 0.000\n",
            "Epoch: 247, Batch: 31124, Example: 247510, Loss: 0.002\n",
            "Epoch: 247, Batch: 31149, Example: 247710, Loss: 0.001\n",
            "Epoch: 247, Batch: 31174, Example: 247910, Loss: 0.002\n",
            "Epoch: 247, Batch: 31199, Example: 248110, Loss: 0.001\n",
            "Epoch: 247, Batch: 31224, Example: 248310, Loss: 0.001\n",
            "Epoch: 248, Batch: 31249, Example: 248504, Loss: 0.001\n",
            "Epoch: 248, Batch: 31274, Example: 248704, Loss: 0.000\n",
            "Epoch: 248, Batch: 31299, Example: 248904, Loss: 0.000\n",
            "Epoch: 248, Batch: 31324, Example: 249104, Loss: 0.000\n",
            "Epoch: 248, Batch: 31349, Example: 249304, Loss: 0.000\n",
            "Epoch: 248, Batch: 31374, Example: 249498, Loss: 0.001\n",
            "Epoch: 249, Batch: 31399, Example: 249698, Loss: 0.001\n",
            "Epoch: 249, Batch: 31424, Example: 249898, Loss: 0.001\n",
            "Epoch: 249, Batch: 31449, Example: 250098, Loss: 0.001\n",
            "Epoch: 249, Batch: 31474, Example: 250298, Loss: 0.001\n",
            "Epoch: 249, Batch: 31499, Example: 250498, Loss: 0.001\n",
            "Epoch: 250, Batch: 31524, Example: 250692, Loss: 0.000\n",
            "Epoch: 250, Batch: 31549, Example: 250892, Loss: 0.001\n",
            "Epoch: 250, Batch: 31574, Example: 251092, Loss: 0.000\n",
            "Epoch: 250, Batch: 31599, Example: 251292, Loss: 0.001\n",
            "Epoch: 250, Batch: 31624, Example: 251492, Loss: 0.001\n",
            "Accuracy of the model at epoch 250: 96.8063872255489%\n",
            "Epoch: 251, Batch: 31649, Example: 251686, Loss: 0.000\n",
            "Epoch: 251, Batch: 31674, Example: 251886, Loss: 0.001\n",
            "Epoch: 251, Batch: 31699, Example: 252086, Loss: 0.001\n",
            "Epoch: 251, Batch: 31724, Example: 252286, Loss: 0.000\n",
            "Epoch: 251, Batch: 31749, Example: 252486, Loss: 0.000\n",
            "Epoch: 252, Batch: 31774, Example: 252680, Loss: 0.001\n",
            "Epoch: 252, Batch: 31799, Example: 252880, Loss: 0.000\n",
            "Epoch: 252, Batch: 31824, Example: 253080, Loss: 0.000\n",
            "Epoch: 252, Batch: 31849, Example: 253280, Loss: 0.000\n",
            "Epoch: 252, Batch: 31874, Example: 253480, Loss: 0.001\n",
            "Epoch: 253, Batch: 31899, Example: 253674, Loss: 0.000\n",
            "Epoch: 253, Batch: 31924, Example: 253874, Loss: 0.000\n",
            "Epoch: 253, Batch: 31949, Example: 254074, Loss: 0.000\n",
            "Epoch: 253, Batch: 31974, Example: 254274, Loss: 0.001\n",
            "Epoch: 253, Batch: 31999, Example: 254474, Loss: 0.001\n",
            "Epoch: 254, Batch: 32024, Example: 254668, Loss: 0.000\n",
            "Epoch: 254, Batch: 32049, Example: 254868, Loss: 0.001\n",
            "Epoch: 254, Batch: 32074, Example: 255068, Loss: 0.000\n",
            "Epoch: 254, Batch: 32099, Example: 255268, Loss: 0.001\n",
            "Epoch: 254, Batch: 32124, Example: 255468, Loss: 0.001\n",
            "Epoch: 255, Batch: 32149, Example: 255662, Loss: 0.001\n",
            "Epoch: 255, Batch: 32174, Example: 255862, Loss: 0.000\n",
            "Epoch: 255, Batch: 32199, Example: 256062, Loss: 0.001\n",
            "Epoch: 255, Batch: 32224, Example: 256262, Loss: 0.001\n",
            "Epoch: 255, Batch: 32249, Example: 256462, Loss: 0.001\n",
            "Accuracy of the model at epoch 255: 80.43912175648703%\n",
            "Epoch: 256, Batch: 32274, Example: 256656, Loss: 0.001\n",
            "Epoch: 256, Batch: 32299, Example: 256856, Loss: 0.001\n",
            "Epoch: 256, Batch: 32324, Example: 257056, Loss: 0.001\n",
            "Epoch: 256, Batch: 32349, Example: 257256, Loss: 0.001\n",
            "Epoch: 256, Batch: 32374, Example: 257456, Loss: 0.002\n",
            "Epoch: 257, Batch: 32399, Example: 257650, Loss: 0.001\n",
            "Epoch: 257, Batch: 32424, Example: 257850, Loss: 0.001\n",
            "Epoch: 257, Batch: 32449, Example: 258050, Loss: 0.001\n",
            "Epoch: 257, Batch: 32474, Example: 258250, Loss: 0.000\n",
            "Epoch: 257, Batch: 32499, Example: 258450, Loss: 0.001\n",
            "Epoch: 258, Batch: 32524, Example: 258644, Loss: 0.001\n",
            "Epoch: 258, Batch: 32549, Example: 258844, Loss: 0.002\n",
            "Epoch: 258, Batch: 32574, Example: 259044, Loss: 0.001\n",
            "Epoch: 258, Batch: 32599, Example: 259244, Loss: 0.000\n",
            "Epoch: 258, Batch: 32624, Example: 259444, Loss: 0.001\n",
            "Epoch: 259, Batch: 32649, Example: 259638, Loss: 0.001\n",
            "Epoch: 259, Batch: 32674, Example: 259838, Loss: 0.000\n",
            "Epoch: 259, Batch: 32699, Example: 260038, Loss: 0.001\n",
            "Epoch: 259, Batch: 32724, Example: 260238, Loss: 0.000\n",
            "Epoch: 259, Batch: 32749, Example: 260438, Loss: 0.001\n",
            "Epoch: 260, Batch: 32774, Example: 260632, Loss: 0.001\n",
            "Epoch: 260, Batch: 32799, Example: 260832, Loss: 0.000\n",
            "Epoch: 260, Batch: 32824, Example: 261032, Loss: 0.000\n",
            "Epoch: 260, Batch: 32849, Example: 261232, Loss: 0.001\n",
            "Epoch: 260, Batch: 32874, Example: 261432, Loss: 0.001\n",
            "Accuracy of the model at epoch 260: 99.10179640718563%\n",
            "Epoch: 261, Batch: 32899, Example: 261626, Loss: 0.000\n",
            "Epoch: 261, Batch: 32924, Example: 261826, Loss: 0.001\n",
            "Epoch: 261, Batch: 32949, Example: 262026, Loss: 0.001\n",
            "Epoch: 261, Batch: 32974, Example: 262226, Loss: 0.001\n",
            "Epoch: 261, Batch: 32999, Example: 262426, Loss: 0.001\n",
            "Epoch: 262, Batch: 33024, Example: 262620, Loss: 0.001\n",
            "Epoch: 262, Batch: 33049, Example: 262820, Loss: 0.000\n",
            "Epoch: 262, Batch: 33074, Example: 263020, Loss: 0.001\n",
            "Epoch: 262, Batch: 33099, Example: 263220, Loss: 0.001\n",
            "Epoch: 262, Batch: 33124, Example: 263420, Loss: 0.002\n",
            "Epoch: 263, Batch: 33149, Example: 263614, Loss: 0.001\n",
            "Epoch: 263, Batch: 33174, Example: 263814, Loss: 0.000\n",
            "Epoch: 263, Batch: 33199, Example: 264014, Loss: 0.001\n",
            "Epoch: 263, Batch: 33224, Example: 264214, Loss: 0.000\n",
            "Epoch: 263, Batch: 33249, Example: 264414, Loss: 0.000\n",
            "Epoch: 264, Batch: 33274, Example: 264608, Loss: 0.000\n",
            "Epoch: 264, Batch: 33299, Example: 264808, Loss: 0.000\n",
            "Epoch: 264, Batch: 33324, Example: 265008, Loss: 0.000\n",
            "Epoch: 264, Batch: 33349, Example: 265208, Loss: 0.001\n",
            "Epoch: 264, Batch: 33374, Example: 265408, Loss: 0.000\n",
            "Epoch: 265, Batch: 33399, Example: 265602, Loss: 0.000\n",
            "Epoch: 265, Batch: 33424, Example: 265802, Loss: 0.001\n",
            "Epoch: 265, Batch: 33449, Example: 266002, Loss: 0.002\n",
            "Epoch: 265, Batch: 33474, Example: 266202, Loss: 0.002\n",
            "Epoch: 265, Batch: 33499, Example: 266402, Loss: 0.001\n",
            "Accuracy of the model at epoch 265: 95.20958083832335%\n",
            "Epoch: 266, Batch: 33524, Example: 266596, Loss: 0.001\n",
            "Epoch: 266, Batch: 33549, Example: 266796, Loss: 0.000\n",
            "Epoch: 266, Batch: 33574, Example: 266996, Loss: 0.000\n",
            "Epoch: 266, Batch: 33599, Example: 267196, Loss: 0.001\n",
            "Epoch: 266, Batch: 33624, Example: 267396, Loss: 0.001\n",
            "Epoch: 267, Batch: 33649, Example: 267590, Loss: 0.001\n",
            "Epoch: 267, Batch: 33674, Example: 267790, Loss: 0.000\n",
            "Epoch: 267, Batch: 33699, Example: 267990, Loss: 0.000\n",
            "Epoch: 267, Batch: 33724, Example: 268190, Loss: 0.000\n",
            "Epoch: 267, Batch: 33749, Example: 268390, Loss: 0.002\n",
            "Epoch: 268, Batch: 33774, Example: 268584, Loss: 0.002\n",
            "Epoch: 268, Batch: 33799, Example: 268784, Loss: 0.000\n",
            "Epoch: 268, Batch: 33824, Example: 268984, Loss: 0.001\n",
            "Epoch: 268, Batch: 33849, Example: 269184, Loss: 0.001\n",
            "Epoch: 268, Batch: 33874, Example: 269384, Loss: 0.000\n",
            "Epoch: 269, Batch: 33899, Example: 269578, Loss: 0.000\n",
            "Epoch: 269, Batch: 33924, Example: 269778, Loss: 0.000\n",
            "Epoch: 269, Batch: 33949, Example: 269978, Loss: 0.000\n",
            "Epoch: 269, Batch: 33974, Example: 270178, Loss: 0.000\n",
            "Epoch: 269, Batch: 33999, Example: 270378, Loss: 0.001\n",
            "Epoch: 270, Batch: 34024, Example: 270572, Loss: 0.000\n",
            "Epoch: 270, Batch: 34049, Example: 270772, Loss: 0.000\n",
            "Epoch: 270, Batch: 34074, Example: 270972, Loss: 0.001\n",
            "Epoch: 270, Batch: 34099, Example: 271172, Loss: 0.001\n",
            "Epoch: 270, Batch: 34124, Example: 271372, Loss: 0.000\n",
            "Accuracy of the model at epoch 270: 98.70259481037924%\n",
            "Epoch: 271, Batch: 34149, Example: 271566, Loss: 0.001\n",
            "Epoch: 271, Batch: 34174, Example: 271766, Loss: 0.001\n",
            "Epoch: 271, Batch: 34199, Example: 271966, Loss: 0.000\n",
            "Epoch: 271, Batch: 34224, Example: 272166, Loss: 0.001\n",
            "Epoch: 271, Batch: 34249, Example: 272366, Loss: 0.001\n",
            "Epoch: 272, Batch: 34274, Example: 272560, Loss: 0.000\n",
            "Epoch: 272, Batch: 34299, Example: 272760, Loss: 0.000\n",
            "Epoch: 272, Batch: 34324, Example: 272960, Loss: 0.001\n",
            "Epoch: 272, Batch: 34349, Example: 273160, Loss: 0.000\n",
            "Epoch: 272, Batch: 34374, Example: 273360, Loss: 0.000\n",
            "Epoch: 273, Batch: 34399, Example: 273554, Loss: 0.000\n",
            "Epoch: 273, Batch: 34424, Example: 273754, Loss: 0.000\n",
            "Epoch: 273, Batch: 34449, Example: 273954, Loss: 0.000\n",
            "Epoch: 273, Batch: 34474, Example: 274154, Loss: 0.000\n",
            "Epoch: 273, Batch: 34499, Example: 274354, Loss: 0.001\n",
            "Epoch: 273, Batch: 34524, Example: 274548, Loss: 0.000\n",
            "Epoch: 274, Batch: 34549, Example: 274748, Loss: 0.001\n",
            "Epoch: 274, Batch: 34574, Example: 274948, Loss: 0.000\n",
            "Epoch: 274, Batch: 34599, Example: 275148, Loss: 0.000\n",
            "Epoch: 274, Batch: 34624, Example: 275348, Loss: 0.000\n",
            "Epoch: 274, Batch: 34649, Example: 275548, Loss: 0.001\n",
            "Epoch: 275, Batch: 34674, Example: 275742, Loss: 0.000\n",
            "Epoch: 275, Batch: 34699, Example: 275942, Loss: 0.001\n",
            "Epoch: 275, Batch: 34724, Example: 276142, Loss: 0.000\n",
            "Epoch: 275, Batch: 34749, Example: 276342, Loss: 0.001\n",
            "Epoch: 275, Batch: 34774, Example: 276542, Loss: 0.001\n",
            "Accuracy of the model at epoch 275: 97.40518962075848%\n",
            "Epoch: 276, Batch: 34799, Example: 276736, Loss: 0.001\n",
            "Epoch: 276, Batch: 34824, Example: 276936, Loss: 0.001\n",
            "Epoch: 276, Batch: 34849, Example: 277136, Loss: 0.001\n",
            "Epoch: 276, Batch: 34874, Example: 277336, Loss: 0.001\n",
            "Epoch: 276, Batch: 34899, Example: 277536, Loss: 0.000\n",
            "Epoch: 277, Batch: 34924, Example: 277730, Loss: 0.001\n",
            "Epoch: 277, Batch: 34949, Example: 277930, Loss: 0.001\n",
            "Epoch: 277, Batch: 34974, Example: 278130, Loss: 0.001\n",
            "Epoch: 277, Batch: 34999, Example: 278330, Loss: 0.000\n",
            "Epoch: 277, Batch: 35024, Example: 278530, Loss: 0.001\n",
            "Epoch: 278, Batch: 35049, Example: 278724, Loss: 0.001\n",
            "Epoch: 278, Batch: 35074, Example: 278924, Loss: 0.002\n",
            "Epoch: 278, Batch: 35099, Example: 279124, Loss: 0.002\n",
            "Epoch: 278, Batch: 35124, Example: 279324, Loss: 0.001\n",
            "Epoch: 278, Batch: 35149, Example: 279524, Loss: 0.000\n",
            "Epoch: 279, Batch: 35174, Example: 279718, Loss: 0.001\n",
            "Epoch: 279, Batch: 35199, Example: 279918, Loss: 0.001\n",
            "Epoch: 279, Batch: 35224, Example: 280118, Loss: 0.001\n",
            "Epoch: 279, Batch: 35249, Example: 280318, Loss: 0.000\n",
            "Epoch: 279, Batch: 35274, Example: 280518, Loss: 0.001\n",
            "Epoch: 280, Batch: 35299, Example: 280712, Loss: 0.002\n",
            "Epoch: 280, Batch: 35324, Example: 280912, Loss: 0.002\n",
            "Epoch: 280, Batch: 35349, Example: 281112, Loss: 0.001\n",
            "Epoch: 280, Batch: 35374, Example: 281312, Loss: 0.002\n",
            "Epoch: 280, Batch: 35399, Example: 281512, Loss: 0.001\n",
            "Accuracy of the model at epoch 280: 97.60479041916167%\n",
            "Epoch: 281, Batch: 35424, Example: 281706, Loss: 0.000\n",
            "Epoch: 281, Batch: 35449, Example: 281906, Loss: 0.001\n",
            "Epoch: 281, Batch: 35474, Example: 282106, Loss: 0.000\n",
            "Epoch: 281, Batch: 35499, Example: 282306, Loss: 0.001\n",
            "Epoch: 281, Batch: 35524, Example: 282506, Loss: 0.000\n",
            "Epoch: 282, Batch: 35549, Example: 282700, Loss: 0.001\n",
            "Epoch: 282, Batch: 35574, Example: 282900, Loss: 0.001\n",
            "Epoch: 282, Batch: 35599, Example: 283100, Loss: 0.000\n",
            "Epoch: 282, Batch: 35624, Example: 283300, Loss: 0.000\n",
            "Epoch: 282, Batch: 35649, Example: 283500, Loss: 0.001\n",
            "Epoch: 283, Batch: 35674, Example: 283694, Loss: 0.000\n",
            "Epoch: 283, Batch: 35699, Example: 283894, Loss: 0.001\n",
            "Epoch: 283, Batch: 35724, Example: 284094, Loss: 0.000\n",
            "Epoch: 283, Batch: 35749, Example: 284294, Loss: 0.001\n",
            "Epoch: 283, Batch: 35774, Example: 284494, Loss: 0.001\n",
            "Epoch: 284, Batch: 35799, Example: 284688, Loss: 0.000\n",
            "Epoch: 284, Batch: 35824, Example: 284888, Loss: 0.000\n",
            "Epoch: 284, Batch: 35849, Example: 285088, Loss: 0.001\n",
            "Epoch: 284, Batch: 35874, Example: 285288, Loss: 0.001\n",
            "Epoch: 284, Batch: 35899, Example: 285488, Loss: 0.001\n",
            "Epoch: 285, Batch: 35924, Example: 285682, Loss: 0.001\n",
            "Epoch: 285, Batch: 35949, Example: 285882, Loss: 0.000\n",
            "Epoch: 285, Batch: 35974, Example: 286082, Loss: 0.001\n",
            "Epoch: 285, Batch: 35999, Example: 286282, Loss: 0.002\n",
            "Epoch: 285, Batch: 36024, Example: 286482, Loss: 0.000\n",
            "Accuracy of the model at epoch 285: 90.81836327345309%\n",
            "Epoch: 286, Batch: 36049, Example: 286676, Loss: 0.000\n",
            "Epoch: 286, Batch: 36074, Example: 286876, Loss: 0.002\n",
            "Epoch: 286, Batch: 36099, Example: 287076, Loss: 0.001\n",
            "Epoch: 286, Batch: 36124, Example: 287276, Loss: 0.001\n",
            "Epoch: 286, Batch: 36149, Example: 287476, Loss: 0.000\n",
            "Epoch: 287, Batch: 36174, Example: 287670, Loss: 0.000\n",
            "Epoch: 287, Batch: 36199, Example: 287870, Loss: 0.000\n",
            "Epoch: 287, Batch: 36224, Example: 288070, Loss: 0.001\n",
            "Epoch: 287, Batch: 36249, Example: 288270, Loss: 0.001\n",
            "Epoch: 287, Batch: 36274, Example: 288470, Loss: 0.001\n",
            "Epoch: 288, Batch: 36299, Example: 288664, Loss: 0.001\n",
            "Epoch: 288, Batch: 36324, Example: 288864, Loss: 0.001\n",
            "Epoch: 288, Batch: 36349, Example: 289064, Loss: 0.000\n",
            "Epoch: 288, Batch: 36374, Example: 289264, Loss: 0.001\n",
            "Epoch: 288, Batch: 36399, Example: 289464, Loss: 0.000\n",
            "Epoch: 289, Batch: 36424, Example: 289658, Loss: 0.001\n",
            "Epoch: 289, Batch: 36449, Example: 289858, Loss: 0.000\n",
            "Epoch: 289, Batch: 36474, Example: 290058, Loss: 0.001\n",
            "Epoch: 289, Batch: 36499, Example: 290258, Loss: 0.000\n",
            "Epoch: 289, Batch: 36524, Example: 290458, Loss: 0.000\n",
            "Epoch: 290, Batch: 36549, Example: 290652, Loss: 0.001\n",
            "Epoch: 290, Batch: 36574, Example: 290852, Loss: 0.001\n",
            "Epoch: 290, Batch: 36599, Example: 291052, Loss: 0.000\n",
            "Epoch: 290, Batch: 36624, Example: 291252, Loss: 0.001\n",
            "Epoch: 290, Batch: 36649, Example: 291452, Loss: 0.000\n",
            "Accuracy of the model at epoch 290: 98.10379241516966%\n",
            "Epoch: 291, Batch: 36674, Example: 291646, Loss: 0.001\n",
            "Epoch: 291, Batch: 36699, Example: 291846, Loss: 0.001\n",
            "Epoch: 291, Batch: 36724, Example: 292046, Loss: 0.000\n",
            "Epoch: 291, Batch: 36749, Example: 292246, Loss: 0.001\n",
            "Epoch: 291, Batch: 36774, Example: 292446, Loss: 0.001\n",
            "Epoch: 292, Batch: 36799, Example: 292640, Loss: 0.001\n",
            "Epoch: 292, Batch: 36824, Example: 292840, Loss: 0.001\n",
            "Epoch: 292, Batch: 36849, Example: 293040, Loss: 0.001\n",
            "Epoch: 292, Batch: 36874, Example: 293240, Loss: 0.000\n",
            "Epoch: 292, Batch: 36899, Example: 293440, Loss: 0.001\n",
            "Epoch: 293, Batch: 36924, Example: 293634, Loss: 0.000\n",
            "Epoch: 293, Batch: 36949, Example: 293834, Loss: 0.000\n",
            "Epoch: 293, Batch: 36974, Example: 294034, Loss: 0.001\n",
            "Epoch: 293, Batch: 36999, Example: 294234, Loss: 0.001\n",
            "Epoch: 293, Batch: 37024, Example: 294434, Loss: 0.002\n",
            "Epoch: 294, Batch: 37049, Example: 294628, Loss: 0.001\n",
            "Epoch: 294, Batch: 37074, Example: 294828, Loss: 0.000\n",
            "Epoch: 294, Batch: 37099, Example: 295028, Loss: 0.000\n",
            "Epoch: 294, Batch: 37124, Example: 295228, Loss: 0.001\n",
            "Epoch: 294, Batch: 37149, Example: 295428, Loss: 0.002\n",
            "Epoch: 295, Batch: 37174, Example: 295622, Loss: 0.002\n",
            "Epoch: 295, Batch: 37199, Example: 295822, Loss: 0.001\n",
            "Epoch: 295, Batch: 37224, Example: 296022, Loss: 0.000\n",
            "Epoch: 295, Batch: 37249, Example: 296222, Loss: 0.001\n",
            "Epoch: 295, Batch: 37274, Example: 296422, Loss: 0.001\n",
            "Accuracy of the model at epoch 295: 95.40918163672654%\n",
            "Epoch: 296, Batch: 37299, Example: 296616, Loss: 0.000\n",
            "Epoch: 296, Batch: 37324, Example: 296816, Loss: 0.000\n",
            "Epoch: 296, Batch: 37349, Example: 297016, Loss: 0.001\n",
            "Epoch: 296, Batch: 37374, Example: 297216, Loss: 0.000\n",
            "Epoch: 296, Batch: 37399, Example: 297416, Loss: 0.001\n",
            "Epoch: 297, Batch: 37424, Example: 297610, Loss: 0.000\n",
            "Epoch: 297, Batch: 37449, Example: 297810, Loss: 0.000\n",
            "Epoch: 297, Batch: 37474, Example: 298010, Loss: 0.001\n",
            "Epoch: 297, Batch: 37499, Example: 298210, Loss: 0.000\n",
            "Epoch: 297, Batch: 37524, Example: 298410, Loss: 0.001\n",
            "Epoch: 298, Batch: 37549, Example: 298604, Loss: 0.000\n",
            "Epoch: 298, Batch: 37574, Example: 298804, Loss: 0.000\n",
            "Epoch: 298, Batch: 37599, Example: 299004, Loss: 0.001\n",
            "Epoch: 298, Batch: 37624, Example: 299204, Loss: 0.001\n",
            "Epoch: 298, Batch: 37649, Example: 299404, Loss: 0.002\n",
            "Epoch: 298, Batch: 37674, Example: 299598, Loss: 0.000\n",
            "Epoch: 299, Batch: 37699, Example: 299798, Loss: 0.000\n",
            "Epoch: 299, Batch: 37724, Example: 299998, Loss: 0.000\n",
            "Epoch: 299, Batch: 37749, Example: 300198, Loss: 0.001\n",
            "Epoch: 299, Batch: 37774, Example: 300398, Loss: 0.000\n",
            "Epoch: 299, Batch: 37799, Example: 300598, Loss: 0.000\n",
            "Epoch: 300, Batch: 37824, Example: 300792, Loss: 0.000\n",
            "Epoch: 300, Batch: 37849, Example: 300992, Loss: 0.002\n",
            "Epoch: 300, Batch: 37874, Example: 301192, Loss: 0.001\n",
            "Epoch: 300, Batch: 37899, Example: 301392, Loss: 0.001\n",
            "Epoch: 300, Batch: 37924, Example: 301592, Loss: 0.000\n",
            "Accuracy of the model at epoch 300: 99.40119760479043%\n",
            "Epoch: 301, Batch: 37949, Example: 301786, Loss: 0.001\n",
            "Epoch: 301, Batch: 37974, Example: 301986, Loss: 0.001\n",
            "Epoch: 301, Batch: 37999, Example: 302186, Loss: 0.000\n",
            "Epoch: 301, Batch: 38024, Example: 302386, Loss: 0.001\n",
            "Epoch: 301, Batch: 38049, Example: 302586, Loss: 0.000\n",
            "Epoch: 302, Batch: 38074, Example: 302780, Loss: 0.001\n",
            "Epoch: 302, Batch: 38099, Example: 302980, Loss: 0.000\n",
            "Epoch: 302, Batch: 38124, Example: 303180, Loss: 0.001\n",
            "Epoch: 302, Batch: 38149, Example: 303380, Loss: 0.000\n",
            "Epoch: 302, Batch: 38174, Example: 303580, Loss: 0.000\n",
            "Epoch: 303, Batch: 38199, Example: 303774, Loss: 0.001\n",
            "Epoch: 303, Batch: 38224, Example: 303974, Loss: 0.003\n",
            "Epoch: 303, Batch: 38249, Example: 304174, Loss: 0.001\n",
            "Epoch: 303, Batch: 38274, Example: 304374, Loss: 0.001\n",
            "Epoch: 303, Batch: 38299, Example: 304574, Loss: 0.000\n",
            "Epoch: 304, Batch: 38324, Example: 304768, Loss: 0.000\n",
            "Epoch: 304, Batch: 38349, Example: 304968, Loss: 0.000\n",
            "Epoch: 304, Batch: 38374, Example: 305168, Loss: 0.001\n",
            "Epoch: 304, Batch: 38399, Example: 305368, Loss: 0.000\n",
            "Epoch: 304, Batch: 38424, Example: 305568, Loss: 0.000\n",
            "Epoch: 305, Batch: 38449, Example: 305762, Loss: 0.001\n",
            "Epoch: 305, Batch: 38474, Example: 305962, Loss: 0.001\n",
            "Epoch: 305, Batch: 38499, Example: 306162, Loss: 0.000\n",
            "Epoch: 305, Batch: 38524, Example: 306362, Loss: 0.001\n",
            "Epoch: 305, Batch: 38549, Example: 306562, Loss: 0.000\n",
            "Accuracy of the model at epoch 305: 95.00998003992017%\n",
            "Epoch: 306, Batch: 38574, Example: 306756, Loss: 0.001\n",
            "Epoch: 306, Batch: 38599, Example: 306956, Loss: 0.000\n",
            "Epoch: 306, Batch: 38624, Example: 307156, Loss: 0.000\n",
            "Epoch: 306, Batch: 38649, Example: 307356, Loss: 0.001\n",
            "Epoch: 306, Batch: 38674, Example: 307556, Loss: 0.000\n",
            "Epoch: 307, Batch: 38699, Example: 307750, Loss: 0.001\n",
            "Epoch: 307, Batch: 38724, Example: 307950, Loss: 0.000\n",
            "Epoch: 307, Batch: 38749, Example: 308150, Loss: 0.001\n",
            "Epoch: 307, Batch: 38774, Example: 308350, Loss: 0.001\n",
            "Epoch: 307, Batch: 38799, Example: 308550, Loss: 0.000\n",
            "Epoch: 308, Batch: 38824, Example: 308744, Loss: 0.001\n",
            "Epoch: 308, Batch: 38849, Example: 308944, Loss: 0.000\n",
            "Epoch: 308, Batch: 38874, Example: 309144, Loss: 0.001\n",
            "Epoch: 308, Batch: 38899, Example: 309344, Loss: 0.000\n",
            "Epoch: 308, Batch: 38924, Example: 309544, Loss: 0.000\n",
            "Epoch: 309, Batch: 38949, Example: 309738, Loss: 0.000\n",
            "Epoch: 309, Batch: 38974, Example: 309938, Loss: 0.000\n",
            "Epoch: 309, Batch: 38999, Example: 310138, Loss: 0.000\n",
            "Epoch: 309, Batch: 39024, Example: 310338, Loss: 0.001\n",
            "Epoch: 309, Batch: 39049, Example: 310538, Loss: 0.000\n",
            "Epoch: 310, Batch: 39074, Example: 310732, Loss: 0.001\n",
            "Epoch: 310, Batch: 39099, Example: 310932, Loss: 0.001\n",
            "Epoch: 310, Batch: 39124, Example: 311132, Loss: 0.001\n",
            "Epoch: 310, Batch: 39149, Example: 311332, Loss: 0.000\n",
            "Epoch: 310, Batch: 39174, Example: 311532, Loss: 0.001\n",
            "Accuracy of the model at epoch 310: 97.0059880239521%\n",
            "Epoch: 311, Batch: 39199, Example: 311726, Loss: 0.001\n",
            "Epoch: 311, Batch: 39224, Example: 311926, Loss: 0.000\n",
            "Epoch: 311, Batch: 39249, Example: 312126, Loss: 0.001\n",
            "Epoch: 311, Batch: 39274, Example: 312326, Loss: 0.000\n",
            "Epoch: 311, Batch: 39299, Example: 312526, Loss: 0.001\n",
            "Epoch: 312, Batch: 39324, Example: 312720, Loss: 0.000\n",
            "Epoch: 312, Batch: 39349, Example: 312920, Loss: 0.000\n",
            "Epoch: 312, Batch: 39374, Example: 313120, Loss: 0.000\n",
            "Epoch: 312, Batch: 39399, Example: 313320, Loss: 0.000\n",
            "Epoch: 312, Batch: 39424, Example: 313520, Loss: 0.000\n",
            "Epoch: 313, Batch: 39449, Example: 313714, Loss: 0.003\n",
            "Epoch: 313, Batch: 39474, Example: 313914, Loss: 0.001\n",
            "Epoch: 313, Batch: 39499, Example: 314114, Loss: 0.000\n",
            "Epoch: 313, Batch: 39524, Example: 314314, Loss: 0.000\n",
            "Epoch: 313, Batch: 39549, Example: 314514, Loss: 0.001\n",
            "Epoch: 314, Batch: 39574, Example: 314708, Loss: 0.000\n",
            "Epoch: 314, Batch: 39599, Example: 314908, Loss: 0.001\n",
            "Epoch: 314, Batch: 39624, Example: 315108, Loss: 0.001\n",
            "Epoch: 314, Batch: 39649, Example: 315308, Loss: 0.001\n",
            "Epoch: 314, Batch: 39674, Example: 315508, Loss: 0.001\n",
            "Epoch: 315, Batch: 39699, Example: 315702, Loss: 0.001\n",
            "Epoch: 315, Batch: 39724, Example: 315902, Loss: 0.000\n",
            "Epoch: 315, Batch: 39749, Example: 316102, Loss: 0.001\n",
            "Epoch: 315, Batch: 39774, Example: 316302, Loss: 0.001\n",
            "Epoch: 315, Batch: 39799, Example: 316502, Loss: 0.001\n",
            "Accuracy of the model at epoch 315: 83.33333333333333%\n",
            "Epoch: 316, Batch: 39824, Example: 316696, Loss: 0.000\n",
            "Epoch: 316, Batch: 39849, Example: 316896, Loss: 0.002\n",
            "Epoch: 316, Batch: 39874, Example: 317096, Loss: 0.001\n",
            "Epoch: 316, Batch: 39899, Example: 317296, Loss: 0.000\n",
            "Epoch: 316, Batch: 39924, Example: 317496, Loss: 0.001\n",
            "Epoch: 317, Batch: 39949, Example: 317690, Loss: 0.001\n",
            "Epoch: 317, Batch: 39974, Example: 317890, Loss: 0.000\n",
            "Epoch: 317, Batch: 39999, Example: 318090, Loss: 0.000\n",
            "Epoch: 317, Batch: 40024, Example: 318290, Loss: 0.000\n",
            "Epoch: 317, Batch: 40049, Example: 318490, Loss: 0.000\n",
            "Epoch: 318, Batch: 40074, Example: 318684, Loss: 0.001\n",
            "Epoch: 318, Batch: 40099, Example: 318884, Loss: 0.000\n",
            "Epoch: 318, Batch: 40124, Example: 319084, Loss: 0.001\n",
            "Epoch: 318, Batch: 40149, Example: 319284, Loss: 0.000\n",
            "Epoch: 318, Batch: 40174, Example: 319484, Loss: 0.000\n",
            "Epoch: 319, Batch: 40199, Example: 319678, Loss: 0.001\n",
            "Epoch: 319, Batch: 40224, Example: 319878, Loss: 0.001\n",
            "Epoch: 319, Batch: 40249, Example: 320078, Loss: 0.000\n",
            "Epoch: 319, Batch: 40274, Example: 320278, Loss: 0.000\n",
            "Epoch: 319, Batch: 40299, Example: 320478, Loss: 0.001\n",
            "Epoch: 320, Batch: 40324, Example: 320672, Loss: 0.000\n",
            "Epoch: 320, Batch: 40349, Example: 320872, Loss: 0.000\n",
            "Epoch: 320, Batch: 40374, Example: 321072, Loss: 0.000\n",
            "Epoch: 320, Batch: 40399, Example: 321272, Loss: 0.001\n",
            "Epoch: 320, Batch: 40424, Example: 321472, Loss: 0.000\n",
            "Accuracy of the model at epoch 320: 98.70259481037924%\n",
            "Epoch: 321, Batch: 40449, Example: 321666, Loss: 0.001\n",
            "Epoch: 321, Batch: 40474, Example: 321866, Loss: 0.000\n",
            "Epoch: 321, Batch: 40499, Example: 322066, Loss: 0.000\n",
            "Epoch: 321, Batch: 40524, Example: 322266, Loss: 0.001\n",
            "Epoch: 321, Batch: 40549, Example: 322466, Loss: 0.000\n",
            "Epoch: 322, Batch: 40574, Example: 322660, Loss: 0.001\n",
            "Epoch: 322, Batch: 40599, Example: 322860, Loss: 0.000\n",
            "Epoch: 322, Batch: 40624, Example: 323060, Loss: 0.000\n",
            "Epoch: 322, Batch: 40649, Example: 323260, Loss: 0.000\n",
            "Epoch: 322, Batch: 40674, Example: 323460, Loss: 0.000\n",
            "Epoch: 323, Batch: 40699, Example: 323654, Loss: 0.001\n",
            "Epoch: 323, Batch: 40724, Example: 323854, Loss: 0.000\n",
            "Epoch: 323, Batch: 40749, Example: 324054, Loss: 0.000\n",
            "Epoch: 323, Batch: 40774, Example: 324254, Loss: 0.000\n",
            "Epoch: 323, Batch: 40799, Example: 324454, Loss: 0.001\n",
            "Epoch: 323, Batch: 40824, Example: 324648, Loss: 0.000\n",
            "Epoch: 324, Batch: 40849, Example: 324848, Loss: 0.001\n",
            "Epoch: 324, Batch: 40874, Example: 325048, Loss: 0.000\n",
            "Epoch: 324, Batch: 40899, Example: 325248, Loss: 0.001\n",
            "Epoch: 324, Batch: 40924, Example: 325448, Loss: 0.000\n",
            "Epoch: 324, Batch: 40949, Example: 325648, Loss: 0.001\n",
            "Epoch: 325, Batch: 40974, Example: 325842, Loss: 0.001\n",
            "Epoch: 325, Batch: 40999, Example: 326042, Loss: 0.000\n",
            "Epoch: 325, Batch: 41024, Example: 326242, Loss: 0.000\n",
            "Epoch: 325, Batch: 41049, Example: 326442, Loss: 0.000\n",
            "Epoch: 325, Batch: 41074, Example: 326642, Loss: 0.000\n",
            "Accuracy of the model at epoch 325: 94.61077844311377%\n",
            "Epoch: 326, Batch: 41099, Example: 326836, Loss: 0.000\n",
            "Epoch: 326, Batch: 41124, Example: 327036, Loss: 0.001\n",
            "Epoch: 326, Batch: 41149, Example: 327236, Loss: 0.001\n",
            "Epoch: 326, Batch: 41174, Example: 327436, Loss: 0.001\n",
            "Epoch: 326, Batch: 41199, Example: 327636, Loss: 0.001\n",
            "Epoch: 327, Batch: 41224, Example: 327830, Loss: 0.001\n",
            "Epoch: 327, Batch: 41249, Example: 328030, Loss: 0.000\n",
            "Epoch: 327, Batch: 41274, Example: 328230, Loss: 0.001\n",
            "Epoch: 327, Batch: 41299, Example: 328430, Loss: 0.001\n",
            "Epoch: 327, Batch: 41324, Example: 328630, Loss: 0.000\n",
            "Epoch: 328, Batch: 41349, Example: 328824, Loss: 0.001\n",
            "Epoch: 328, Batch: 41374, Example: 329024, Loss: 0.000\n",
            "Epoch: 328, Batch: 41399, Example: 329224, Loss: 0.001\n",
            "Epoch: 328, Batch: 41424, Example: 329424, Loss: 0.000\n",
            "Epoch: 328, Batch: 41449, Example: 329624, Loss: 0.001\n",
            "Epoch: 329, Batch: 41474, Example: 329818, Loss: 0.001\n",
            "Epoch: 329, Batch: 41499, Example: 330018, Loss: 0.001\n",
            "Epoch: 329, Batch: 41524, Example: 330218, Loss: 0.001\n",
            "Epoch: 329, Batch: 41549, Example: 330418, Loss: 0.001\n",
            "Epoch: 329, Batch: 41574, Example: 330618, Loss: 0.001\n",
            "Epoch: 330, Batch: 41599, Example: 330812, Loss: 0.000\n",
            "Epoch: 330, Batch: 41624, Example: 331012, Loss: 0.000\n",
            "Epoch: 330, Batch: 41649, Example: 331212, Loss: 0.001\n",
            "Epoch: 330, Batch: 41674, Example: 331412, Loss: 0.000\n",
            "Epoch: 330, Batch: 41699, Example: 331612, Loss: 0.001\n",
            "Accuracy of the model at epoch 330: 98.80239520958084%\n",
            "Epoch: 331, Batch: 41724, Example: 331806, Loss: 0.001\n",
            "Epoch: 331, Batch: 41749, Example: 332006, Loss: 0.000\n",
            "Epoch: 331, Batch: 41774, Example: 332206, Loss: 0.001\n",
            "Epoch: 331, Batch: 41799, Example: 332406, Loss: 0.000\n",
            "Epoch: 331, Batch: 41824, Example: 332606, Loss: 0.001\n",
            "Epoch: 332, Batch: 41849, Example: 332800, Loss: 0.001\n",
            "Epoch: 332, Batch: 41874, Example: 333000, Loss: 0.000\n",
            "Epoch: 332, Batch: 41899, Example: 333200, Loss: 0.000\n",
            "Epoch: 332, Batch: 41924, Example: 333400, Loss: 0.001\n",
            "Epoch: 332, Batch: 41949, Example: 333600, Loss: 0.001\n",
            "Epoch: 333, Batch: 41974, Example: 333794, Loss: 0.001\n",
            "Epoch: 333, Batch: 41999, Example: 333994, Loss: 0.002\n",
            "Epoch: 333, Batch: 42024, Example: 334194, Loss: 0.002\n",
            "Epoch: 333, Batch: 42049, Example: 334394, Loss: 0.001\n",
            "Epoch: 333, Batch: 42074, Example: 334594, Loss: 0.000\n",
            "Epoch: 334, Batch: 42099, Example: 334788, Loss: 0.001\n",
            "Epoch: 334, Batch: 42124, Example: 334988, Loss: 0.000\n",
            "Epoch: 334, Batch: 42149, Example: 335188, Loss: 0.001\n",
            "Epoch: 334, Batch: 42174, Example: 335388, Loss: 0.000\n",
            "Epoch: 334, Batch: 42199, Example: 335588, Loss: 0.000\n",
            "Epoch: 335, Batch: 42224, Example: 335782, Loss: 0.000\n",
            "Epoch: 335, Batch: 42249, Example: 335982, Loss: 0.001\n",
            "Epoch: 335, Batch: 42274, Example: 336182, Loss: 0.001\n",
            "Epoch: 335, Batch: 42299, Example: 336382, Loss: 0.001\n",
            "Epoch: 335, Batch: 42324, Example: 336582, Loss: 0.000\n",
            "Accuracy of the model at epoch 335: 97.1057884231537%\n",
            "Epoch: 336, Batch: 42349, Example: 336776, Loss: 0.002\n",
            "Epoch: 336, Batch: 42374, Example: 336976, Loss: 0.001\n",
            "Epoch: 336, Batch: 42399, Example: 337176, Loss: 0.000\n",
            "Epoch: 336, Batch: 42424, Example: 337376, Loss: 0.000\n",
            "Epoch: 336, Batch: 42449, Example: 337576, Loss: 0.000\n",
            "Epoch: 337, Batch: 42474, Example: 337770, Loss: 0.000\n",
            "Epoch: 337, Batch: 42499, Example: 337970, Loss: 0.002\n",
            "Epoch: 337, Batch: 42524, Example: 338170, Loss: 0.001\n",
            "Epoch: 337, Batch: 42549, Example: 338370, Loss: 0.000\n",
            "Epoch: 337, Batch: 42574, Example: 338570, Loss: 0.000\n",
            "Epoch: 338, Batch: 42599, Example: 338764, Loss: 0.000\n",
            "Epoch: 338, Batch: 42624, Example: 338964, Loss: 0.001\n",
            "Epoch: 338, Batch: 42649, Example: 339164, Loss: 0.001\n",
            "Epoch: 338, Batch: 42674, Example: 339364, Loss: 0.001\n",
            "Epoch: 338, Batch: 42699, Example: 339564, Loss: 0.000\n",
            "Epoch: 339, Batch: 42724, Example: 339758, Loss: 0.000\n",
            "Epoch: 339, Batch: 42749, Example: 339958, Loss: 0.001\n",
            "Epoch: 339, Batch: 42774, Example: 340158, Loss: 0.000\n",
            "Epoch: 339, Batch: 42799, Example: 340358, Loss: 0.000\n",
            "Epoch: 339, Batch: 42824, Example: 340558, Loss: 0.000\n",
            "Epoch: 340, Batch: 42849, Example: 340752, Loss: 0.001\n",
            "Epoch: 340, Batch: 42874, Example: 340952, Loss: 0.001\n",
            "Epoch: 340, Batch: 42899, Example: 341152, Loss: 0.001\n",
            "Epoch: 340, Batch: 42924, Example: 341352, Loss: 0.000\n",
            "Epoch: 340, Batch: 42949, Example: 341552, Loss: 0.000\n",
            "Accuracy of the model at epoch 340: 98.60279441117764%\n",
            "Epoch: 341, Batch: 42974, Example: 341746, Loss: 0.000\n",
            "Epoch: 341, Batch: 42999, Example: 341946, Loss: 0.001\n",
            "Epoch: 341, Batch: 43024, Example: 342146, Loss: 0.000\n",
            "Epoch: 341, Batch: 43049, Example: 342346, Loss: 0.000\n",
            "Epoch: 341, Batch: 43074, Example: 342546, Loss: 0.000\n",
            "Epoch: 342, Batch: 43099, Example: 342740, Loss: 0.000\n",
            "Epoch: 342, Batch: 43124, Example: 342940, Loss: 0.001\n",
            "Epoch: 342, Batch: 43149, Example: 343140, Loss: 0.001\n",
            "Epoch: 342, Batch: 43174, Example: 343340, Loss: 0.001\n",
            "Epoch: 342, Batch: 43199, Example: 343540, Loss: 0.001\n",
            "Epoch: 343, Batch: 43224, Example: 343734, Loss: 0.001\n",
            "Epoch: 343, Batch: 43249, Example: 343934, Loss: 0.001\n",
            "Epoch: 343, Batch: 43274, Example: 344134, Loss: 0.001\n",
            "Epoch: 343, Batch: 43299, Example: 344334, Loss: 0.001\n",
            "Epoch: 343, Batch: 43324, Example: 344534, Loss: 0.001\n",
            "Epoch: 344, Batch: 43349, Example: 344728, Loss: 0.001\n",
            "Epoch: 344, Batch: 43374, Example: 344928, Loss: 0.000\n",
            "Epoch: 344, Batch: 43399, Example: 345128, Loss: 0.000\n",
            "Epoch: 344, Batch: 43424, Example: 345328, Loss: 0.001\n",
            "Epoch: 344, Batch: 43449, Example: 345528, Loss: 0.000\n",
            "Epoch: 345, Batch: 43474, Example: 345722, Loss: 0.000\n",
            "Epoch: 345, Batch: 43499, Example: 345922, Loss: 0.001\n",
            "Epoch: 345, Batch: 43524, Example: 346122, Loss: 0.000\n",
            "Epoch: 345, Batch: 43549, Example: 346322, Loss: 0.001\n",
            "Epoch: 345, Batch: 43574, Example: 346522, Loss: 0.001\n",
            "Accuracy of the model at epoch 345: 90.7185628742515%\n",
            "Epoch: 346, Batch: 43599, Example: 346716, Loss: 0.001\n",
            "Epoch: 346, Batch: 43624, Example: 346916, Loss: 0.000\n",
            "Epoch: 346, Batch: 43649, Example: 347116, Loss: 0.001\n",
            "Epoch: 346, Batch: 43674, Example: 347316, Loss: 0.000\n",
            "Epoch: 346, Batch: 43699, Example: 347516, Loss: 0.001\n",
            "Epoch: 347, Batch: 43724, Example: 347710, Loss: 0.000\n",
            "Epoch: 347, Batch: 43749, Example: 347910, Loss: 0.000\n",
            "Epoch: 347, Batch: 43774, Example: 348110, Loss: 0.001\n",
            "Epoch: 347, Batch: 43799, Example: 348310, Loss: 0.000\n",
            "Epoch: 347, Batch: 43824, Example: 348510, Loss: 0.001\n",
            "Epoch: 348, Batch: 43849, Example: 348704, Loss: 0.001\n",
            "Epoch: 348, Batch: 43874, Example: 348904, Loss: 0.000\n",
            "Epoch: 348, Batch: 43899, Example: 349104, Loss: 0.001\n",
            "Epoch: 348, Batch: 43924, Example: 349304, Loss: 0.000\n",
            "Epoch: 348, Batch: 43949, Example: 349504, Loss: 0.000\n",
            "Epoch: 348, Batch: 43974, Example: 349698, Loss: 0.000\n",
            "Epoch: 349, Batch: 43999, Example: 349898, Loss: 0.000\n",
            "Epoch: 349, Batch: 44024, Example: 350098, Loss: 0.000\n",
            "Epoch: 349, Batch: 44049, Example: 350298, Loss: 0.000\n",
            "Epoch: 349, Batch: 44074, Example: 350498, Loss: 0.000\n",
            "Epoch: 349, Batch: 44099, Example: 350698, Loss: 0.000\n",
            "Epoch: 350, Batch: 44124, Example: 350892, Loss: 0.001\n",
            "Epoch: 350, Batch: 44149, Example: 351092, Loss: 0.000\n",
            "Epoch: 350, Batch: 44174, Example: 351292, Loss: 0.000\n",
            "Epoch: 350, Batch: 44199, Example: 351492, Loss: 0.000\n",
            "Epoch: 350, Batch: 44224, Example: 351692, Loss: 0.001\n",
            "Accuracy of the model at epoch 350: 99.40119760479043%\n",
            "Epoch: 351, Batch: 44249, Example: 351886, Loss: 0.001\n",
            "Epoch: 351, Batch: 44274, Example: 352086, Loss: 0.000\n",
            "Epoch: 351, Batch: 44299, Example: 352286, Loss: 0.000\n",
            "Epoch: 351, Batch: 44324, Example: 352486, Loss: 0.000\n",
            "Epoch: 351, Batch: 44349, Example: 352686, Loss: 0.000\n",
            "Epoch: 352, Batch: 44374, Example: 352880, Loss: 0.000\n",
            "Epoch: 352, Batch: 44399, Example: 353080, Loss: 0.000\n",
            "Epoch: 352, Batch: 44424, Example: 353280, Loss: 0.001\n",
            "Epoch: 352, Batch: 44449, Example: 353480, Loss: 0.000\n",
            "Epoch: 352, Batch: 44474, Example: 353680, Loss: 0.001\n",
            "Epoch: 353, Batch: 44499, Example: 353874, Loss: 0.001\n",
            "Epoch: 353, Batch: 44524, Example: 354074, Loss: 0.000\n",
            "Epoch: 353, Batch: 44549, Example: 354274, Loss: 0.001\n",
            "Epoch: 353, Batch: 44574, Example: 354474, Loss: 0.000\n",
            "Epoch: 353, Batch: 44599, Example: 354674, Loss: 0.000\n",
            "Epoch: 354, Batch: 44624, Example: 354868, Loss: 0.000\n",
            "Epoch: 354, Batch: 44649, Example: 355068, Loss: 0.000\n",
            "Epoch: 354, Batch: 44674, Example: 355268, Loss: 0.001\n",
            "Epoch: 354, Batch: 44699, Example: 355468, Loss: 0.000\n",
            "Epoch: 354, Batch: 44724, Example: 355668, Loss: 0.001\n",
            "Epoch: 355, Batch: 44749, Example: 355862, Loss: 0.001\n",
            "Epoch: 355, Batch: 44774, Example: 356062, Loss: 0.000\n",
            "Epoch: 355, Batch: 44799, Example: 356262, Loss: 0.000\n",
            "Epoch: 355, Batch: 44824, Example: 356462, Loss: 0.000\n",
            "Epoch: 355, Batch: 44849, Example: 356662, Loss: 0.001\n",
            "Accuracy of the model at epoch 355: 95.80838323353294%\n",
            "Epoch: 356, Batch: 44874, Example: 356856, Loss: 0.000\n",
            "Epoch: 356, Batch: 44899, Example: 357056, Loss: 0.000\n",
            "Epoch: 356, Batch: 44924, Example: 357256, Loss: 0.000\n",
            "Epoch: 356, Batch: 44949, Example: 357456, Loss: 0.000\n",
            "Epoch: 356, Batch: 44974, Example: 357656, Loss: 0.001\n",
            "Epoch: 357, Batch: 44999, Example: 357850, Loss: 0.000\n",
            "Epoch: 357, Batch: 45024, Example: 358050, Loss: 0.000\n",
            "Epoch: 357, Batch: 45049, Example: 358250, Loss: 0.001\n",
            "Epoch: 357, Batch: 45074, Example: 358450, Loss: 0.001\n",
            "Epoch: 357, Batch: 45099, Example: 358650, Loss: 0.000\n",
            "Epoch: 358, Batch: 45124, Example: 358844, Loss: 0.001\n",
            "Epoch: 358, Batch: 45149, Example: 359044, Loss: 0.000\n",
            "Epoch: 358, Batch: 45174, Example: 359244, Loss: 0.000\n",
            "Epoch: 358, Batch: 45199, Example: 359444, Loss: 0.000\n",
            "Epoch: 358, Batch: 45224, Example: 359644, Loss: 0.001\n",
            "Epoch: 359, Batch: 45249, Example: 359838, Loss: 0.000\n",
            "Epoch: 359, Batch: 45274, Example: 360038, Loss: 0.001\n",
            "Epoch: 359, Batch: 45299, Example: 360238, Loss: 0.000\n",
            "Epoch: 359, Batch: 45324, Example: 360438, Loss: 0.000\n",
            "Epoch: 359, Batch: 45349, Example: 360638, Loss: 0.001\n",
            "Epoch: 360, Batch: 45374, Example: 360832, Loss: 0.000\n",
            "Epoch: 360, Batch: 45399, Example: 361032, Loss: 0.001\n",
            "Epoch: 360, Batch: 45424, Example: 361232, Loss: 0.000\n",
            "Epoch: 360, Batch: 45449, Example: 361432, Loss: 0.000\n",
            "Epoch: 360, Batch: 45474, Example: 361632, Loss: 0.000\n",
            "Accuracy of the model at epoch 360: 97.60479041916167%\n",
            "Epoch: 361, Batch: 45499, Example: 361826, Loss: 0.000\n",
            "Epoch: 361, Batch: 45524, Example: 362026, Loss: 0.000\n",
            "Epoch: 361, Batch: 45549, Example: 362226, Loss: 0.000\n",
            "Epoch: 361, Batch: 45574, Example: 362426, Loss: 0.001\n",
            "Epoch: 361, Batch: 45599, Example: 362626, Loss: 0.000\n",
            "Epoch: 362, Batch: 45624, Example: 362820, Loss: 0.000\n",
            "Epoch: 362, Batch: 45649, Example: 363020, Loss: 0.000\n",
            "Epoch: 362, Batch: 45674, Example: 363220, Loss: 0.001\n",
            "Epoch: 362, Batch: 45699, Example: 363420, Loss: 0.000\n",
            "Epoch: 362, Batch: 45724, Example: 363620, Loss: 0.000\n",
            "Epoch: 363, Batch: 45749, Example: 363814, Loss: 0.000\n",
            "Epoch: 363, Batch: 45774, Example: 364014, Loss: 0.000\n",
            "Epoch: 363, Batch: 45799, Example: 364214, Loss: 0.001\n",
            "Epoch: 363, Batch: 45824, Example: 364414, Loss: 0.000\n",
            "Epoch: 363, Batch: 45849, Example: 364614, Loss: 0.000\n",
            "Epoch: 364, Batch: 45874, Example: 364808, Loss: 0.000\n",
            "Epoch: 364, Batch: 45899, Example: 365008, Loss: 0.001\n",
            "Epoch: 364, Batch: 45924, Example: 365208, Loss: 0.001\n",
            "Epoch: 364, Batch: 45949, Example: 365408, Loss: 0.001\n",
            "Epoch: 364, Batch: 45974, Example: 365608, Loss: 0.001\n",
            "Epoch: 365, Batch: 45999, Example: 365802, Loss: 0.001\n",
            "Epoch: 365, Batch: 46024, Example: 366002, Loss: 0.000\n",
            "Epoch: 365, Batch: 46049, Example: 366202, Loss: 0.000\n",
            "Epoch: 365, Batch: 46074, Example: 366402, Loss: 0.001\n",
            "Epoch: 365, Batch: 46099, Example: 366602, Loss: 0.000\n",
            "Accuracy of the model at epoch 365: 98.20359281437126%\n",
            "Epoch: 366, Batch: 46124, Example: 366796, Loss: 0.001\n",
            "Epoch: 366, Batch: 46149, Example: 366996, Loss: 0.001\n",
            "Epoch: 366, Batch: 46174, Example: 367196, Loss: 0.000\n",
            "Epoch: 366, Batch: 46199, Example: 367396, Loss: 0.001\n",
            "Epoch: 366, Batch: 46224, Example: 367596, Loss: 0.000\n",
            "Epoch: 367, Batch: 46249, Example: 367790, Loss: 0.001\n",
            "Epoch: 367, Batch: 46274, Example: 367990, Loss: 0.001\n",
            "Epoch: 367, Batch: 46299, Example: 368190, Loss: 0.000\n",
            "Epoch: 367, Batch: 46324, Example: 368390, Loss: 0.000\n",
            "Epoch: 367, Batch: 46349, Example: 368590, Loss: 0.000\n",
            "Epoch: 368, Batch: 46374, Example: 368784, Loss: 0.000\n",
            "Epoch: 368, Batch: 46399, Example: 368984, Loss: 0.000\n",
            "Epoch: 368, Batch: 46424, Example: 369184, Loss: 0.000\n",
            "Epoch: 368, Batch: 46449, Example: 369384, Loss: 0.000\n",
            "Epoch: 368, Batch: 46474, Example: 369584, Loss: 0.000\n",
            "Epoch: 369, Batch: 46499, Example: 369778, Loss: 0.000\n",
            "Epoch: 369, Batch: 46524, Example: 369978, Loss: 0.001\n",
            "Epoch: 369, Batch: 46549, Example: 370178, Loss: 0.001\n",
            "Epoch: 369, Batch: 46574, Example: 370378, Loss: 0.000\n",
            "Epoch: 369, Batch: 46599, Example: 370578, Loss: 0.000\n",
            "Epoch: 370, Batch: 46624, Example: 370772, Loss: 0.003\n",
            "Epoch: 370, Batch: 46649, Example: 370972, Loss: 0.000\n",
            "Epoch: 370, Batch: 46674, Example: 371172, Loss: 0.000\n",
            "Epoch: 370, Batch: 46699, Example: 371372, Loss: 0.002\n",
            "Epoch: 370, Batch: 46724, Example: 371572, Loss: 0.001\n",
            "Accuracy of the model at epoch 370: 94.31137724550898%\n",
            "Epoch: 371, Batch: 46749, Example: 371766, Loss: 0.000\n",
            "Epoch: 371, Batch: 46774, Example: 371966, Loss: 0.001\n",
            "Epoch: 371, Batch: 46799, Example: 372166, Loss: 0.000\n",
            "Epoch: 371, Batch: 46824, Example: 372366, Loss: 0.000\n",
            "Epoch: 371, Batch: 46849, Example: 372566, Loss: 0.000\n",
            "Epoch: 372, Batch: 46874, Example: 372760, Loss: 0.000\n",
            "Epoch: 372, Batch: 46899, Example: 372960, Loss: 0.000\n",
            "Epoch: 372, Batch: 46924, Example: 373160, Loss: 0.002\n",
            "Epoch: 372, Batch: 46949, Example: 373360, Loss: 0.001\n",
            "Epoch: 372, Batch: 46974, Example: 373560, Loss: 0.001\n",
            "Epoch: 373, Batch: 46999, Example: 373754, Loss: 0.000\n",
            "Epoch: 373, Batch: 47024, Example: 373954, Loss: 0.001\n",
            "Epoch: 373, Batch: 47049, Example: 374154, Loss: 0.000\n",
            "Epoch: 373, Batch: 47074, Example: 374354, Loss: 0.000\n",
            "Epoch: 373, Batch: 47099, Example: 374554, Loss: 0.000\n",
            "Epoch: 373, Batch: 47124, Example: 374748, Loss: 0.000\n",
            "Epoch: 374, Batch: 47149, Example: 374948, Loss: 0.000\n",
            "Epoch: 374, Batch: 47174, Example: 375148, Loss: 0.000\n",
            "Epoch: 374, Batch: 47199, Example: 375348, Loss: 0.001\n",
            "Epoch: 374, Batch: 47224, Example: 375548, Loss: 0.001\n",
            "Epoch: 374, Batch: 47249, Example: 375748, Loss: 0.001\n",
            "Epoch: 375, Batch: 47274, Example: 375942, Loss: 0.000\n",
            "Epoch: 375, Batch: 47299, Example: 376142, Loss: 0.001\n",
            "Epoch: 375, Batch: 47324, Example: 376342, Loss: 0.000\n",
            "Epoch: 375, Batch: 47349, Example: 376542, Loss: 0.000\n",
            "Epoch: 375, Batch: 47374, Example: 376742, Loss: 0.001\n",
            "Accuracy of the model at epoch 375: 98.90219560878243%\n",
            "Epoch: 376, Batch: 47399, Example: 376936, Loss: 0.000\n",
            "Epoch: 376, Batch: 47424, Example: 377136, Loss: 0.001\n",
            "Epoch: 376, Batch: 47449, Example: 377336, Loss: 0.001\n",
            "Epoch: 376, Batch: 47474, Example: 377536, Loss: 0.000\n",
            "Epoch: 376, Batch: 47499, Example: 377736, Loss: 0.000\n",
            "Epoch: 377, Batch: 47524, Example: 377930, Loss: 0.000\n",
            "Epoch: 377, Batch: 47549, Example: 378130, Loss: 0.001\n",
            "Epoch: 377, Batch: 47574, Example: 378330, Loss: 0.000\n",
            "Epoch: 377, Batch: 47599, Example: 378530, Loss: 0.000\n",
            "Epoch: 377, Batch: 47624, Example: 378730, Loss: 0.000\n",
            "Epoch: 378, Batch: 47649, Example: 378924, Loss: 0.000\n",
            "Epoch: 378, Batch: 47674, Example: 379124, Loss: 0.000\n",
            "Epoch: 378, Batch: 47699, Example: 379324, Loss: 0.001\n",
            "Epoch: 378, Batch: 47724, Example: 379524, Loss: 0.001\n",
            "Epoch: 378, Batch: 47749, Example: 379724, Loss: 0.001\n",
            "Epoch: 379, Batch: 47774, Example: 379918, Loss: 0.000\n",
            "Epoch: 379, Batch: 47799, Example: 380118, Loss: 0.001\n",
            "Epoch: 379, Batch: 47824, Example: 380318, Loss: 0.000\n",
            "Epoch: 379, Batch: 47849, Example: 380518, Loss: 0.000\n",
            "Epoch: 379, Batch: 47874, Example: 380718, Loss: 0.000\n",
            "Epoch: 380, Batch: 47899, Example: 380912, Loss: 0.001\n",
            "Epoch: 380, Batch: 47924, Example: 381112, Loss: 0.000\n",
            "Epoch: 380, Batch: 47949, Example: 381312, Loss: 0.001\n",
            "Epoch: 380, Batch: 47974, Example: 381512, Loss: 0.001\n",
            "Epoch: 380, Batch: 47999, Example: 381712, Loss: 0.000\n",
            "Accuracy of the model at epoch 380: 99.40119760479043%\n",
            "Epoch: 381, Batch: 48024, Example: 381906, Loss: 0.000\n",
            "Epoch: 381, Batch: 48049, Example: 382106, Loss: 0.000\n",
            "Epoch: 381, Batch: 48074, Example: 382306, Loss: 0.000\n",
            "Epoch: 381, Batch: 48099, Example: 382506, Loss: 0.001\n",
            "Epoch: 381, Batch: 48124, Example: 382706, Loss: 0.001\n",
            "Epoch: 382, Batch: 48149, Example: 382900, Loss: 0.001\n",
            "Epoch: 382, Batch: 48174, Example: 383100, Loss: 0.001\n",
            "Epoch: 382, Batch: 48199, Example: 383300, Loss: 0.001\n",
            "Epoch: 382, Batch: 48224, Example: 383500, Loss: 0.000\n",
            "Epoch: 382, Batch: 48249, Example: 383700, Loss: 0.001\n",
            "Epoch: 383, Batch: 48274, Example: 383894, Loss: 0.000\n",
            "Epoch: 383, Batch: 48299, Example: 384094, Loss: 0.001\n",
            "Epoch: 383, Batch: 48324, Example: 384294, Loss: 0.000\n",
            "Epoch: 383, Batch: 48349, Example: 384494, Loss: 0.000\n",
            "Epoch: 383, Batch: 48374, Example: 384694, Loss: 0.000\n",
            "Epoch: 384, Batch: 48399, Example: 384888, Loss: 0.000\n",
            "Epoch: 384, Batch: 48424, Example: 385088, Loss: 0.000\n",
            "Epoch: 384, Batch: 48449, Example: 385288, Loss: 0.001\n",
            "Epoch: 384, Batch: 48474, Example: 385488, Loss: 0.001\n",
            "Epoch: 384, Batch: 48499, Example: 385688, Loss: 0.000\n",
            "Epoch: 385, Batch: 48524, Example: 385882, Loss: 0.000\n",
            "Epoch: 385, Batch: 48549, Example: 386082, Loss: 0.000\n",
            "Epoch: 385, Batch: 48574, Example: 386282, Loss: 0.000\n",
            "Epoch: 385, Batch: 48599, Example: 386482, Loss: 0.001\n",
            "Epoch: 385, Batch: 48624, Example: 386682, Loss: 0.000\n",
            "Accuracy of the model at epoch 385: 94.31137724550898%\n",
            "Epoch: 386, Batch: 48649, Example: 386876, Loss: 0.000\n",
            "Epoch: 386, Batch: 48674, Example: 387076, Loss: 0.000\n",
            "Epoch: 386, Batch: 48699, Example: 387276, Loss: 0.000\n",
            "Epoch: 386, Batch: 48724, Example: 387476, Loss: 0.000\n",
            "Epoch: 386, Batch: 48749, Example: 387676, Loss: 0.001\n",
            "Epoch: 387, Batch: 48774, Example: 387870, Loss: 0.001\n",
            "Epoch: 387, Batch: 48799, Example: 388070, Loss: 0.001\n",
            "Epoch: 387, Batch: 48824, Example: 388270, Loss: 0.001\n",
            "Epoch: 387, Batch: 48849, Example: 388470, Loss: 0.000\n",
            "Epoch: 387, Batch: 48874, Example: 388670, Loss: 0.001\n",
            "Epoch: 388, Batch: 48899, Example: 388864, Loss: 0.000\n",
            "Epoch: 388, Batch: 48924, Example: 389064, Loss: 0.000\n",
            "Epoch: 388, Batch: 48949, Example: 389264, Loss: 0.000\n",
            "Epoch: 388, Batch: 48974, Example: 389464, Loss: 0.001\n",
            "Epoch: 388, Batch: 48999, Example: 389664, Loss: 0.000\n",
            "Epoch: 389, Batch: 49024, Example: 389858, Loss: 0.001\n",
            "Epoch: 389, Batch: 49049, Example: 390058, Loss: 0.000\n",
            "Epoch: 389, Batch: 49074, Example: 390258, Loss: 0.000\n",
            "Epoch: 389, Batch: 49099, Example: 390458, Loss: 0.000\n",
            "Epoch: 389, Batch: 49124, Example: 390658, Loss: 0.000\n",
            "Epoch: 390, Batch: 49149, Example: 390852, Loss: 0.000\n",
            "Epoch: 390, Batch: 49174, Example: 391052, Loss: 0.000\n",
            "Epoch: 390, Batch: 49199, Example: 391252, Loss: 0.001\n",
            "Epoch: 390, Batch: 49224, Example: 391452, Loss: 0.000\n",
            "Epoch: 390, Batch: 49249, Example: 391652, Loss: 0.000\n",
            "Accuracy of the model at epoch 390: 98.00399201596807%\n",
            "Epoch: 391, Batch: 49274, Example: 391846, Loss: 0.001\n",
            "Epoch: 391, Batch: 49299, Example: 392046, Loss: 0.001\n",
            "Epoch: 391, Batch: 49324, Example: 392246, Loss: 0.001\n",
            "Epoch: 391, Batch: 49349, Example: 392446, Loss: 0.001\n",
            "Epoch: 391, Batch: 49374, Example: 392646, Loss: 0.000\n",
            "Epoch: 392, Batch: 49399, Example: 392840, Loss: 0.000\n",
            "Epoch: 392, Batch: 49424, Example: 393040, Loss: 0.000\n",
            "Epoch: 392, Batch: 49449, Example: 393240, Loss: 0.000\n",
            "Epoch: 392, Batch: 49474, Example: 393440, Loss: 0.000\n",
            "Epoch: 392, Batch: 49499, Example: 393640, Loss: 0.000\n",
            "Epoch: 393, Batch: 49524, Example: 393834, Loss: 0.001\n",
            "Epoch: 393, Batch: 49549, Example: 394034, Loss: 0.000\n",
            "Epoch: 393, Batch: 49574, Example: 394234, Loss: 0.000\n",
            "Epoch: 393, Batch: 49599, Example: 394434, Loss: 0.000\n",
            "Epoch: 393, Batch: 49624, Example: 394634, Loss: 0.001\n",
            "Epoch: 394, Batch: 49649, Example: 394828, Loss: 0.000\n",
            "Epoch: 394, Batch: 49674, Example: 395028, Loss: 0.001\n",
            "Epoch: 394, Batch: 49699, Example: 395228, Loss: 0.001\n",
            "Epoch: 394, Batch: 49724, Example: 395428, Loss: 0.000\n",
            "Epoch: 394, Batch: 49749, Example: 395628, Loss: 0.000\n",
            "Epoch: 395, Batch: 49774, Example: 395822, Loss: 0.000\n",
            "Epoch: 395, Batch: 49799, Example: 396022, Loss: 0.000\n",
            "Epoch: 395, Batch: 49824, Example: 396222, Loss: 0.000\n",
            "Epoch: 395, Batch: 49849, Example: 396422, Loss: 0.001\n",
            "Epoch: 395, Batch: 49874, Example: 396622, Loss: 0.000\n",
            "Accuracy of the model at epoch 395: 99.60079840319361%\n",
            "Epoch: 396, Batch: 49899, Example: 396816, Loss: 0.001\n",
            "Epoch: 396, Batch: 49924, Example: 397016, Loss: 0.001\n",
            "Epoch: 396, Batch: 49949, Example: 397216, Loss: 0.000\n",
            "Epoch: 396, Batch: 49974, Example: 397416, Loss: 0.001\n",
            "Epoch: 396, Batch: 49999, Example: 397616, Loss: 0.001\n",
            "Epoch: 397, Batch: 50024, Example: 397810, Loss: 0.000\n",
            "Epoch: 397, Batch: 50049, Example: 398010, Loss: 0.001\n",
            "Epoch: 397, Batch: 50074, Example: 398210, Loss: 0.001\n",
            "Epoch: 397, Batch: 50099, Example: 398410, Loss: 0.000\n",
            "Epoch: 397, Batch: 50124, Example: 398610, Loss: 0.000\n",
            "Epoch: 398, Batch: 50149, Example: 398804, Loss: 0.001\n",
            "Epoch: 398, Batch: 50174, Example: 399004, Loss: 0.000\n",
            "Epoch: 398, Batch: 50199, Example: 399204, Loss: 0.000\n",
            "Epoch: 398, Batch: 50224, Example: 399404, Loss: 0.001\n",
            "Epoch: 398, Batch: 50249, Example: 399604, Loss: 0.000\n",
            "Epoch: 398, Batch: 50274, Example: 399798, Loss: 0.000\n",
            "Epoch: 399, Batch: 50299, Example: 399998, Loss: 0.000\n",
            "Epoch: 399, Batch: 50324, Example: 400198, Loss: 0.000\n",
            "Epoch: 399, Batch: 50349, Example: 400398, Loss: 0.000\n",
            "Epoch: 399, Batch: 50374, Example: 400598, Loss: 0.001\n",
            "Epoch: 399, Batch: 50399, Example: 400798, Loss: 0.001\n",
            "Epoch: 400, Batch: 50424, Example: 400992, Loss: 0.000\n",
            "Epoch: 400, Batch: 50449, Example: 401192, Loss: 0.000\n",
            "Epoch: 400, Batch: 50474, Example: 401392, Loss: 0.000\n",
            "Epoch: 400, Batch: 50499, Example: 401592, Loss: 0.000\n",
            "Epoch: 400, Batch: 50524, Example: 401792, Loss: 0.001\n",
            "Accuracy of the model at epoch 400: 96.9061876247505%\n",
            "Epoch: 401, Batch: 50549, Example: 401986, Loss: 0.000\n",
            "Epoch: 401, Batch: 50574, Example: 402186, Loss: 0.000\n",
            "Epoch: 401, Batch: 50599, Example: 402386, Loss: 0.000\n",
            "Epoch: 401, Batch: 50624, Example: 402586, Loss: 0.001\n",
            "Epoch: 401, Batch: 50649, Example: 402786, Loss: 0.000\n",
            "Epoch: 402, Batch: 50674, Example: 402980, Loss: 0.000\n",
            "Epoch: 402, Batch: 50699, Example: 403180, Loss: 0.000\n",
            "Epoch: 402, Batch: 50724, Example: 403380, Loss: 0.001\n",
            "Epoch: 402, Batch: 50749, Example: 403580, Loss: 0.000\n",
            "Epoch: 402, Batch: 50774, Example: 403780, Loss: 0.000\n",
            "Epoch: 403, Batch: 50799, Example: 403974, Loss: 0.000\n",
            "Epoch: 403, Batch: 50824, Example: 404174, Loss: 0.000\n",
            "Epoch: 403, Batch: 50849, Example: 404374, Loss: 0.000\n",
            "Epoch: 403, Batch: 50874, Example: 404574, Loss: 0.000\n",
            "Epoch: 403, Batch: 50899, Example: 404774, Loss: 0.000\n",
            "Epoch: 404, Batch: 50924, Example: 404968, Loss: 0.001\n",
            "Epoch: 404, Batch: 50949, Example: 405168, Loss: 0.001\n",
            "Epoch: 404, Batch: 50974, Example: 405368, Loss: 0.000\n",
            "Epoch: 404, Batch: 50999, Example: 405568, Loss: 0.000\n",
            "Epoch: 404, Batch: 51024, Example: 405768, Loss: 0.000\n",
            "Epoch: 405, Batch: 51049, Example: 405962, Loss: 0.001\n",
            "Epoch: 405, Batch: 51074, Example: 406162, Loss: 0.000\n",
            "Epoch: 405, Batch: 51099, Example: 406362, Loss: 0.001\n",
            "Epoch: 405, Batch: 51124, Example: 406562, Loss: 0.000\n",
            "Epoch: 405, Batch: 51149, Example: 406762, Loss: 0.000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "843fdbadeb2445afa181f7cd9beb66eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Control-C detected -- Run data was not synced\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-9807c214ebcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-d81b860ff056>\u001b[0m in \u001b[0;36mmodel_pipeline\u001b[0;34m(hyperparameters)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0;31m# and use them to train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-2cba68e23db6>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(encoder, model, train_loader, test_loader, criterion, optimizer, config)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m           \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m25\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-d76b23f3b9c5>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(test_loader, encoder, model, epoch)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mimages1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0moutput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-47a5df2eab81>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrue_divide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mimg_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gdrive/MyDrive/64x64/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_name_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mimg_tp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gdrive/MyDrive/64x64/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_name_tp1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mimg_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/io/image.py\u001b[0m in \u001b[0;36mread_image\u001b[0;34m(path, mode)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \"\"\"\n\u001b[1;32m    222\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecode_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/io/image.py\u001b[0m in \u001b[0;36mdecode_image\u001b[0;34m(input, mode)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_width\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \"\"\"\n\u001b[0;32m--> 202\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"gdrive/MyDrive/models/cnn_rnn_400.pt\"\n",
        "\n",
        "encoder = Encoder()\n",
        "model = RNN(config)\n",
        "optimizer = torch.optim.Adam(model.parameters(), \n",
        "                                 lr=config.get(\"learning_rate\"))\n",
        "\n",
        "checkpoint = torch.load(PATH)\n",
        "encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']"
      ],
      "metadata": {
        "id": "8vMIri_uGY2s"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def printgradnorm(self, grad_input, grad_output):\n",
        "#     print('Inside ' + self.__class__.__name__ + ' backward')\n",
        "#     print('Inside class:' + self.__class__.__name__)\n",
        "#     print('')\n",
        "#     print('grad_input: ', type(grad_input))\n",
        "#     print('grad_input[0]: ', type(grad_input[0]))\n",
        "#     print('grad_output: ', type(grad_output))\n",
        "#     print('grad_output[0]: ', type(grad_output[0]))\n",
        "#     print('')\n",
        "#     print('grad_input size:', grad_input[0].size())\n",
        "#     print('grad_output size:', grad_output[0].size())\n",
        "#     print('grad_input norm:', grad_input[0].norm())\n",
        "# model.rnn.register_forward_hook(printgradnorm)\n",
        "\n",
        "# out = model(train_loader)\n",
        "# err = loss_fn(out, target)\n",
        "# err.backward()"
      ],
      "metadata": {
        "id": "ycRLGqbsdoCR",
        "outputId": "ba081fd9-2121-4b65-d580-d77f94025496",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-1936ac417076>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_forward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprintgradnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
          ]
        }
      ]
    }
  ]
}